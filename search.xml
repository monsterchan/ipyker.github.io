<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Elasticsearch7.0详解]]></title>
    <url>%2F2019%2F05%2F20%2Felasticsearch.html</url>
    <content type="text"><![CDATA[什么是ElasticsearchElasticsearch是一个高度可扩展的开源全文搜索和分析引擎。 它允许您快速，近乎实时地存储，搜索和分析大量数据。 它通常用作底层引擎/技术，本身扩展性很好，可以扩展到上百台服务器，处理PB级别的数据。 为具有复杂搜索特性和需求的应用程序提供支持。Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。 Elasticsearch能干什么 您运行在线网上商店，允许您的客户搜索您销售的产品。 在这种情况下，您可以使用Elasticsearch存储整个产品目录和库存，并为它们提供搜索和自动填充建议。 您希望收集日志或交易数据，并且希望分析和挖掘此数据以查找趋势，统计信息，摘要或异常。 在这种情况下，您可以使用Logstash（Elasticsearch / Logstash / Kibana堆栈的一部分）来收集，聚合和解析数据，然后让Logstash将此数据提供给Elasticsearch。 一旦数据在Elasticsearch中，您就可以运行搜索和聚合来挖掘您感兴趣的任何信息。 您运行价格提醒平台，允许对价格明确的客户指定一条规则，例如“我有兴趣购买特定的电子产品，如果某个供应商的电子产品价格在下个月内跌破X美元，我希望得到通知”。在这种情况下，您可以抓取供应商价格，将其推入Elasticsearch并使用其反向搜索（Percolator）功能来匹配价格变动与客户查询，并最终在发现匹配后将警报推送给客户。 您有分析/商业智能需求，并希望快速调查，分析，可视化并询问有关大量数据的特定问题（想想数百万或数十亿条记录）。 在这种情况下，您可以使用Elasticsearch存储数据，然后使用Kibana（Elasticsearch / Logstash / Kibana堆栈的一部分）构建自定义仪表板，该仪表板可以可视化对您来说重要的数据。 此外，您可以使用Elasticsearch聚合功能针对您的数据执行复杂的商业智能查询。 Elasticsearch核心概念Near-realtime(NRT)： 近实时 Elasticsearch是一个近实时搜索平台。 这意味着从索引文档到可搜索文档的时间有一点延迟（通常是一秒）。 Cluster：集群 cluster是一个或多个节点（服务器）的集合，它们共同保存您的整个数据，并提供跨所有节点的联合索引和搜索功能。 群集由唯一名称标识，默认情况下为“elasticsearch”。 这个标识很重要，节点会根据这个标识加入到一个集群。 确保不要在不同的环境中使用相同的群集名称，这会导致节点加入错误的集群。例如，您可以将logging-dev，logging-stage和logging-prod用于开发，测试和生产集群。 请注意，如果一个集群只有一个节点也是完全可行的，此外你也可以建立多个独立的集群，每个集群有自己的唯一标识。 Node：节点 节点是作为群集一部分的单个服务器，用于存储集群数据并为集群提供索引和搜索能力。 与集群一样，每个节点也有一个唯一名称标识，在节点启动的时候会默认分配给它一个随机通用唯一标识(UUID)。 你也可以自定义节点标识，以代替默认标识。在集群的管理中，可以使用节点标识来对应网络中的服务器名称。 节点可以根据配置的集群标识加入指定的集群。一般来说，每个节点在启动之后会默认加入一个叫elasticsearch的集群。假如在一个节点可以相互发现对方的网络环境中，启动多个节点，他们会自动加入到一个标识为elasticsearch的集群。 在一个独立的集群中，你可以建立任意个数的节点。此外，如果当前网络环境中没有其他的elasticsearch节点在运行，那么单独启动一个节点会形成一个单节点的集群，其集群标识为elasticsearch Index：索引索引是具有某些类似特征的文档（Document）集合。 例如，可以为客户数据建立索引，为产品目录建立另一个索引，为订单数据建立另一个索引。索引由名称标识(必须全部为小写)，当对其中的文档执行索引、搜索、更新和删除操作时，需要引用索引名称。 Type：类型warning :在6.0.0后弃用 它曾经是索引的逻辑类别/分区，允许您在同一索引中存储不同类型的文档，例如，一种用户类型，另一种用于博客帖子。 不再可能在索引中创建多个类型。在Elasticsearch 7.0.0或更高版本中创建的索引不再接受default映射。 在6.x中创建的索引将继续像以前一样在Elasticsearch 6.x中运行。 在7.0中的API中不推荐使用type，对索引创建，放置映射，获取映射，放置模板，获取模板和获取字段映射API进行重大更改。详见Removal of mapping types Document：文档 Document是可以被索引的基本信息单元。 例如，您可以为单个客户提供文档，为单个产品提供另一个文档，为单个订单提供另一个文档。 该文档以JSON格式表示。在索引（index）或者类型（type）中可以存储任意多的文档。尽管文档实际存储在索引中，但是使用中必须把文档编入或者分配到一个索引的类型中。 Shard：分片 一个索引index可能会存储大量的数据，大到超过一个节点的存储能力。例如：一个占用1T磁盘存储空间的索引，对单节点来说可能会太大，或者造成查询请求太慢。 为了解决这个问题，Elasticsearch提供了将索引细分为多个称为分片(shard)的功能。 创建索引时，只需定义所需的分片数即可。 每个分片本身都是一个功能齐全且独立的“索引”，每个分片可以放到不同的服务器上。 当你查询的索引分布在多个分片上时，Elasticsearch会把查询发送给每个相关的分片，并将结果组合在一起，而应用程序并不知道分片的存在。即：这个过程对用户来说是透明的。 Replicas：副本 为提高查询吞吐量或实现高可用性，可以使用分片副本。 副本是一个分片的精确复制，每个分片可以有零个或多个副本。Elasticsearch会中可以有许多相同的分片，其中之一被选择更改索引操作，这种特殊的分片称为主分片。 当主分片丢失时，如：该分片所在的数据不可用时，集群将副本提升为新的主分片。 Full-text-search：全文检索全文检索就是对一篇文章进行索引，可以根据关键字搜索，类似于mysql里的like语句。 全文索引就是把内容根据词的意义进行分词，然后分别创建索引，例如“你们的激情是因为什么事情来的” 可能会被分词成：“你们“，”激情“，“什么事情“，”来“ 等token，这样当你搜索“你们” 或者 “激情” 都会把这句搜出来。 Elasticsearch的安装由于上篇文章已经对elasticsearch7.0.1版本进行了安装，用户可以参考该安装方式，进行多节点集群安装部署。 Restful API接口规范Elasticsearch提供了一个非常全面和强大的REST API，可以使用它与集群进行交互。使用该API可以做一些事情如下: 检查群集，节点和索引运行状况，状态和统计信息 管理您的群集，节点和索引数据和元数据 对索引执行CRUD（创建，读取，更新和删除）和搜索操作 执行高级搜索操作，例如分页，排序，过滤，脚本编写，聚合等等]]></content>
      <categories>
        <category>elastic</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客Next7.X版本主题配置]]></title>
    <url>%2F2019%2F05%2F01%2Fhexo-next.html</url>
    <content type="text"><![CDATA[前言 Hexo安装过后，默认的主题是landscape，如果不喜欢，我们也可以进行更换。本文主要讲解NexT主题的使用。 Hexo主题相关网址hexo官网nexT7.x 目录我们主要对next主题进行了如下配置操作，该配置后的next主题获取地址：https://github.com/ipyker/hexo-next-theme 设置中文语言设置博主文字描述设置博客文章连接为year/month/day/title.html格式Menu增加关于、标签、分类、互动、搜索菜单禁用关于、标签、分类菜单评论功能添加添加RSS设置背景图片。默认禁用，可以在themes/nexT/source/css/_custom/custon.styl文件中启用设置Canvas_nest动态背景图片快速加载设置微信支付宝打赏功能点击出现桃心效果主页文章添加阴影效果设置代码高亮顶栏背景色底栏背景色在右上角实现红色的fork me on github。默认禁用，可以在themes/nexT/_config.yml文件github_banner键中启用添加添加RSS修改文章内链接文本样式修改文章底部标签样式在文章末尾添加“文章结束”标记设置头像网站底部加上访问量网站底部字数统计网站底部添加网站运行时间网站底部添加动态桃心网站底部添加备案信息底部隐藏由Hexo强力驱动、主题–NexT.Mist设置网站的图标Favicon实现文章文字统计功能和阅读时长添加来必力云跟帖功能。（需要自己注册获取ID）去掉底部重复字数统计修改字体大小添加DaoVoice在线联系。（需要自己注册获取ID）侧边栏社交小图标设置添加侧栏推荐阅读修改侧边栏背景图片修改侧边栏文字颜色在文章底部增加版权信息Hexo博客添加站内搜索修改选中字符的颜色添加aplay音乐播放添加博客右下角卡通动漫]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7 安装Docker-CE]]></title>
    <url>%2F2019%2F03%2F21%2Finstall-docker-ce.html</url>
    <content type="text"><![CDATA[CentOS7 安装Docker-CE从2017年3月开始 docker 在原来的基础上分为两个分支版本: Docker-CE 和 Docker-EE。Docker-CE 即社区免费版，Docker-EE 即企业版，强调安全，但需付费使用。本文介绍 Docker-ce的安装使用。 移除旧的版本12345678910$ sudo yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine 安装一些必要的系统工具1$ sudo yum install -y yum-utils device-mapper-persistent-data lvm2 添加软件源信息1$ sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 更新 yum 缓存1$ sudo yum makecache fast 查看可用版本的 Docker-CE1$ yum list docker-ce --showduplicates | sort -r 注意：如果需要只显示table版本，可以关闭测试版本的list 12$ sudo yum-config-manager --enable docker-ce-edge$ sudo yum-config-manager --enable docker-ce-test 更新yum包索引1$ yum makecache fast 安装指定版本的docker-CE1$ sudo yum install -y docker-ce-17.03.2.ce-1.el7.centos 报错：如果在安装指定版本的docker时显示需要安装指定版本的docker-ce-selinux依赖包，请安装： 1$ yum install -y https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-selinux-17.03.2.ce-1.el7.centos.noarch.rpm]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elastic stack之EFK安装]]></title>
    <url>%2F2019%2F03%2F15%2Finstall-efk.html</url>
    <content type="text"><![CDATA[试验环境本次试验的elastic stack软件都为7.0.1版本，现在官网最新的为7.1版本，用户可在官方下载下载地址。 主机名 ip地址 服务 efk-node1 192.168.20.211 elasticsearch、kibana、jdk8 efk-node2 192.168.20.212 elasticsearch、cerebro、jdk8 real-server 192.168.20.250 filebeat 环境准备安装JDKelasticsearch需要jdk环境的支持，7.0.1版本默认已经自带JDK了，但是为了日后扩展问题，我们还是手动配置一边JDK环境。以下操作在efk-node1和efk-node2主机上进行：123456789101112131415161718# 下面下载链接因授权问题，需用户前往JDK官网下载$ wget https://download.oracle.com/otn/java/jdk/8u171-b12/478a62b7d4e34b78b671c754eaaf38ab/jdk-8u171-linux-x64.tar.gz$ tar zxvf jdk-8u171-linux-x64.tar.gz -C /usr/local/$ cat &gt;&gt; /etc/profile &lt;&lt; EOFexport JAVA_HOME=/usr/local/jdk1.8.0_171export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$JAVA_HOME/bin:$PATHEOF$ source /etc/profile# 验证JDK, JDK配置完成$ java -versionjava version "1.8.0_171"Java(TM) SE Runtime Environment (build 1.8.0_171-b11)Java HotSpot(TM) 64-Bit Server VM (build 25.171-b11, mixed mode) 设置服务器的最大文件数123456$ cat &gt;&gt; /etc/security/limits.conf &lt;&lt; EOF * soft nofile 655350 * hard nofile 655350 * soft nproc 655350 * hard nproc 655350EOF 设置服务器打开的最大进程数1234$ cat &gt; /etc/security/limits.d/20-nproc.conf &lt;&lt; EOF* soft nproc 4096root soft nproc unlimitedEOF 设置nmap数量对虚拟内存的支持12345$ cat &gt;&gt; /etc/sysctl.conf &lt;&lt; EOFvm.max_map_count=262144EOF$ sysctl -p 本地host解析12345cat &gt;&gt; /etc/hosts &lt;&lt; EOFefk-node1 192.168.20.211efk-node2 192.168.20.212real-server 192.168.20.250EOF 安装elasticsearch以下操作在efk-node1和efk-node2主机上进行： 下载和解压12345678# 创建elastic工作目录$ mkdir /elastic &amp;&amp; cd /elastic# 下载elasticsearch tar包$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.0.1-linux-x86_64.tar.gz# 解压到当前/elastic目录$ tar zxvf elasticsearch-7.0.1-linux-x86_64.tar.gz 修改配置文件下面只列出已配置的参数1234567891011$ cat elasticsearch-7.0.1/config/elasticsearch.yml | egrep -v "^$|^#" cluster.name: efk-cluster # 集群名称 node.name: efk-node1 # 节点名称，212服务器改成efk-node2 path.data: /var/lib/elasticsearch # elasticsearch数据目录 path.logs: /var/log/elasticsearch # elasticsearch日志目录 network.host: 0.0.0.0 # elasticsearch绑定的地址 http.port: 9200 # elasticsearch绑定的端口 discovery.seed_hosts: ["efk-node1", "efk-node2"] #集群发现 cluster.initial_master_nodes: ["efk-node1", "efk-node2"] #第一次访问初始的集群节点 xpack.security.enabled: true # ssl\tls安全参数 xpack.security.transport.ssl.enabled: true # ssl\tls安全参数 创建运行elasticsearch用户 elasticsearch默认是不运行root用户运行的，因此我们得创建一个新用户来运行elasticsearch。 12$ useradd elastic$ passwd elastic 创建依赖文件12345678910$ mkdir /var/log/elasticsearch # 创建日志目录$ mkdir /var/lib/elasticsearch # 创建数据目录$ touch /var/run/elasticsearch.pid # 创建进程文件$ chown -R elastic.elastic /elastic # 修改elastic工作目录所有者$ chown -R elastic.elastic /var/log/elasticsearch &amp;&amp; \chown -R elastic.elastic /var/lib/elasticsearch &amp;&amp; \chown -R elastic.elastic /var/run/elasticsearch.pid # 相关目录所有者都修改成运行elasticsearch服务的用户 准备elasticsearch systemctl文件12345678910111213141516171819[Unit]Description=ElasticsearchDocumentation=http://www.elastic.coWants=network-online.targetAfter=network-online.target[Service]Environment=JAVA_HOME=/usr/local/jdk1.8.0_171User=elasticGroup=elasticExecStart=/elastic/elasticsearch-7.0.1/bin/elasticsearch -p /var/run/elasticsearch.pidLimitNOFILE=65535LimitNPROC=65535LimitAS=infinityLimitFSIZE=infinity[Install]WantedBy=multi-user.target 启动elasticsearch12345$ systemctl daemon-reload # 加载systemctl配置文件$ systemctl start elasticsearch # 启动elasticsearch$ systemctl enable elasticsearch # 设置开机启动elasticsearch Tips: elasticsearch7.0.1安装完默认自带基础版的X-Pack功能，使用铂金版的需要购买或者参考破解X-pack进行破解。 验证集群状态通过上面的配置，我们的elasticsearch服务器已经启动，并且默认监听在9200和9300端口。9200端口: 为web访问提供服务；9300端口：为集群节点提供通信。12345678910# 验证集群节点数，其中master为*的代表该节点为主节点$ curl http://192.168.20.211:9200/_cat/nodes?vip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name192.168.20.212 10 39 0 0.00 0.01 0.05 mdi - efk-node2192.168.20.211 18 37 0 0.00 0.01 0.05 mdi * efk-node1# 验证集群健康状态，status为green表示正常$ curl http://192.168.20.211:9200/_cat/health?vepoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent1558517253 09:27:33 efk-cluster green 2 2 6 3 0 0 0 0 - 100.0% 由上可知，我们的elasticsearch集群已经正常工作了，并且在2台集群节点下/var/lib/elasticsearch目录下都有相同的数据。更多关于elasticsearch REST API请参考官方说明。cluster apis _cat apis Search apis Document apis 安装 Kibana以下操作只在efk-node1主机上进行： 下载和解压12345678# 进入elastic工作目录$ cd /elastic# 下载kibana tar包$ wget https://artifacts.elastic.co/downloads/kibana/kibana-7.0.1-linux-x86_64.tar.gz# 解压到当前/elastic目录$ tar zxvf kibana-7.0.1-linux-x86_64.tar.gz 修改配置文件下面只列出已配置的参数123456789101112$ cat kibana-7.0.1-linux-x86_64/config/kibana.yml | egrep -v "^$|^#" server.port: 5601 # kibana服务端口 server.host: "0.0.0.0" # kibana服务地址 elasticsearch.hosts: ["http://192.168.20.201:9200"] # es访问地址，kibana需要和它通信 elasticsearch.username: "elastic" # es帐号，如果是X-pack铂金版可配 elasticsearch.password: "pyker123456" # es密码，如果是X-pack铂金版可配 elasticsearch.logQueries: true # 查询日志是否发送到ES，配合logging.json: true pid.file: /var/run/kibana.pid # kibana的进行id文件 logging.dest: /var/log/kibana.log # kibana日志文件 logging.json: true # 以json格式输出日志 logging.verbose: true # 记录所有事件，包括系统使用信息和所以请求 i18n.locale: "zh-CN" # 设置kibana为中文 创建依赖文件1234567$ touch /var/log/kibana.log # 创建日志文件$ touch /var/run/kibana.pid # 创建进程文件$ chown -R elastic.elastic /elastic &amp;&amp; \chown -R elastic.elastic /var/log/kibana.log &amp;&amp; \chown -R elastic.elastic /var/run/kibana.pid # 修改elastic工作目录及相关工作文件所有者 Tips：默认Kibana是支持root运行的，我这里为了统一elasticsearch运行环境所以打算elastic用户运行。 准备kibana systemctl文件1234567891011121314[Unit]Description=KibanaDocumentation=http://www.elastic.coWants=network-online.targetAfter=network-online.target[Service]User=elasticGroup=elasticExecStart=/elastic/kibana-7.0.1-linux-x86_64/bin/kibanaRestart=always[Install]WantedBy=multi-user.target 启动kibana12345$ systemctl daemon-reload # 加载systemctl配置文件$ systemctl start kibana # 启动kibana$ systemctl enable kibana # 设置开机启动kibana Kibana默认监控在5601端口上，此时可以通过http://192.168.20.211:5601访问kibana。 安装cerebro可视化集群管理工具cerebro是一个使用Scala，Play Framework，AngularJS和Bootstrap构建的开源（MIT许可）elasticsearch web可视化的监控工具，Github项目以下操作只在efk-node2主机上进行： 下载和解压请前往https://github.com/lmenezes/cerebro/releases 地址下载cerebro工具12345678910111213141516$ tar zxvf cerebro-0.8.3.tgz$ vim cerebro-0.8.3/conf/application.conf # 设置cerebro密码登陆认证auth=&#123; type: basic settings: &#123; username="admin" password="pyker123456" &#125;&#125;# 文件最后配置elasticsearch地址hosts = [ &#123; host = "http://192.168.20.211:9200" name = "efk-cluster" &#125;, 准备cerebro systemctl文件123456789101112131415[Unit]Description=CerebroAfter=network.target[Service]Environment=JAVA_HOME=/usr/local/jdk1.8.0_171User=elasticGroup=elasticLimitNOFILE=65535ExecStart=/elastic/cerebro-0.8.3/bin/cerebro -Dconfig.file=/elastic/cerebro-0.8.3/conf/application.conf -Dhttp.port=1234Restart=on-failureWorkingDirectory=/elastic/cerebro-0.8.3[Install]WantedBy=multi-user.target 命令启动cerebro12# 默认9000端口$ nohup ./bin/cerebro -Dhttp.port=1234 -Dhttp.address=192.168.20.212 &amp; systemctl方式启动cerebro12345$ systemctl daemon-reload # 加载systemctl配置文件$ systemctl start cerebro # 启动cerebro$ systemctl enable cerebro # 设置开机启动cerebro 访问cerebro通过浏览器访问http://192.168.20.212:1234就可以cerebro工具了。该工具详细的显示了es集群状态、节点数、索引数、分片数、文档数以及数据大小等参数。 安装filebeat此前文档我们已经说明了关于filebeat的原理，以及一些配置文件参数。现在我们只初略的说明我们已使用的配置参数。以下操作只在real-server主机上进行：（也就是我们业务所跑的服务器，我们要抓取的是业务日志，所以当然是安装在业务服务器上咯） 下载和解压12345678# 进入elastic工作目录$ mkdir /elastic &amp;&amp;&amp; cd /elastic# 下载kibana tar包$ wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.0.1-linux-x86_64.tar.gz# 解压到当前/elastic目录$ tar zxvf filebeat-7.0.1-linux-x86_64.tar.gz 本例我们使用filebeat监控tomcat日志和nginx日志 修改配置文件以配置文件方式支持tomcat日志输入下面只列出已配置的参数，关于参数说明，请参考此前文档123456789101112131415161718192021222324252627282930313233343536$ cat filebeat-7.0.1-linux-x86_64/filebeat.ymlfilebeat.inputs:- type: log enabled: true paths: - /usr/local/tomcat/logs/catalina.out # 监控tomcat控制台catalina.out日志文件 fields: log_topic: tomcat_access_logs exclude_lines: ['收到ping的消息'] multiline.pattern: '^[[:space:]]+|^Caused by:' multiline.negate: false multiline.match: after ignore_older: 0 close_inactive: 2m- type: log enabled: true paths: - /usr/local/tomcat/logs/localhost_access.* # 监控tomcat访问localhost_access日志文件 fields: log_topic: tomcat_catalina_logsfilebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: truesetup.template.settings: index.number_of_shards: 1setup.kibana: host: "192.168.20.211:5601"output.elasticsearch: # 我们这里直接输出到ES，当然也可以输出到logstash、kafka等中间件 hosts: ["192.168.20.211:9200"] #protocol: "https" username: "elastic" password: "pyker123456"processors: - add_host_metadata: ~ - add_cloud_metadata: ~ catalina.out和localhost_access都需要使用一定的格式。方便filebeat处理多行事件日志。 以模版方式支持nginx日志输入默认filebeat自带诸多服务日志模版，如：nginx、redis、apache、IIS、kafka等等。默认都在filebeat解压后module、modules.d目录中。12345678$ cat /elastic/filebeat-7.0.1-linux-x86_64/modules.d/nginx.yml.disabled- module: nginx access: enabled: true var.paths: ["/data/wwwlogs/access.log*"] # 配置nginx实际的访问日志路径，多个文件逗号分开 error: enabled: true var.paths: ["/data/wwwlogs/error_nginx.log*"] # 配置nginx实际的错误日志路径 启动nginx模版123456789101112$ cd /elastic/filebeat-7.0.1-linux-x86_64$ ./filebeat modules enable nginx $ ./filebeat modules list # 列出已启动和未启动的模版Enabled:nginxsystemDisabledapacheauditd... 准备filebeat systemctl文件123456789101112[Unit]Description=Filebeat sends log files to Logstash or directly to Elasticsearch.Documentation=https://www.elastic.co/products/beats/filebeatWants=network-online.targetAfter=network-online.target[Service]ExecStart=/elastic/filebeat-7.0.1-linux-x86_64/filebeat -c /elastic/filebeat-7.0.1-linux-x86_64/filebeat.ymlRestart=always[Install]WantedBy=multi-user.target 启动filebeat12345$ systemctl daemon-reload # 加载systemctl配置文件$ systemctl start filebeat # 启动filebeat$ systemctl enable filebeat # 设置开机启动filebeat 至此简单的EFK集群搭建完成。在生成环境中 我们还会在filebeat和elasticsearch中间加入kafka和logstash来提高日志数据的高效传输和更强的日志过滤功能，而kafka又可以配置成集群模式。 在当前文档中我们并未说明kibana如何使用，请参考官方使用教程]]></content>
      <categories>
        <category>elastic</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
        <tag>filebeat</tag>
        <tag>kibana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elastic Stack之Filebeat7.0详解]]></title>
    <url>%2F2019%2F03%2F14%2Ffilebeat.html</url>
    <content type="text"><![CDATA[一：认识Filebeat Filebeat是beats其中一个组件，它是一个轻量型日志采集器，可以直接（或者通过Logstash）将数据发送到Elasticsearch，在那里你可以进一步处理和增强数据，然后在Kibana中将其可视化。 当您要面对成百上千、甚至成千上万的服务器、虚拟机和容器生成的日志时，请告别 SSH 吧。Filebeat 将为您提供一种轻量型方法，用于转发和汇总日志与文件，让简单的事情不再繁杂。 它性能稳健，不错过任何检测信号，无论在任何环境中，随时都潜伏着应用程序中断的风险。Filebeat 能够读取并转发日志行，如果出现中断，还会在一切恢复正常后，从中断前停止的位置继续开始。 Filebeat 内置有多种模块（auditd、Apache、NGINX、System、MySQL 等等），可针对常见格式的日志大大简化收集、解析和可视化过程，只需一条命令即可。之所以能实现这一点，是因为它将自动默认路径（因操作系统而异）与 Elasticsearch 采集节点管道的定义和 Kibana 仪表板组合在一起。不仅如此，数个 Filebeat 模块还包括预配置的 Machine Learning 任务。 二：Filebeat工作原理Filebeat由两个主要组件组成：inputs 和 harvesters（直译：收割机，采集器）。这些组件一起工作以跟踪文件，并将事件数据发送到你指定的输出。 2.1 harvester是什么一个harvester负责读取一个单个文件的内容。harvester逐行读取每个文件（一行一行地读取每个文件），并把这些内容发送到输出。每个文件启动一个harvester负责打开和关闭这个文件，这就意味着在harvester运行时文件描述符保持打开状态。而在harvester正在读取文件内容的时候，文件被删除或者重命名了，那么Filebeat会继续读这个文件。这就有一个问题了，就是只要负责这个文件的harvester没用关闭，那么磁盘空间就不会释放。默认情况下，Filebeat保存文件打开直到close_inactive到达。 2.2 input是什么一个input负责管理当前的harvesters，并找到所有要读取的源。如果input类型是log，则input查找paths已定义的glob路径匹配的所有日志文件，并为每个文件启动一个harvester。下面的例子配置Filebeat从所有匹配指定的glob模式的文件中读取行：12345filebeat.inputs:- type: log paths: - /var/log/*.log - /var/path2/*.log 2.3 Filebeat如何保持文件状态Filebeat保存每个文件的状态，并经常刷新状态到磁盘上的注册文件（registry）。状态用于记住harvester读取文件的最后一个偏移量（行），并确保所有日志行被发送到输出（如Elasticsearch 或者 Logstash等），当输出无法访问时，那么Filebeat会跟踪已经发送的最后一行，并只要输出再次变得可用时继续读取文件。当Filebeat运行时，会将每个文件的状态新保存在内存中。当Filebeat重新启动时，将使用注册文件中的数据重新构建状态，Filebeat将在最后一个已知行位置继续每个harvester。对于每个输入，Filebeat保存它找到的每个文件的状态。因为文件可以重命名或移动，所以文件名和路径不足以标识文件。对于每个文件，Filebeat存储惟一标识符，以检测文件是否以前读取过。如果你的情况涉及每天创建大量的新文件，你可能会发现注册表文件变得太大了。为了减小注册表文件的大小，有两个配置选项可用：clean_remove和clean_inactive。对于你不再访问且被忽略的旧文件，建议您使用clean_inactive。如果想从磁盘上删除旧文件，那么使用clean_remove选项。 2.4 Filebeat如何确保至少投递一次（at-least-once）Filebeat保证事件将被投递到配置的输出中至少一次，并且不会丢失数据。Filebeat能够实现这种行为，因为它将每个事件的投递状态存储在注册表文件中。在定义的输出被阻塞且没有确认所有事件的情况下，Filebeat将继续尝试发送事件，直到输出确认收到事件为止。如果Filebeat在发送事件的过程中关闭了，则在关闭之前它不会等待输出确认所有事件。当Filebeat重新启动时，发送到输出（但在Filebeat关闭前未确认）的任何事件将再次发送。这确保每个事件至少被发送一次，但是你最终可能会将重复的事件发送到输出。你可以通过设置shutdown_timeout选项，将Filebeat配置为在关闭之前等待特定的时间。 三：配置Filebeat为了配置Filebeat，你可以编辑配置文件filebeat.yml。此外同级目录下还有一个完整的配置文件示例filebeat.reference.yml 3.1 指定运行哪个模块Filebeat提供了几种启用模块的不同方式： 用modules.d目录下的配置启用模块 运行Filebea命令的时候启用模块 配置filebeat.yml文件启用模块配置 1234567891011# 用modules.d目录启用模块配置$ ./filebeat modules enable apache2 mysql# 运行Filebea命令的时候启用模块$ ./filebeat --modules nginx,mysql,system# 配置`filebeat.yml`文件启用模块配置filebeat.modules: - module: nginx - module: mysql - module: system 3.2 配置inputs为了手动配置Filebeat（代替用模块），你可以在filebeat.yml中的filebeat.inputs区域下指定一个inputs列表。列表是一个YMAL数组，并且你还可以指定多个inputs，相同input类型也可以指定多个。例如：1234567891011filebeat.inputs:- type: log paths: - /var/log/system.log - /var/log/wifi.log- type: log paths: - "/var/log/apache2/*" fields: apache: true fields_under_root: true 上面案例是从日志文件中读取行，类型为log的input需要指定一个paths列表，列表中的每一项必须能够定位并抓取到日志行。此外你还可以配置其它额外的配置项（比如，fields, include_lines, exclude_lines, multiline等等）来从这些文件中过滤读取行。你设置的这些配置对当前所有这种类型的input在获取日志行的时候都生效。为了对不同的文件应用不同的配置，你需要定义多个input区域。 3.3 其他配置项 paths：从预定义的目录级别下抓取所有文件。例如：/var/log//.log 将会抓取/var/log子目录目录下所有.log文件。它不会抓取/var/log本身目录下的日志文件。也不会抓取子目录的子目录下的日志文件。如果你应用recursive_glob: true设置的话，它将递归地抓取所有子目录下的所有.log文件。 recursive_glob.enabled允许将**扩展为递归glob模式。启用这个特性后，每个路径中最右边的**被扩展为固定数量的glob模式。例如：/foo/**扩展到/foo， /foo/*， /foo/**，等等。如果启用，它将单个**扩展为8级深度*模式。这个特性默认是启用的，设置recursive_glob.enabled: false可以禁用它。 encoding按照W3C推荐的HTML5读取的文件的编码。例如：plain, latin1, utf-8, utf-16be-bom, utf-16be, utf-16le, big5, gb18030, gbk, hz-gb-2312。plain编码是特殊的，因为它不校验或者转换任何输入。 exclude_lines一组正则表达式，用于匹配你想要排除的行。Filebeat会删除这组正则表达式匹配的行。默认情况下，没有行被删除。空行被忽略。如果指定了multiline，那么在用exclude_lines过滤之前会将每个多行消息合并成一个单行。（PS：也就是说，多行合并成单行后再支持排除行的过滤）例如配置Filebeat删除以DBG开头的行： 1234filebeat.inputs:- type: log ... exclude_lines: ['^DBG'] include_lines一组正则表达式，用于匹配你想要包含的行。Filebeat只会导出匹配这组正则表达式的行。默认情况下，所有行都被导出。空行被忽略。如果指定了multipline设置，每个多行消息先被合并成单行后再执行include_lines过滤。例如配置Filebeat导出以ERR或者WARN开头的行： 1234filebeat.inputs:- type: log ... include_lines: ['^ERR', '^WARN'] 如果include_lines 和 exclude_lines 都被定义了，那么Filebeat先执行include_lines后执行exclude_lines，而与这两个选项被定义的顺序没有关系。例如导出那些除了以DGB开头的所有包含sometext的行： 12345filebeat.inputs:- type: log ... include_lines: ['sometext'] exclude_lines: ['^DBG'] exclude_files需要排除的日志文件。 要匹配的正则表达式列表。 Filebeat从列表中删除与任何正则表达式匹配的文件。 默认情况下，不会删除任何文件。例如忽略.gz的文件: 1234filebeat.inputs:- type: log ... exclude_files: ['\.gz$'] fields可选的附加字段。 可以自由选择这些字段，以便将其他信息添加到已抓取到的日志文件中进行过滤。 fields_under_root设置为true可将其他字段存储为顶级字段，而不是“字段”子字典下。 如果名称与Filebeat本身添加的字段冲突，则自定义字段会覆盖默认字段。 harvester_buffer_size当抓取一个文件时每个harvester使用的buffer的字节数。默认是16384。 max_bytes单个日志消息允许的最大字节数。超过max_bytes的字节将被丢弃且不会发送到输出。对于多行日志消息来说这个设置是很有用的，因为它们往往很大。默认是10MB（10485760）。 json json.keys_under_root 默认情况下，解码后的JSON被放置在一个以”json”为key的输出文档中。如果你启用这个设置，那么这个key在文档中被复制为顶级。默认是false。 json.overwrite_keys 如果启用了keys_under_root和该设置，则解码的JSON对象中的值将覆盖Filebeat通常添加的字段（类型，来源，偏移等），以防发生冲突。 json.add_error_key 如果启用次设置，则当JSON解析出现错误的时候Filebeat添加 error.message和 error.type: json两个key，或者当没有使用message_key的时候。 json.message_key 一个可选的配置，用于在应用行过滤和多行设置的时候指定一个JSON key。指定的这个key必须在JSON对象中是顶级的，而且其关联的值必须是一个字符串，否则没有过滤或者多行聚集发送。 ignore_decoding_error 一个可选的配置，用于指定是否JSON解码错误应该被记录到日志中。如果设为true，错误将被记录。默认是false。 123json.keys_under_root: truejson.add_error_key: truejson.message_key: log multiline multiline.pattern 指定要匹配的正则表达式模式。根据您配置其他多行选项的方式，与指定正则表达式匹配的行被视为前一行的延续或新多行事件的开始。 您可以设置negate选项来否定模式。 multiline.negate 定义模式是否被否定。 默认值为false。 multiline.match 指定Filebeat如何将匹配行组合到事件中。 设置是在之前或之后。 这些设置的行为取决于您为negate指定的内容。 123multiline.pattern: '^\['multiline.negate: truemultiline.match: after multiline.negate multiline.match Result false after 与模式匹配的连续行和前面不匹配的行合并成一条完整日志 false before 与模式匹配的连续行和后面不匹配的行合并成一条完整日志 true after 与模式匹配的行和后面不匹配的行组成一条完整日志 true before 与模式匹配的行和前面不匹配的行组成一条完整日志 例如Java堆栈跟踪由多行组成，在初始行之后的每一行都以空格开头，例如下面这样：1234Exception in thread "main" java.lang.NullPointerException at com.example.myproject.Book.getTitle(Book.java:16) at com.example.myproject.Author.getBookTitles(Author.java:25) at com.example.myproject.Bootstrap.main(Bootstrap.java:14) 为了把这些行合并成单个事件，用写了多行配置：123multiline.pattern: '^[[:space:]]'multiline.negate: falsemultiline.match: after 下面是一个稍微更复杂的例子1234567Exception in thread "main" java.lang.IllegalStateException: A book has a null property at com.example.myproject.Author.getBookIds(Author.java:38) at com.example.myproject.Bootstrap.main(Bootstrap.java:14)Caused by: java.lang.NullPointerException at com.example.myproject.Book.getId(Book.java:22) at com.example.myproject.Author.getBookIds(Author.java:35) ... 1 more 为了合并这个，用下面的配置：123multiline.pattern: '^[[:space:]]+(at|\.&#123;3&#125;)\b|^Caused by:'multiline.negate: falsemultiline.match: after 在这个例子中，模式匹配下列行： 以空格开头，后面跟 at 或者 … 的行 以 Caused by: 开头的行 ignore_older如果启用，那么Filebeat会忽略在指定的时间跨度之前被修改的文件。如果你想要保留日志文件一个较长的时间，那么配置ignore_older是很有用的。例如，如果你想要开始Filebeat，但是你只想发送最近一周最新的文件，这个情况下你可以配置这个选项。你可以用时间字符串，比如2h（2小时），5m（5分钟）。默认是0，意思是禁用这个设置。你必须设置ignore_older比close_inactive更大。 close_*close_*配置项用于在一个确定的条件或者时间点之后关闭harvester。关闭harvester意味着关闭文件处理器。如果在harvester关闭以后文件被更新，那么在scan_frequency结束后改文件将再次被拾起。然而，当harvester关闭的时候如果文件被删除或者被移动，那么Filebeat将不会被再次拾起，并且这个harvester还没有读取的数据将会丢失。 close_inactive 当启用此选项时，如果文件在指定的持续时间内未被获取，则Filebeat将关闭文件句柄。当harvester读取最后一行日志时，指定周期的计数器就开始工作了。它不基于文件的修改时间。如果关闭的文件再次更改，则会启动一个新的harvester，并且在scan_frequency结束后，将获得最新的更改。 推荐给close_inactive设置一个比你的日志文件更新频率更大一点儿的值。例如，如果你的日志文件每隔几秒就会更新，你可以设置close_inactive为1m。如果日志文件的更新速率不固定，那么可以用多个配置。将close_inactive设置为更低的值意味着文件句柄可以更早关闭。然而，这样做的副作用是，如果harvester关闭了，新的日志行不会实时发送。 关闭文件的时间戳不依赖于文件的修改时间。代替的，Filebeat用一个内部时间戳来反映最后一次读取文件的时间。例如，如果close_inactive被设置为5分钟，那么在harvester读取文件的最后一行以后，这个5分钟的倒计时就开始了。你可以用时间字符串，比如2h（2小时），5m（5分钟）。默认是5m。 close_renamed 当启用此选项时，Filebeat会在重命名文件时关闭文件处理器。默认情况下，harvester保持打开状态并继续读取文件，因为文件处理器不依赖于文件名。如果启用了close_rename选项，并且重命名或者移动的文件不再匹配文件模式的话，那么文件将不会再次被选中。Filebeat将无法完成文件的读取。 close_removed 当启用此选项时，Filebeat会在删除文件时关闭harvester。通常，一个文件只有在它在由close_inactive指定的期间内不活跃的情况下才会被删除。但是，如果一个文件被提前删除，并且你不启用close_removed，则Filebeat将保持文件打开，以确保harvester已经完成。如果由于文件过早地从磁盘中删除而导致文件不能完全读取，请禁用此选项。 close_eof 抓取到达文件末尾后立即关闭文件处理程序。默认情况下，此选项被禁用。 注意：潜在的数据丢失。 请务必阅读并理解此选项的文档。 close_timeout 当启用此选项是，Filebeat会给每个harvester一个预定义的生命时间。无论读到文件的什么位置，只要close_timeout周期到了以后就会停止读取。当你想要在文件上只花费预定义的时间时，这个选项对旧的日志文件很有用。尽管在close_timeout时间以后文件就关闭了，但如果文件仍然在更新，则Filebeat将根据已定义的scan_frequency再次启动一个新的harvester。这个harvester的close_timeout将再次启动，为超时倒计时。 scan_frequencyFilebeat多久检查一次指定路径下的新文件（PS：检查的频率）。例如，如果你指定的路径是 /var/log/* ，那么会以指定的scan_frequency频率去扫描目录下的文件（PS：周期性扫描）。指定1秒钟扫描一次目录，默认值10秒。如果你需要近实时的发送日志行的话，不要设置scan_frequency为一个很低的值，而应该调整close_inactive以至于文件处理器保持打开状态，并不断地轮询你的文件。 更多关于类型为log的输入配置，请参考官方配置文档 四：加载外部配置文件Filebeat可以为输入和模块加载外部配置文件，允许您将配置分成多个较小的配置文件。 4.1 配置input对于输入配置，请在filebeat.yml文件的filebeat.config.inputs部分中指定path选项。 例如：123filebeat.config.inputs: enabled: true path: configs/*.yml 每一个在path下的文件都必须包含一个或多个input定义，例如：123456789- type: log paths: - /var/log/mysql.log scan_frequency: 10s- type: log paths: - /var/log/apache.log scan_frequency: 5s 4.2 模块配置对于模块配置，请在filebeat.yml文件的filebeat.config.modules部分中指定path选项。 默认情况下，Filebeat会加载modules.d目录中启用的模块配置。 例如：123filebeat.config.modules: enabled: true path: $&#123;path.config&#125;/modules.d/*.yml 每个被发现的配置文件必须包含一个或多个模块定义，例如：1234567- module: apache2 access: enabled: true var.paths: [/var/log/apache2/access.log*] error: enabled: true var.paths: [/var/log/apache2/error.log*] 4.3 配置output您可以通过在filebeat.yml配置文件的输出部分中设置选项来配置Filebeat以写入特定输出。 只能定义一个输出。支持的输出如：Elasticsearch, Logstash, Kafka, Redis, File, Console, Cloud。 4.3.1 配置Elasticsearch输出为输出指定Elasticsearch时，Filebeat会使用Elasticsearch HTTP API将事务直接发送到Elasticsearch。例如：123456output.elasticsearch: hosts: ["https://localhost:9200"] index: "filebeat-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;" ssl.certificate_authorities: ["/etc/pki/root/ca.pem"] ssl.certificate: "/etc/pki/client/cert.pem" ssl.key: "/etc/pki/client/cert.key" 为了启用SSL，只需要在hosts下的所有URL添加https即可1234output.elasticsearch: hosts: ["https://localhost:9200"] username: "filebeat_internal" password: "YOUR_PASSWORD" 如果Elasticsearch节点是用IP:PORT的形式定义的，那么添加protocol:https。12345output.elasticsearch: hosts: ["localhost"] protocol: "https" username: "&#123;beatname_lc&#125;_internal" password: "&#123;pwd&#125;" 4.3.2 Elasticsearch输出配置项enabled启用或禁用该输出。默认true。 hostsElasticsearch节点列表。事件以循环顺序发送到这些节点。如果一个节点变得不可访问，那么自动发送到下一个节点。每个节点可以是URL形式，也可以是IP:PORT形式。如果端口没有指定，用9200。1234output.elasticsearch: hosts: ["10.45.3.2:9220", "10.45.3.1:9230"] protocol: https path: /elasticsearch username用于认证的用户名 password用户认证的密码 protocol可选值是：http 或者 https。默认是http。 pathHTTP API调用前的HTTP路径前缀。这对于Elasticsearch监听HTTP反向代理的情况很有用。 headers将自定义HTTP头添加到Elasticsearch输出的每个请求。 index索引名字。（PS：意思是要发到哪个索引中去）。默认是&quot;filebeat-%{[beat.version]}-%{+yyyy.MM.dd}&quot;（例如，”filebeat-6.3.2-2017.04.26”）。如果你想改变这个设置，你需要配置 setup.template.name 和 setup.template.pattern 选项。如果你用内置的Kibana dashboards，你也需要设置setup.dashboards.index选项。 indices索引选择器规则数组，支持条件、基于格式字符串的字段访问和名称映射。如果索引缺失或没有匹配规则，将使用index字段。例如：12345678910output.elasticsearch: hosts: ["http://localhost:9200"] index: "logs-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;" indices: - index: "critical-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;" when.contains: message: "CRITICAL" - index: "error-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;" when.contains: message: "ERR" timeout请求超时时间。默认90秒。 更多关于elasticsearch输出配置请参考官方文档这里只以elasticsearch输出类型为例，更多关于output 输出类型配置，请参考官方配置输出类型 4.4 加载索引模板在filebeat.yml配置文件的setup.template区域指定索引模板，用来设置在Elasticsearch中的映射。如果模板加载是启用的（默认的），Filebeat在成功连接到Elasticsearch后自动加载索引模板。你可以调整下列设置或者覆盖一个已经存在的模板。 setup.template.enabled设为false表示禁用模板加载 setup.template.name模板的名字。默认是filebeat。Filebeat的版本总是跟在名字后面，所以最终的名字是 filebeat-%{[beat.version]} setup.template.pattern模板的模式。默认模式是filebeat-*。例如：12setup.template.name: "filebeat"setup.template.pattern: "filebeat-*" setup.template.fields描述字段的YAML文件路径。默认是 fields.yml。 setup.template.overwrite是否覆盖存在的模板。默认false。 setup.template.settings._source12345setup.template.name: "filebeat"setup.template.fields: "fields.yml"setup.template.overwrite: falsesetup.template.settings: _source.enabled: false 有关filebeat完整的配置文档，请参考(https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-getting-started.html)]]></content>
      <categories>
        <category>elastic</category>
      </categories>
      <tags>
        <tag>filebeat</tag>
        <tag>efk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elastic Stack之X-Pack7.0破解]]></title>
    <url>%2F2019%2F03%2F13%2Felastic-x-pack.html</url>
    <content type="text"><![CDATA[说明： elastic官方在elastic stack 6.4.2版本后就在elasticsearch中内置了X-Pack工具，因此下文破解X-Pack7.0.1的版本也是对应elastic stack7.0.1的版本。而X-Pack内置在elasticsearch包中，以下所有操作都是针对elasticsearch7.0.1包中进行的。 X-Pack是什么X-pack是elasticsearch的一个扩展包，将安全，警告，监视，图形和报告功能捆绑在一个易于安装的软件包中，虽然x-pack被设计为一个无缝的工作，但是你可以轻松的启用或者关闭一些功能。 目前6.2及以下版本只能使用免费版，然而免费版的功能相当少。X-pack 的破解基本思路是先安装正常版本，之后替换破解的jar包来实现，目前只能破解到白金版，但已经够用了。更多版本功能介绍请查看官方版本订阅文档 下载elasticsearch上面提到X-Pack自6.4.2版本后已经内置到elasticsearch中，因此我们需要下载elasticsearch7.0.1最新版。123456# 下载elasticsearch.tar.gz$ mkdir /elk &amp;&amp; cd /elk$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.0.1-linux-x86_64.tar.gz# 解压elasticsearch.tar.gz$ tar zxvf elasticsearch-7.0.1-linux-x86_64.tar.gz 下载完成并且解压后，我们可以查看自带x-pack的模版。12345678910111213141516# 查看x-pack相关的模块$ cd elasticsearch-7.0.1$ ls modules/ | grep x-packx-pack-ccrx-pack-corex-pack-deprecationx-pack-graphx-pack-ilmx-pack-logstashx-pack-mlx-pack-monitoringx-pack-rollupx-pack-securityx-pack-sqlx-pack-watcher 我们需要破解的x-pack-core.7.0.1.jar也就位于x-pack-core目录下12$ ls /elk/elasticsearch-7.0.1/modules/x-pack-core | grep x-packx-pack-core-7.0.1.jar 下载反编译工具Luyten破解X-Pack-core-7.0.1.jar需要反编译工具Luyten，我们可以前往下载地址下载Luyten工具。我们这里下载Luyten.exe windows版本，下载下来后打开，并将x-pack-core.7.0.1.jar文件拖进去，即可展开jar包的源代码了。 修改X-Pack源码文件在Luyten工具中我们需要把2个文件提取出来进行修改。org.elasticsearch.license.LicenseVerifier和org.elasticsearch.xpack.core.XPackBuild。 修改LicenseVerifier.javaLicenseVerifier中有两个静态方法，这就是验证授权文件是否有效的方法，我们把它修改为全部返回true.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091/*如下代码为修改完后的代码,我们这里使用注释将不需要的代码注释掉*/package org.elasticsearch.license;import java.nio.*;import org.elasticsearch.common.bytes.*;import java.security.*;import java.util.*;import org.elasticsearch.common.xcontent.*;import org.apache.lucene.util.*;import org.elasticsearch.core.internal.io.*;import java.io.*;public class LicenseVerifier&#123; public static boolean verifyLicense(final License license, final byte[] publicKeyData) &#123; /* byte[] signedContent = null; byte[] publicKeyFingerprint = null; try &#123; final byte[] signatureBytes = Base64.getDecoder().decode(license.signature()); final ByteBuffer byteBuffer = ByteBuffer.wrap(signatureBytes); final int version = byteBuffer.getInt(); final int magicLen = byteBuffer.getInt(); final byte[] magic = new byte[magicLen]; byteBuffer.get(magic); final int hashLen = byteBuffer.getInt(); publicKeyFingerprint = new byte[hashLen]; byteBuffer.get(publicKeyFingerprint); final int signedContentLen = byteBuffer.getInt(); signedContent = new byte[signedContentLen]; byteBuffer.get(signedContent); final XContentBuilder contentBuilder = XContentFactory.contentBuilder(XContentType.JSON); license.toXContent(contentBuilder, (ToXContent.Params)new ToXContent.MapParams((Map)Collections.singletonMap("license_spec_view", "true"))); final Signature rsa = Signature.getInstance("SHA512withRSA"); rsa.initVerify(CryptUtils.readPublicKey(publicKeyData)); final BytesRefIterator iterator = BytesReference.bytes(contentBuilder).iterator(); BytesRef ref; while ((ref = iterator.next()) != null) &#123; rsa.update(ref.bytes, ref.offset, ref.length); &#125; return rsa.verify(signedContent); &#125; catch (IOException ex) &#123;&#125; catch (NoSuchAlgorithmException ex2) &#123;&#125; catch (SignatureException ex3) &#123;&#125; catch (InvalidKeyException e) &#123; throw new IllegalStateException(e); &#125; finally &#123; if (signedContent != null) &#123; Arrays.fill(signedContent, (byte)0); &#125; &#125;*/ return true; &#125; public static boolean verifyLicense(final License license) &#123; /* byte[] publicKeyBytes; try &#123; final InputStream is = LicenseVerifier.class.getResourceAsStream("/public.key"); try &#123; final ByteArrayOutputStream out = new ByteArrayOutputStream(); Streams.copy(is, (OutputStream)out); publicKeyBytes = out.toByteArray(); if (is != null) &#123; is.close(); &#125; &#125; catch (Throwable t) &#123; if (is != null) &#123; try &#123; is.close(); &#125; catch (Throwable t2) &#123; t.addSuppressed(t2); &#125; &#125; throw t; &#125; &#125; catch (IOException ex) &#123; throw new IllegalStateException(ex); &#125; //return verifyLicense(license, publicKeyBytes); */ return true; &#125;&#125; 修改XPackBuild.javaXPackBuild中最后一个静态代码块中 try的部分全部删除，这部分会验证jar包是否被修改.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/*如下代码为修改完后的代码,我们这里使用注释将不需要的代码注释掉*/package org.elasticsearch.xpack.core;import org.elasticsearch.common.io.*;import java.net.*;import org.elasticsearch.common.*;import java.nio.file.*;import java.io.*;import java.util.jar.*;public class XPackBuild&#123; public static final XPackBuild CURRENT; private String shortHash; private String date; @SuppressForbidden(reason = "looks up path of xpack.jar directly") static Path getElasticsearchCodebase() &#123; final URL url = XPackBuild.class.getProtectionDomain().getCodeSource().getLocation(); try &#123; return PathUtils.get(url.toURI()); &#125; catch (URISyntaxException bogus) &#123; throw new RuntimeException(bogus); &#125; &#125; XPackBuild(final String shortHash, final String date) &#123; this.shortHash = shortHash; this.date = date; &#125; public String shortHash() &#123; return this.shortHash; &#125; public String date() &#123; return this.date; &#125; static &#123; final Path path = getElasticsearchCodebase(); String shortHash = null; String date = null; Label_0109: &#123;/* if (path.toString().endsWith(".jar")) &#123; try &#123; final JarInputStream jar = new JarInputStream(Files.newInputStream(path, new OpenOption[0])); try &#123; final Manifest manifest = jar.getManifest(); shortHash = manifest.getMainAttributes().getValue("Change"); date = manifest.getMainAttributes().getValue("Build-Date"); jar.close(); &#125; catch (Throwable t) &#123; try &#123; jar.close(); &#125; catch (Throwable t2) &#123; t.addSuppressed(t2); &#125; throw t; &#125; break Label_0109; &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; &#125;*/ shortHash = "Unknown"; date = "Unknown"; &#125; CURRENT = new XPackBuild(shortHash, date); &#125;&#125; 生成.class文件上述LicenseVerifier.java和XPackBuild.java两个文件在本地电脑windows修改完成后，我们需要将其复制到elasticsearch服务器上并编译成class文件，然后打包到x-pack-core-7.0.1.jar中。我们这里将这2个文件放到了/root目录下。12345678910# 编译LicenseVerifier.java$ javac -cp "/elk/elasticsearch-7.0.1/lib/elasticsearch-7.0.1.jar:/elk/elasticsearch-7.0.1/lib/lucene-core-8.0.0.jar:/elk/elasticsearch-7.0.1/modules/x-pack-core/x-pack-core-7.0.1.jar:/elk/elasticsearch-7.0.1/modules/x-pack-core/netty-common-4.1.32.Final.jar:/elk/elasticsearch-7.0.1/lib/elasticsearch-core-7.0.1.jar" /root/LicenseVerifier.java# 编译XPackBuild.java$ javac -cp "/elk/elasticsearch-7.0.1/lib/elasticsearch-7.0.1.jar:/elk/elasticsearch-7.0.1/lib/lucene-core-8.0.0.jar:/elk/elasticsearch-7.0.1/modules/x-pack-core/x-pack-core-7.0.1.jar:/elk/elasticsearch-7.0.1/modules/x-pack-core/netty-common-4.1.32.Final.jar:/elk/elasticsearch-7.0.1/lib/elasticsearch-core-7.0.1.jar" /root/XPackBuild.java# 查看编译后的文件$ ls /root | grep .classLicenseVerifier.classXPackBuild.class 替换LicenseVerifier.class和XPackBuild.class我们把/elk/elasticsearch-7.0.1/modules/x-pack-core目录下的x-pack-core-7.0.1.jar提取出来，放到一个临时的/elk/x-pack目录中。12345678$ cp /elk/elasticsearch-7.0.1/modules/x-pack-core/x-pack-core-7.0.1.jar /elk/x-pack$ cd /elk/x-pack# 解压x-pack-core-7.0.1.jar$ jar -xvf x-pack-core-7.0.1.jar# 替换.class文件$ cp /root/XPackBuild.class /elk/x-pack/org/elasticsearch/xpack/core/$ cp /root/LicenseVerifier.class /elk/x-pack/org/elasticsearch/license/ 打包新x-pack-core-7.0.1.jar文件123$ cd /elk/x-pack$ rm -rf x-pack-core-7.0.1.jar # 删除临时拷贝过来的源文件$ jar cvf x-pack-core-7.0.1.jar . 至此在/elk/x-pack目录下会新生成一个x-pack-core-7.0.1.jar文件。也就是破解后的文件。 替换x-pack-core-7.0.1.jar文件我们将新生成的x-pack-core-7.0.1.jar文件文件替换掉源x-pack-core-7.0.1.jar文件。12345678910111213141516171819cp /elk/x-pack/x-pack-core-7.0.1.jar /elk/elasticsearch-7.0.1/modules/x-pack-core/rm -rf /elk/x-pack # 完成文件替换后该目录既可以删除了``` ## 申请License完成以上步骤后，我们还需要去elastic官网申请一个license, [License申请地址](https://license.elastic.co/registration)，申请完成后，下载下来的License格式为json格式。并将该License的`type`、`expiry_date_in_millis`、`max_nodes`分别修改成`platinum`、`2524579200999`、`1000`。如下：```json&#123;"license": &#123; "uid":"537c5c48-c1dd-43ea-ab69-68d209d80c32", "type":"platinum", "issue_date_in_millis":1558051200000, "expiry_date_in_millis":2524579200999, "max_nodes":1000, "issued_to":"pyker", "issuer":"Web Form", "signature":"AAAAAwAAAA3fIq7NLN3Blk2olVjbAAABmC9ZN0hjZDBGYnVyRXpCOW5Bb3FjZDAxOWpSbTVoMVZwUzRxVk1PSmkxaktJRVl5MUYvUWh3bHZVUTllbXNPbzBUemtnbWpBbmlWRmRZb25KNFlBR2x0TXc2K2p1Y1VtMG1UQU9TRGZVSGRwaEJGUjE3bXd3LzRqZ05iLzRteWFNekdxRGpIYlFwYkJiNUs0U1hTVlJKNVlXekMrSlVUdFIvV0FNeWdOYnlESDc3MWhlY3hSQmdKSjJ2ZTcvYlBFOHhPQlV3ZHdDQ0tHcG5uOElCaDJ4K1hob29xSG85N0kvTWV3THhlQk9NL01VMFRjNDZpZEVXeUtUMXIyMlIveFpJUkk2WUdveEZaME9XWitGUi9WNTZVQW1FMG1DenhZU0ZmeXlZakVEMjZFT2NvOWxpZGlqVmlHNC8rWVVUYzMwRGVySHpIdURzKzFiRDl4TmM1TUp2VTBOUlJZUlAyV0ZVL2kvVk10L0NsbXNFYVZwT3NSU082dFNNa2prQ0ZsclZ4NTltbU1CVE5lR09Bck93V2J1Y3c9PQAAAQCjNd8mwy8B1sm9rGrgTmN2Gjm/lxqfnTEpTc+HOEmAgwQ7Q1Ye/FSGVNIU/enZ5cqSzWS2mY8oZ7FM/7UPKVQ4hkarWn2qye964MW+cux54h7dqxlSB19fG0ZJOJZxxwVxxi8iyJPUSQBa+QN8m7TFkK2kVmP+HnhU7mGUrqXt3zTk5d3pZw3QBQ/Rr3wmSYC5pxV6/o2UHFgu1OPDcX+kEb+UZtMrVNneR+cEwyx7o5Bg3rbKC014T+lMtt69Y080JDI5KfHa7e9Ul0c3rozIL975fP45dU175D4PKZy98cvHJgtsCJF3K8XUZKo2lOcbsWzhK2mZ5kFp0BMXF3Hs", "start_date_in_millis":1558051200000 &#125;&#125; 我们将过期时间写到2050年，type改为platinum 白金版，这样我们就会拥有全部的x-pack功能。 配置elasticsearch安全协议完成以上所有操作在启动elasticsearch前，我们需要配置elasticsearch的SSL/TLS安全协议,如果不配置的话，需要禁止security才能配置License。当License配置完成后我们需要再开启security，并开启SSL\TLS。12345678# 加载License到elasticsearch之前操作$ echo "xpack.security.enabled: false" &gt;&gt; /elk/elasticsearch-7.0.1/config/elasticsearch.yml$ ./bin/elasticsearch -d # 后台方式启动elasticsearch# 加载License到elasticsearch之后操作$ echo "xpack.security.transport.ssl.enabled: true" &gt;&gt; /elk/elasticsearch-7.0.1/config/elasticsearch.yml$ sed -i 's/xpack.security.enabled: false/xpack.security.enabled: true/g' /elk/elasticsearch-7.0.1/config/elasticsearch.yml$ kill -9 13023 &amp;&amp; ./bin/elasticsearch -d # 重启elasticsearch 加载License到elasticsearch123$ curl -XPUT -u elastic 'http://192.168.20.210:9200/_xpack/license' -H "Content-Type: application/json" -d @license.jsonEnter host password for user 'elastic': # 提示输入elastic用户密码，当前无密码，所以直接回车&#123;"acknowledged":true,"license_status":"valid"&#125; # license写入成功 查看License12345678910111213141516$ curl -XGET -u elastic:tWbWZc7NE3wYqS6DvSu4 http://192.168.20.210:9200/_license&#123; "license" : &#123; "status" : "active", "uid" : "537c5c48-c1dd-43ea-ab69-68d209d80c32", "type" : "platinum", "issue_date" : "2019-05-17T00:00:00.000Z", "issue_date_in_millis" : 1558051200000, "expiry_date" : "2049-12-31T16:00:00.999Z", "expiry_date_in_millis" : 2524579200999, "max_nodes" : 1000, "issued_to" : "pyker", "issuer" : "Web Form", "start_date_in_millis" : 1558051200000 &#125;&#125; 由结果可以看出x-pack到期时间为2049-12-31，破解完成。也可以在kibana web页面管理中查看破解详情。 设置密码现在我们可以使用x-pack铂金版的所有功能了，例如密码安全验证功能。1234567891011121314151617181920212223$ ./bin/elasticsearch-setup-passwords autoInitiating the setup of passwords for reserved users elastic,apm_system,kibana,logstash_system,beats_system,remote_monitoring_user.The passwords will be randomly generated and printed to the console.Please confirm that you would like to continue [y/N]yChanged password for user apm_systemPASSWORD apm_system = 24UtJKbNI1UqHUQkKPZYChanged password for user kibanaPASSWORD kibana = 8SSZMisIY0NZFMCS6wv9Changed password for user logstash_systemPASSWORD logstash_system = rFhWkYzayIUZVl8VIunJChanged password for user beats_systemPASSWORD beats_system = U1B4O5SKrSEatqDQRsQzChanged password for user remote_monitoring_userPASSWORD remote_monitoring_user = zdpj7HqO02yRXZR9Bwa2Changed password for user elasticPASSWORD elastic = tWbWZc7NE3wYqS6DvSu4]]></content>
      <categories>
        <category>elastic</category>
      </categories>
      <tags>
        <tag>x-pack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[下一代监控Prometheus初识]]></title>
    <url>%2F2019%2F01%2F12%2Fprometheus.html</url>
    <content type="text"><![CDATA[Prometheus介绍Prometheus 是一套开源的系统监控报警框架。它启发于 Google 的 borgmon 监控系统，由工作在 SoundCloud 的 google 前员工在 2012 年创建，作为社区开源项目进行开发，并于 2015 年正式发布。2016 年，Prometheus 正式加入 Cloud Native Computing Foundation，成为受欢迎度仅次于 Kubernetes 的项目。 什么是TSDBTSDB(Time Series Database)时序列数据库，我们可以简单的理解为一个优化后用来处理时间序列数据的软件，并且数据中的数组是由时间进行索引的。 Prometheus作为TSDB具有以下特点： 具有由指标名称和键/值对标识的时间序列数据的多维度数据模型。 PromQL灵活的查询语言。 不依赖分布式存储，单个服务器节点是自主的。 通过基于HTTP的pull方式采集时序数据。 可以通过中间网关（Pushgateway）进行时序列数据推送。 通过服务发现或者静态配置来发现目标服务对象。 支持多种多样的图表和界面展示，比如Grafana等。 Prometheus组成和架构Prometheus 生态圈中包含了多个组件，其中许多组件是可选的： Prometheus Server：它是Prometheus组件中的核心部分，负责实现对监控数据的获取，存储及查询。Prometheus Server可以通过静态配置管理监控目标，也可以配合使用Service Discovery的方式动态管理监控目标，并从这些监控目标中获取数据。其次Prometheus Sever需要对采集到的数据进行存储，Prometheus Server本身就是一个实时数据库，将采集到的监控数据按照时间序列的方式存储在本地磁盘当中。Prometheus Server对外提供了自定义的PromQL，实现对数据的查询以及分析。另外Prometheus Server的联邦集群能力可以使其从其他的Prometheus Server实例中获取数据。 Exporters：Exporter将监控数据采集的端点通过HTTP服务的形式暴露给Prometheus Server，将其转化为Prometheus支持的格式，Prometheus Server通过访问该Exporter提供的Endpoint端点，即可以获取到需要采集的监控数据。可以将Exporter分为2类： 直接采集：这一类Exporter直接内置了对Prometheus监控的支持，比如cAdvisor，Kubernetes，Etcd，Gokit等，都直接内置了用于向Prometheus暴露监控数据的端点。 间接采集：原有监控目标并不直接支持Prometheus，因此需要通过Prometheus提供的Client Library编写该监控目标的监控采集程序。如：Mysql Exporter，JMX Exporter，Consul Exporter等。 AlertManager：在Prometheus Server中支持基于Prom QL创建告警规则，如果满足Prom QL定义的规则，则会产生一条告警。当AlertManager从 Prometheus server 端接收到 alerts后，会进行去除重复数据，分组，并路由到对收的接受方式，发出报警。常见的接收方式有：电子邮件，pagerduty，webhook 等。 PushGateway: 主要用于短期的jobs。由于这类 jobs 存在时间较短，可能在 Prometheus 来 pull 之前就消失了。为此，这次 jobs 可以直接向 Prometheus中间网关推送它们的 metrics。这种方式主要用于服务层面的 metrics，对于机器层面的 metrices，需要使用 node exporter。（PushGatway类似zabbix proxy） Prometheus 架构图从上图可以看出，Prometheus 的主要模块包括：Prometheus server, exporters, Pushgateway, PromQL, Alertmanager 以及图形界面。Prometheus的基本原理是通过HTTP协议周期性抓取被监控组件的状态，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。输出被监控组件信息的HTTP接口被叫做exporter 。目前互联网公司常用的组件大部分都有exporter可以直接使用，比如Varnish、Haproxy、Nginx、MySQL、Linux系统信息(包括磁盘、内存、CPU、网络等等)。 Prometheus工作流程 Prometheus server 定期从配置好的 jobs 或者 exporters 中拉取 metrics，或者从Pushgateway 拉取metrics，或者从其他的 Prometheus server 中拉 metrics。 Prometheus server 在本地存储收集到的 metrics，并运行已定义好的 alert.rules，通过一定规则进行清理和整理数据，并把得到的结果存储到新的时间序列中。记录新的时间序列或者向 Alertmanager 推送警报。 Prometheus通过PromQL和其他API可视化地展示收集的数据。Prometheus支持很多方式的图表可视化，例如Grafana、自带的Promdash以及自身提供的模版引擎等等。Prometheus还提供HTTP API的查询方式，自定义所需要的输出。 Prometheus相关概念数据模型Prometheus 中存储的数据为时间序列，是由 metric 的名字和一系列的标签（键值对）唯一标识的，不同的标签则代表不同的时间序列。给定度量标准名称和一组标签，通常使用此表示法标识时间序列：1&lt;metric name&gt;&#123;&lt;label name&gt;=&lt;label value&gt;, ...&#125; 例如：度量名称的时间序列api_http_requests_total和标签method=”POST”，并handler=”/messages”可以这样写：1api_http_requests_total&#123;method="POST", handler="/messages"&#125; 四种Metric类型 Counter 一种累加的 metric，计数器可以用于记录只会增加不会减少的指标类型,比如记录：应用请求的总数，cpu使用时间，结束的任务数， 出现的错误数等。 对于Counter类型的指标，只包含一个inc()方法，用于计数器+1。 Gauge 一种常规的 metric，可以任意加减。 常用于反应应用的当前状态。典型的应用如：温度，运行的 goroutines 的个数。对于Gauge指标的对象则包含两个主要的方法inc()以及dec(),用户添加或者减少计数。 Histogram 自带buckets区间用于统计分布直方图，主要用于在指定分布范围内(Buckets)记录大小或者事件发生的次数。典型的应用如：请求持续时间，响应大小。 Summary Summary和Histogram非常类型相似，都可以统计事件发生的次数或者大小，以及其分布情况。Summary和Histogram都提供了对于事件的计数_count以及值的汇总_sum。 因此使用_count,和_sum时间序列可以计算出相同的内容，例如http每秒的平均响应时间：rate(basename_sum[5m]) / rate(basename_count[5m])。 同时Summary和Histogram都可以计算和统计样本的分布情况，比如中位数，9分位数等等。其中 0.0&lt;= 分位数Quantiles &lt;= 1.0。 不同在于Histogram可以通过histogram_quantile函数在服务器端计算分位数。 而Sumamry的分位数则是直接在客户端进行定义。因此对于分位数的计算。 Summary在通过PromQL进行查询时有更好的性能表现，而Histogram则会消耗更多的资源。 Jobs 和 Instances在Prometheus术语中，您可以scrape的目标称为instance，通常对应于单个进程。具有相同目的的instance集合，例如，为可伸缩性或可靠性而复制的流程称为Job。例如：12345job: api-server instance 1: 1.2.3.4:5670 instance 2: 1.2.3.4:5671 instance 3: 5.6.7.8:5670 instance 4: 5.6.7.8:5671 当Prometheus进行scrape目标时，它会自动将job标签和instance标签附加到scrape到的时间序列中，用于识别被抓取的目标，如果这些标签中的任何一个已存在于已删除数据中，则行为取决于honor_labels配置选项。 表达式语言类型Prometheus表达式或子表达式可以评估为一下四种类型之一： 即时向量（Instant vector） - 包含每个时间序列单个样品的一组时间序列，共享相同的时间戳 范围向量（Range vector） - 包含一个范围内数据点的一组时间序列 标量（Scalar） - 一个简单的数字浮点值 字符串（String） - 一个简单的字符串值；当前未使用 时间序列选择器即时向量选择即时向量选择器允许选择一组时间序列，或者某个给定的时间戳的样本数据。下面这个例子选择了具有http_requests_total的时间序列：1http_requests_total 你可以通过附加一组标签，并用{}括起来，来进一步筛选这些时间序列。下面这个例子只选择有http_requests_total名称的、有prometheus工作标签的、有canary组标签的时间序列：1http_requests_total&#123;job="prometheus",group="canary"&#125; 另外，也可以也可以将标签值反向匹配，或者对正则表达式匹配标签值。下面列举匹配操作符： =：选择正好相等的字符串标签 !=：选择不相等的字符串标签 =~：选择匹配正则表达式的标签（或子标签） !~：选择不匹配正则表达式的标签（或子标签） 例如，选择staging、testing、development环境下的，GET之外的HTTP方法的http_requests_total的时间序列： 1http_requests_total&#123;environment=~"staging|testing|development",method!="GET"&#125; 范围向量选择范围向量表达式正如即时向量表达式一样运行，但是前者返回从当前时刻开始的一定时间范围的时间序列集合回来。语法是，在一个向量表达式之后添加[]来表示时间范围，持续时间用数字表示，后接下面单元之一： s：seconds m：minutes h：hours d：days w：weeks y：years 在下面这个例子中，我们选择最后5分钟的记录，metric名称为http_requests_total、作业标签为prometheus的时间序列的所有值：1http_requests_total&#123;job="prometheus"&#125;[5m] 偏移量Offset所述offset可以改变时间为查询中的个别时刻和范围矢量偏移。例如，以下表达式返回http_requests_total相对于当前查询评估时间的过去5分钟值 ：1http_requests_total offset 5m 同样适用于范围向量。这将返回http_requests_total一周前的5分钟费率 ：1rate(http_requests_total[5m] offset 1w) 操作符关于操作符的说明，请参考官网操作符说明 函数关于函数的说明，请参考官网函数解释 Prometheus的安装下载prometheus二进制包1$ wget https://github.com/prometheus/prometheus/releases/download/v2.9.1/prometheus-2.9.1.linux-amd64.tar.gz 解压prometheus压缩包1$ tar zxvf prometheus-2.9.1.linux-amd64.tar.gz 将prometheus放到/usr/local目录下1$ mv prometheus-2.9.1.linux-amd64 /usr/local/prometheus 验证版本12345$ /usr/local/prometheus/prometheus --version prometheus, version 2.9.1 (branch: HEAD, revision: ad71f2785fc321092948e33706b04f3150eee44f) build user: root@09f919068df4 build date: 20190416-17:50:04 go version: go1.12.4 配置prometheus用户12$ groupadd prometheus$ useradd -g prometheus -s /sbin/nologin prometheus 创建prometheus数据目录1$ mkdir -p /var/lib/prometheus 创建prometheus的systemctl文件123456789101112131415$ cat &gt; /usr/lib/systemd/system/prometheus.service &lt;&lt; EOF[Unit]Description=PrometheusDocumentation=https://prometheus.io/After=network.target[Service]Type=simpleUser=prometheusExecStart=/usr/local/prometheus/prometheus --config.file=/usr/local/prometheus/prometheus.yml --storage.tsdb.path=/var/lib/prometheusRestart=on-failure[Install]WantedBy=multi-user.targetEOF prometheus权限配置12345678# prometheus主程序$ chown -R prometheus:prometheus /usr/local/prometheus/# prometheus数据目录$ chown -R prometheus:prometheus /var/lib/prometheus/# prometheus启动文件$ chown prometheus:prometheus /usr/lib/systemd/system/prometheus.service 启动服务并设为开机启动12$ systemctl start prometheus$ systemctl enable prometheus Prometheus.yml配置说明Prometheus通过命令行参数和配置文件进行配置。虽然命令行参数配置了不可变的系统参数（例如存储位置，保留在磁盘和内存中的数据量等），但配置文件定义了与抓取job及其instance相关的所有内容，以及哪些规则文件的加载。Prometheus可以在运行时重新加载其配置。如果新配置格式不正确，则不会应用更改。它有两种方式： 通过向prometheus进程发送SIGHUP信号 向Prometheus进程发送/-/reload的POST请求，curl -X POST http://localdns:9090/-/reload 配置文件要指定要加载的配置文件，请使用该--config.file标志。该文件以YAML格式编写，由下面描述的方案定义。括号表示参数是可选的。对于非列表参数，该值设置为指定的默认值。 以下为一个简单的prometheus.yml示例： 123456789101112131415161718192021222324252627282930# Prometheus全局配置项global: scrape_interval: 15s # 设定抓取数据的周期，默认为1min evaluation_interval: 15s # 设定更新rules文件的周期，默认为1min scrape_timeout: 15s # 设定抓取数据的超时时间，默认为10s external_labels: # 额外的属性，会添加到拉取得数据并存到数据库中 monitor: 'codelab_monitor'# Alertmanager配置alerting: alertmanagers: - static_configs: - targets: ["localhost:9093"] # 设定alertmanager和prometheus交互的接口，即alertmanager监听的ip地址和端口# rule配置，首次读取默认加载，之后根据evaluation_interval设定的周期加载rule_files: - "alertmanager_rules.yml" - "prometheus_rules.yml"# scrape配置scrape_configs:- job_name: 'prometheus' # job_name默认写入timeseries的labels中，可以用于查询使用 scrape_interval: 15s # 抓取周期，默认采用global配置 static_configs: # 静态配置 - targets: ['localdns:9090'] # prometheus所要抓取数据的地址，即instance实例项- job_name: 'example-random' static_configs: - targets: ['localhost:8080'] 更多关于prometheus配置文件参数以及自动发现规则，请参考官方prometheus配置]]></content>
      <categories>
        <category>prometheus</category>
      </categories>
      <tags>
        <tag>prometheus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat8配置APR模式]]></title>
    <url>%2F2018%2F12%2F14%2Ftomcat-apr.html</url>
    <content type="text"><![CDATA[tomcat三种模式Tomcat Connector运行有三种模式： bio默认的模式,同步阻塞，性能非常低下,没有经过任何优化处理和支持. nio同步非阻塞，利用java的异步io护理技术,noblocking IO技术,想运行在该模式下，直接修改server.xml里的Connector节点,修改protocol为protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot;启动后,就可以生效。 apr安装起来最困难,但是从操作系统级别来解决异步的IO问题,大幅度的提高性能. Tomcat apr也是在Tomcat上运行高并发应用的首选模式。必须要安装apr、apr-util和native，nio修改模式，修改protocol为org.apache.coyote.http11.Http11AprProtocol，直接启动就支持apr。 安装配置APR模式本文所有步骤的前提是已经可以正常运行tomcat程序，JDK已安装的环境。 Tomcat配置apr模式依赖以下包,（ 版本根据自己需求选择 ）123apr-1.6.2apr-util-1.6.0openssl-1.0.2l 下载依赖包123$ wget http://mirror.bit.edu.cn/apache//apr/apr-1.6.2.tar.gz$ wget http://mirror.bit.edu.cn/apache//apr/apr-util-1.6.0.tar.gz$ wget https://www.openssl.org/source/openssl-1.0.2l.tar.gz 安装各个依赖包123456789101112#安装apr$ tar zxvf apr-1.6.2.tar.gz$ cd apr-1.6.2$ ./configure --prefix=/usr/local/apr &amp;&amp; make &amp;&amp; make install#安装apr-util$ tar zxvf apr-util-1.6.0.tar.gz$ cd apr-util-1.6.0$ ./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr &amp;&amp; make &amp;&amp; make install#安装openss-1.0.2l$ tar zxvf openssl-1.0.2l.tar.gz$ cd openssl-1.0.2l$ ./config --prefix=/usr/local/openssl shared zlib &amp;&amp; make &amp;&amp; make install 1、安装apr-util前请确认是否安装了 expat-devel 包，如没安装请安装，不然会报错。yum install expat-devel 2、检查openssl是否安装成功 /usr/local/openssl/bin/openssl version -a 显示1.0.2l版本为成功 安装tomcat-native123$ tar zxvf /usr/local/tomcat8/bin/tomcat-native.tar.gz$ cd /usr/local/tomcat8/bin/tomcat-native-1.2.12-src/native$ ./configure --with-apr=/usr/local/apr --with-java-home=/usr/local/java8/ --with-ssl=/usr/local/openssl/ &amp;&amp; make &amp;&amp; make install 配置tomcat支持apr配置apr库文件123456#方式1：配置坏境变量：$ echo "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/apr/lib" &gt;&gt; /etc/profile$ echo "export LD_RUN_PATH=$LD_RUN_PATH:/usr/local/apr/lib" &gt;&gt; /etc/profile &amp;&amp; source /etc/profile##方式2：catalina.sh脚本文件：在注释行# Register custom URL handlers下添加一行 $ JAVA_OPTS="$JAVA_OPTS -Djava.library.path=/usr/local/apr/lib" 修改tomcat server.xml文件&lt;Connector port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11AprProtocol&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; 启动Tomcat12$ cd /usr/local/tomcat8/bin$ ./startup.sh 查看Tomcat模式运行1$ cat /usr/local/tomcat8/logs/catalina.out 如果有显示[http-apr-8080] 说明配置APR模式成功。 java.net.ConnectException异常处理有时候在安装完tomcat后，停止tomcat会的会有如下异常，该异常可能和JDK有关系。 解决办法：进入JDK目录，编辑java.security文件,(注释掉原来的securerandom.source行，新增此行，保存即可 )12$ vi /usr/local/java8/jre/lib/security/java.securitysecurerandom.source=file:/dev/./urandom]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 常 用 命 令]]></title>
    <url>%2F2018%2F11%2F30%2Fgit-command.html</url>
    <content type="text"><![CDATA[以下总结了日常常用的git指令方便读者学习和测试，如果想了解更多git指令相关的命令和参数，请参考Git指令指南1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889git init # 初始化本地git仓库（创建新仓库）git config --global user.name "xxx" # 配置用户名git config --global user.email "xxx@xxx.com" # 配置邮件git config --global color.ui true # git status等命令自动着色git config --global color.status autogit config --global color.diff autogit config --global color.branch autogit config --global color.interactive autogit clone git+ssh://git@192.168.53.168/VT.git # clone远程仓库git status # 查看当前版本状态（是否修改）git add xyz # 添加xyz文件至暂存区git add . # 增加当前子目录下所有更改过的文件至暂存区git commit -m 'xxx' # 提交git commit --amend -m 'xxx' # 合并上一次提交（用于反复修改）git commit -am 'xxx' # 将add和commit合为一步git rm xxx # 删除暂存区中的文件git rm -r * # 递归删除git log # 显示提交日志git log -1 # 显示最近1次commit的日志 -n为最近n次git log -5 --oneline # 极简显示最近5次的commit日志git log --stat # 显示提交日志及相关变动文件git log --graph --pretty=oneline --abbrev-commit # 以图形表示分支合并历史git show dfb02e6e4f2f7b573337763e5c0013802e392818 # 显示某个提交的详细内容git show dfb02 # 可只用commitid的前几位git show HEAD # 显示HEAD提交日志git show HEAD^ # 显示HEAD的父的提交日志git show HEAD~10 # 显示前面第10次的提交日志git show -s --pretty=raw 2be7fcb476git tag # 显示已存在的taggit tag -a v2.0 -m 'xxx' # 增加v2.0的taggit show v2.0 # 显示v2.0的日志及详细内容git log v2.0 # 显示v2.0的日志git diff # 显示所有未添加至暂存区的变更git diff --cached # 显示所有已添加index但还未commit的变更git diff HEAD^ # 比较与上一个版本的差异git diff HEAD -- ./lib # 比较与HEAD版本lib目录的差异git diff origin/master..master # 比较远程分支master与本地master分支的区别git diff origin/master..master --stat # 只显示差异的文件，不显示具体内容git remote add origin git+ssh://git@192.168.53.168/VT.git # 增加远程地址定义（用于push/pull/fetch）git branch # 显示本地分支git branch --contains 50089 # 显示包含提交50089的分支git branch -a # 显示所有分支git branch -r # 显示所有原创分支，包括本地和远程跟踪分支git branch --merged # 显示所有已合并到当前分支的分支git branch --no-merged # 显示所有未合并到当前分支的分支git branch -m master master_copy # 本地分支重命名git checkout -b master_copy # 从当前分支创建新分支master_copy并检出git checkout -b dev origin/dev # 拉取远程dev分支到本地dev分支git checkout features/performance # 检出已存在的features/performance分支git checkout --track hotfix/BJP93 # 检出远程分支hotfix/BJP93并创建本地跟踪分支git checkout v2.0 # 检出版本v2.0git checkout -b devel origin/develop # 从远程分支develop创建新本地分支devel并检出git checkout -- README # 将README文件回退到更新前(用于修改错误回退)git merge --no-ff origin/master # 合并远程master分支至当前分支git cherry-pick ff44785404a8e # 合并提交ff44785404a8e的修改git push origin master # 将当前master分支push到远程master分支git push origin :hotfixes/BJVEP933 # 删除远程仓库的hotfixes/BJVEP933分支git push --tags # 把所有tag推送到远程仓库git push --set-upstream origin dev # 推送本地当前分支到远程dev分支git fetch # 获取所有远程分支（不更新本地分支，需merge）git fetch --prune # 获取所有原创分支并清除服务器上已删掉的分支git fetch origin dev:tmp # 拉取远程dev分支到本地tmp分支git pull origin master # 获取远程分支master并merge到当前分支git mv README README2 # 重命名文件README为README2git reset --hard 2f3c # 将当前版本重置为2f3c（常用于merge回退）git rebasegit branch -d hotfix # 删除分支hotfix (该分支已合并到其他分支)git branch -D hotfix/BJP93 # 强制删除分支hotfix/BJP93git ls-files # 列出git 暂存区包含的文件git show-branch # 图示当前分支历史git show-branch --all # 图示所有分支历史git whatchanged # 显示提交历史对应的文件修改git revert dfb02e6e4 # 撤销提交dfb02e6e4git ls-tree HEAD # 内部命令：显示某个git对象git rev-parse v2.0 # 内部命令：显示某个ref对于的SHA1 HASHgit reflog # 显示历史所有提交，包括孤立节点git show HEAD@&#123;5&#125;git show master@&#123;yesterday&#125; # 显示master分支昨天的状态git log --pretty=format:'%h %s' --graph # 图示提交日志git stash # 暂存当前修改，将所有至为HEAD状态git stash list # 查看所有暂存git stash show -p stash@&#123;0&#125; # 参考第一次暂存git stash apply stash@&#123;0&#125; # 应用第一次暂存git stash drop # 删除stash记录git stash pop # 等价于 git stash apply和git stash dropgit grep "delete from" # 文件中搜索文本“delete from”git grep -e '#define' --and -e SORT_DIRENTgit gcgit fsck git fetch 和git pull 的差别 git fetch 相当于是从远程获取最新到本地，不会自动merge，如下指令： 1234git fetch # 将远程仓库的当前分支下载到本地当前branch中git diff origin/master # 比较本地的master分支和origin/master分支的差别git diff HEAD FETCH_HEAD # 和上条命令一样效果git merge origin/master # 进行合并 也可以用以下指令： 123git fetch origin master:tmp # 从远程仓库master分支获取最新，在本地建立tmp分支git diff tmp # 将当前分支和tmp進行對比git merge tmp # 合并tmp分支到当前分支 git pull：相当于是从远程获取最新版本并merge到本地 1git pull origin master git pull 相当于从远程获取最新版本并merge到本地 在实际使用中，git fetch更安全一些]]></content>
      <categories>
        <category>CI/CD</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab-CE社区版安装]]></title>
    <url>%2F2018%2F11%2F29%2Finstall-gitlab-ce.html</url>
    <content type="text"><![CDATA[常见的git环境有git web版和gitolite版本，gitolite权限控制强大，但功能不完善，而git web(gitlab)虽然权限没有像gitolite分的那么细，但是功能异常强大，不仅支持SSH KEY、web密码方式还有CI/CD，PIPELINE功能。所以下文将介绍如何在公司内网搭建私有的gitlab环境。 GitLab官网强烈建议安装Omnibus软件包，因为它安装更快，更易于升级，并且包含增强其他方法所没有的可靠性的功能。我们还强烈建议至少4GB的可用内存` 来运行GitLab。 GitLab的安装Omnibus方式安装安装并配置必要的依赖项在CentOS 7（和RedHat / Oracle / Scientific Linux 7）上，执行以下命令。1sudo yum install -y curl policycoreutils-python openssh-server 更新GitLab国内yum源1234567$ cat &gt; /etc/yum.repos.d/gitlab-ce.repo &lt;&lt; EOF[gitlab-ce]name=Gitlab CE Repositorybaseurl=https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el$releasever/gpgcheck=0enabled=1 EOF 安装GitLab-CE包12$ yum makecache$ yum install gitlab-ce -y 配置GitLab-CE域名和邮件通知配置文件为/etc/gitlab/gitlab.rb123456789101112131415#修改external_url 为你gitlab的访问域名$ vim /etc/gitlab/gitlab.rbexternal_url 'http://git.ipyker.com'#添加gitlab邮件通知配置（大约在/etc/gitlab/gitlab.rb文件的517行）gitlab_rails['smtp_enable'] = true gitlab_rails['smtp_address'] = "smtp.ipyker.com"gitlab_rails['smtp_port'] = 465gitlab_rails['smtp_user_name'] = "gitlab@ipyker.com"gitlab_rails['smtp_password'] = "mypasswd"gitlab_rails['smtp_authentication'] = "login"gitlab_rails['smtp_enable_starttls_auto'] = true gitlab_rails['smtp_tls'] = true gitlab_rails['gitlab_email_from'] = 'gitlab@ipyker.com'gitlab_rails['smtp_domain'] = "ipyker.com" GitLab安装完后，工作目录默认为：/var/opt/gitlab、/opt/gitlab，配置文件目录为：/etc/gitlab GitLab管理重载配置信息1$ gitlab-ctl reconfigure 启动1$ gitlab-ctl start 停止1$ gitlab-ctl stop 重启1$ gitlab-ctl restart 登陆第一次用域名登录gitlab，需要为root用户修改密码，root用户也是gitlab的超级管理员，gitlab也支持修改中文界面，如下图所示 更多关于gitlab配置信息参数，请参考官网GitLab配置文件 Docker方式安装GitLab docker 镜像gitlab-ce镜像存放在docker官方仓库中。 GitLab Docker镜像是GitLab的单个镜像，在单个容器上运行所有必要的服务。在以下示例中，我们使用GitLab CE的镜像。如果要使用最新的RC映像，请使用gitlab/gitlab-ce:rc 用于GitLab CEGitLab Docker镜像可以多种方式运行： 在Docker Engine中运行映像 将GitLab安装到群集中 使用docker-compose安装GitLab 本文档以第一种方式在docker中运行，如你需要高可用可以用第二种，甚至是通过kubenetes deplyment部署pod方式安装。 先决条件需要先安装docker，请参考docker-ce安装 运行gitlab-ce容器123456789$ docker run -d \ --hostname gitlab.example.com \ --publish 443:443 --publish 80:80 --publish 22:22 \ --name gitlab \ --restart always \ --volume /srv/gitlab/config:/etc/gitlab \ --volume /srv/gitlab/logs:/var/log/gitlab \ --volume /srv/gitlab/data:/var/opt/gitlab \ gitlab/gitlab-ce:latest docker run 命令将直接拉取镜像和运行容器，相当于运行docker pull和docker start两条命令。gitlab-ce容器将制定域名，开放的端口，以及容器挂载本地的文件系统，所有GitLab数据都将存储为子目录 /srv/gitlab/。restart系统重启后，容器将自动运行。 宿主目录 docker目录 用途 /srv/gitlab/data /var/opt/gitlab 用于存储应用数据 /srv/gitlab/logs /var/log/gitlab 用于存储日志 /srv/gitlab/config /etc/gitlab 用于存储GitLab配置文件 配置girlab-ce此容器使用官方的Omnibus GitLab软件包，因此所有配置都在docker唯一的配置文件中完成/etc/gitlab/gitlab.rb，也可以通过修改挂载卷文件来完成。 要访问GitLab的配置文件，您可以在正在运行的容器的上下文中启动shell会话。这将允许您浏览所有目录并使用您喜欢的文本编辑器：1$ docker exec -it gitlab /bin/bash 打开后，请/etc/gitlab/gitlab.rb 确保将指针设置external_url 为有效的URL。 此外您可以通过将环境变量添加GITLAB_OMNIBUS_CONFIG 到docker run命令来预配置GitLab Docker映像。此变量可以包含任何gitlab.rb设置，并在加载容器gitlab.rb文件之前进行评估。这样，您可以轻松配置GitLab的外部URL，从Omnibus GitLab模板进行任何数据库配置或任何其他选项 。注意：包含的设置GITLAB_OMNIBUS_CONFIG 不会写入gitlab.rb配置文件，而是在加载时进行评估。这是一个设置外部URL并在启动容器时启用LFS的示例：12345678910$ docker run -d \ --hostname gitlab.example.com \ --env GITLAB_OMNIBUS_CONFIG="external_url 'http://my.domain.com/'; gitlab_rails['lfs_enabled'] = true;" \ --publish 443:443 --publish 80:80 --publish 22:22 \ --name gitlab \ --restart always \ --volume /srv/gitlab/config:/etc/gitlab \ --volume /srv/gitlab/logs:/var/log/gitlab \ --volume /srv/gitlab/data:/var/opt/gitlab \ gitlab/gitlab-ce:latest 要从GitLab接收电子邮件，您必须配置 SMTP设置，因为GitLab Docker映像没有安装SMTP服务器。默认也为HTTP，还可以启动https访问。 重启gitlab-ce完成所需的所有更改后，需要重新启动容器才能重新配置GitLab：1$ docker restart gitlab 手动配置HTTPS默认情况下，omnibus-gitlab不使用HTTPS。如果要为gitlab.example.com启用HTTPS，请将以下语句添加到/etc/gitlab/gitlab.rb ：1external_url "https://gitlab.example.com" 因为在我们的例子中，主机名是“gitlab.example.com”，所以创建/etc/gitlab/ssl 目录并在那里复制密钥和证书。123$ sudo mkdir -p /etc/gitlab/ssl$ sudo chmod 700 /etc/gitlab/ssl$ sudo cp gitlab.example.com.key gitlab.example.com.crt /etc/gitlab/ssl/ 重新加载配置，当重新配置完成时，您的GitLab实例应该可以访问https://gitlab.example.com。1$ gitlab-ctl reconfigure 如果certificate.key文件有设置密码，Nginx在sudo gitlab-ctl reconfigure 执行时不会要求输入密码。在这种情况下，Omnibus GitLab将无声地失败，没有错误消息。要从密钥中删除密码，请使用以下命令： openssl rsa -in certificate_before.key -out certificate_after.key 。]]></content>
      <categories>
        <category>CI/CD</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql状态信息查询]]></title>
    <url>%2F2018%2F10%2F22%2Fmysql-status.html</url>
    <content type="text"><![CDATA[Mysql在安装运行后，其性能并不一定为实际需要的性能，因此我们常常会在mysql运行一段时间后进行mysql的性能状态查询来了解mysql服务器的性能指标，从而来优化mysql。 查看mysql性能状态命令查看mysql全局状态12mysql&gt; show global status;可以列出MySQL服务器运行各种状态值，另外，查询MySQL服务器配置信息语句。 12mysql&gt; show variables;可以查看Mysql系统变量及其值。 12mysql&gt; show processlist;可以查看Mysql当前连接数的进程以及状态。 慢查询123456789101112131415mysql&gt; show variables like '%slow%'; +------------------+-------+ | Variable_name | Value | +------------------+-------+ | log_slow_queries | ON | | slow_launch_time | 2 | +------------------+-------+ mysql&gt; show global status like '%slow%'; +---------------------+-------+ | Variable_name | Value | +---------------------+-------+ | Slow_launch_threads | 0 | | Slow_queries | 4148 | +---------------------+-------+ 配置中打开了记录慢查询，执行时间超过2秒的即为慢查询，系统显示有4148个慢查询，你可以分析慢查询日志，找出有问题的SQL语句，慢查询时间不宜设置过长，否则意义不大，最好在5秒以内，如果你需要微秒级别的慢查询，可以考虑给MySQL打补丁 ，记得找对应的版本。 打开慢查询日志可能会对系统性能有一点点影响，如果你的MySQL是主-从结构，可以考虑打开其中一台从服务器的慢查询日志，这样既可以监控慢查询，对系统性能影响又小。 连接数经常会遇见”MySQL: ERROR 1040: Too many connections”的情况，一种是访问量确实很高，MySQL服务器抗不住，这个时候就要考虑增加从服务器分散读压力，另外一种情况是MySQL配置文件中max_connections值过小：123456mysql&gt; show variables like 'max_connections'; +-----------------+-------+ | Variable_name | Value | +-----------------+-------+ | max_connections | 256 | +-----------------+-------+ 这台MySQL服务器最大连接数是256，然后查询一下服务器响应的最大连接数：1mysql&gt; show global status like ‘Max_used_connections’; MySQL服务器过去的最大连接数是245，没有达到服务器连接数上限256，应该没有出现1040错误，比较理想的设置是：Max_used_connections / max_connections * 100% ≈ 85% 最大连接数占上限连接数的85%左右，如果发现比例在10%以下，MySQL服务器连接数上限设置的过高了。 Key_buffer_sizekey_buffer_size是对MyISAM表性能影响最大的一个参数，下面一台以MyISAM为主要存储引擎服务器的配置：123456mysql&gt; show variables like ‘key_buffer_size’; +-----------------+------------+ | Variable_name | Value | +-----------------+------------+ | key_buffer_size | 536870912 | +-----------------+------------+ 分配了512MB内存给key_buffer_size，我们再看一下key_buffer_size的使用情况：1234567mysql&gt; show global status like 'key_read%'; +------------------------+-------------+ | Variable_name | Value | mysql +------------------------+-------------+ | Key_read_requests | 27813678764 | | Key_reads | 6798830 | +------------------------+-------------+ 一共有27813678764个索引读取请求，有6798830个请求在内存中没有找到直接从硬盘读取索引，计算索引未命中缓存的概率：key_cache_miss_rate = Key_reads / Key_read_requests * 100%比如上面的数据，key_cache_miss_rate为0.0244%，4000个索引读取请求才有一个直接读硬盘，已经很BT了,key_cache_miss_rate在0.1%以下都很好(每1000个请求有一个直接读硬盘)，如果key_cache_miss_rate在0.01%以下的话，key_buffer_size分配的过多，可以适当减少。MySQL服务器还提供了key_blocks_*参数：1234567mysql&gt; show global status like 'key_blocks_u%'; +------------------------+-------------+ | Variable_name | Value | +------------------------+-------------+ | Key_blocks_unused | 0 | | Key_blocks_used | 413543 | +------------------------+-------------+ Key_blocks_unused表示未使用的缓存簇(blocks)数，Key_blocks_used表示曾经用到的最大的blocks数，比如这台服务器，所有的缓存都用到了，要么增加key_buffer_size，要么就是过渡索引了，把缓存占满了。比较理想的设置：Key_blocks_used / (Key_blocks_unused + Key_blocks_used) * 100% ≈ 80% 临时表12345678mysql&gt; show global status like 'created_tmp%'; +-------------------------+---------+ | Variable_name | Value | +-------------------------+---------+ | Created_tmp_disk_tables | 21197 | | Created_tmp_files | 58 | | Created_tmp_tables | 1771587 | +-------------------------+---------+ 每次创建临时表，Created_tmp_tables增加，如果是在磁盘上创建临时表，Created_tmp_disk_tables也增加,Created_tmp_files表示MySQL服务创建的临时文件文件数，比较理想的配置是：Created_tmp_disk_tables / Created_tmp_tables * 100% &lt;= 25%比如上面的服务器Created_tmp_disk_tables / Created_tmp_tables * 100% = 1.20%, 应该相当好了。我们再看一下MySQL服务器对临时表的配置：1234567mysql&gt; show variables where Variable_name in ('tmp_table_size', 'max_heap_table_size'); +---------------------+-----------+ | Variable_name | Value | +---------------------+-----------+ | max_heap_table_size | 268435456 | | tmp_table_size | 536870912 | +---------------------+-----------+ 只有256MB以下的临时表才能全部放内存，超过的就会用到硬盘临时表。 Open Table1234567mysql&gt; show global status like 'open%tables%'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | Open_tables | 919 | | Opened_tables | 1951 | +---------------+-------+ Open_tables表示打开表的数量，Opened_tables表示打开过的表数量，如果Opened_tables数量过大，说明配置中table_cache(5.1.3之后这个值叫做table_open_cache)值可能太小，我们查询一下服务器table_cache值：123456mysql&gt; show variables like 'table_cache'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | table_cache | 2048 | +---------------+-------+ 比较合适的值为：Open_tables / Opened_tables * 100% &gt;= 85%, 及Open_tables / table_cache * 100% &lt;= 95%` 六、进程使用情况123456789mysql&gt; show global status like ‘Thread%’; +-------------------+-------+ | Variable_name | Value | +-------------------+-------+ | Threads_cached | 46 | | Threads_connected | 2 | | Threads_created | 570 | | Threads_running | 1 | +-------------------+-------+ 如果我们在MySQL服务器配置文件中设置了thread_cache_size， 当客户端断开之后，服务器处理此客户的线程将会缓存起来以响应下一个客户而不是销毁(前提是缓存数未达上限)。Threads_created表示创建过的线程数，如果发现Threads_created值过大的话，表明MySQL服务器一直在创建线程，这也是比较耗资源，可以适当增加配置文件中thread_cache_size值，查询服务器thread_cache_size配置：123456mysql&gt; show variables like 'thread_cache_size'; +-------------------+-------+ | Variable_name | Value | +-------------------+-------+ | thread_cache_size | 64 | +-------------------+-------+ 示例中的服务器还是挺健康的。 查询缓存(query cache)12345678910111213mysql&gt; show global status like 'qcache%'; +-------------------------+-----------+ | Variable_name | Value | +-------------------------+-----------+ | Qcache_free_blocks | 22756 | | Qcache_free_memory | 76764704 | | Qcache_hits | 213028692 | | Qcache_inserts | 208894227 | | Qcache_lowmem_prunes | 4010916 | | Qcache_not_cached | 13385031 | | Qcache_queries_in_cache | 43560 | | Qcache_total_blocks | 111212 | +-------------------------+-----------+ MySQL查询缓存变量解释：Qcache_free_blocks： 缓存中相邻内存块的个数。数目大说明可能有碎片。FLUSH QUERY CACHE会对缓存中的碎片进行整理，从而得到一个空闲块。Qcache_free_memory： 缓存中的空闲内存。Qcache_hits： 每次查询在缓存中命中时就增大Qcache_inserts： 每次插入一个查询时就增大。命中次数除以插入次数就是不中比率。Qcache_lowmem_prunes： 缓存出现内存不足并且必须要进行清理以便为更多查询提供空间的次数。这个数字最好长时间来看;如果这个数字在不断增长，就表示可能碎片非常严重，或者内存很少。(上面的 free_blocks和free_memory可以告诉您属于哪种情况)Qcache_not_cached： 不适合进行缓存的查询的数量，通常是由于这些查询不是 SELECT 语句或者用了now()之类的函数。Qcache_queries_in_cache： 当前缓存的查询(和响应)的数量。Qcache_total_blocks： 缓存中块的数量。 我们再查询一下服务器关于query_cache的配置：12345678910mysql&gt; show variables like 'query_cache%'; +------------------------------+-----------+ | Variable_name | Value | +------------------------------+-----------+ | query_cache_limit | 2097152 | | query_cache_min_res_unit | 4096 | | query_cache_size | 203423744 | | query_cache_type | ON | | query_cache_wlock_invalidate | OFF |+——————————+———–+ 各字段的解释：query_cache_limit： 超过此大小的查询将不缓存query_cache_min_res_unit： 缓存块的最小大小query_cache_size： 查询缓存大小query_cache_type： 缓存类型，决定缓存什么样的查询，示例中表示不缓存 select sql_no_cache 查询query_cache_wlock_invalidate： 当有其他客户端正在对MyISAM表进行写操作时，如果查询在query cache中，是否返回cache结果还是等写操作完成再读表获取结果。query_cache_min_res_unit 的配置是一柄”双刃剑”，默认是4KB，设置值大对大数据查询有好处，但如果你的查询都是小数据查询，就容易造成内存碎片和浪费。 查询缓存碎片率 = Qcache_free_blocks / Qcache_total_blocks * 100%如果查询缓存碎片率超过20%，可以用FLUSH QUERY CACHE整理缓存碎片，或者试试减小query_cache_min_res_unit，如果你的查询都是小数据量的话。查询缓存利用率 = (query_cache_size - Qcache_free_memory) / query_cache_size * 100%查询缓存利用率在25%以下的话说明query_cache_size设置的过大，可适当减小;查询缓存利用率在80%以上而且Qcache_lowmem_prunes &gt; 50的话说明query_cache_size可能有点小，要不就是碎片太多。查询缓存命中率 = (Qcache_hits - Qcache_inserts) / Qcache_hits * 100%示例服务器 查询缓存碎片率 = 20.46%，查询缓存利用率 = 62.26%，查询缓存命中率 = 1.94%，命中率很差，可能写操作比较频繁吧，而且可能有些碎片。 排序使用情况123456789mysql&gt; show global status like 'sort%'; +-------------------+------------+ | Variable_name | Value | +-------------------+------------+ | Sort_merge_passes | 29 | | Sort_range | 37432840 | | Sort_rows | 9178691532 | | Sort_scan | 1860569 | +-------------------+------------+ Sort_merge_passes 包括两步。MySQL 首先会尝试在内存中做排序，使用的内存大小由系统变量 Sort_buffer_size 决定，如果它的大小不够把所有的记录都读到内存中，MySQL 就会把每次在内存中排序的结果存到临时文件中，等 MySQL 找到所有记录之后，再把临时文件中的记录做一次排序。这再次排序就会增加 Sort_merge_passes。实际上，MySQL 会用另一个临时文件来存再次排序的结果，所以通常会看到 Sort_merge_passes 增加的数值是建临时文件数的两倍。因为用到了临时文件，所以速度可能会比较慢，增加 Sort_buffer_size 会减少 Sort_merge_passes 和 创建临时文件的次数。但盲目的增加 Sort_buffer_size 并不一定能提高速度。另外，增加read_rnd_buffer_size(3.2.3是record_rnd_buffer_size)的值对排序的操作也有一点的好处，参见：http://www.mysqlperformanceblog.com/2007/07/24/what-exactly-is-read_rnd_buffer_size/ 文件打开数(open_files)123456789101112mysql&gt; show global status like 'open_files'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | Open_files | 1410 | +---------------+-------+ mysql&gt; show variables like 'open_files_limit'; +------------------+-------+ | Variable_name | Value | +------------------+-------+ | open_files_limit | 4590 | +------------------+-------+ 比较合适的设置：Open_files / open_files_limit * 100% &lt;= 75% 表锁情况1234567mysql&gt; show global status like 'table_locks%'; +-----------------------+-----------+ | Variable_name | Value | +-----------------------+-----------+ | Table_locks_immediate | 490206328 | | Table_locks_waited | 2084912 | +-----------------------+-----------+ Table_locks_immediate 表示立即释放表锁数，Table_locks_waited 表示需要等待的表锁数，如果Table_locks_immediate / Table_locks_waited &gt; 5000，最好采用InnoDB引擎，因为InnoDB是行锁而MyISAM是表锁，对于高并发写入的应用InnoDB效果会好些。示例中的服务器Table_locks_immediate / Table_locks_waited = 235，MyISAM就足够了。 表扫描情况123456789101112131415161718mysql&gt; show global status like 'handler_read%'; +-----------------------+-------------+ | Variable_name | Value | +-----------------------+-------------+ | Handler_read_first | 5803750 | | Handler_read_key | 6049319850 | | Handler_read_next | 94440908210 | | Handler_read_prev | 34822001724 | | Handler_read_rnd | 405482605 | | Handler_read_rnd_next | 18912877839 | +-----------------------+-------------+ mysql&gt; show global status like 'com_select'; +---------------+-----------+ | Variable_name | Value | +---------------+-----------+ | Com_select | 222693559 | +---------------+-----------+ 计算表扫描率：表扫描率 = Handler_read_rnd_next / Com_select如果表扫描率超过4000，说明进行了太多表扫描，很有可能索引没有建好，增加read_buffer_size值会有一些好处，但最好不要超过8MB。 查看Mysql状态QPS/TPS/缓存命中率QPS(每秒Query量)12QPS = Questions(or Queries) / seconds mysql &gt; show global status like 'Question%'; TPS(每秒事务量)123TPS = (Com_commit + Com_rollback) / seconds mysql &gt; show global status like 'Com_commit'; mysql &gt; show global status like 'Com_rollback'; key Buffer 命中率12345mysql&gt;show global status like 'key%'; key_buffer_read_hits = (1-key_reads / key_read_requests) * 100% key_buffer_write_hits = (1-key_writes / key_write_requests) * 100% ``` #### InnoDB Buffer命中率 mysql&gt; show status like ‘innodb_buffer_pool_read%’;innodb_buffer_read_hits = (1 - innodb_buffer_pool_reads / innodb_buffer_pool_read_requests) * 100%12#### Query Cache命中率 ` mysql&gt; show status like ‘Qcache%’;Query_cache_hits = (Qcahce_hits / (Qcache_hits + Qcache_inserts )) * 100%;1#### Table Cache状态量 mysql&gt; show global status like ‘open%’;123比较 open_tables 与 opend_tables 值 #### Thread Cache 命中率 mysql&gt; show global status like ‘Thread%’;mysql&gt; show global status like ‘Connections’;Thread_cache_hits = (1 - Threads_created / connections ) * 100%1#### 锁定状态 mysql&gt; show global status like ‘%lock%’;Table_locks_waited/Table_locks_immediate=0.3% 如果这个比值比较大的话，说明表锁造成的阻塞比较严重Innodb_row_lock_waits innodb行锁，太大可能是间隙锁造成的1#### 复制延时量 mysql &gt; show slave status查看延时时间1#### Tmp Table 状况(临时表状况) mysql &gt; show status like ‘Create_tmp%’;Created_tmp_disk_tables/Created_tmp_tables比值最好不要超过10%，如果Created_tmp_tables值比较大，可能是排序句子过多或者是连接句子不够优化1#### Binlog Cache 使用状况 mysql &gt; show status like ‘Binlog_cache%’;如果Binlog_cache_disk_use值不为0 ，可能需要调大 binlog_cache_size大小1#### Innodb_log_waits 量 mysql &gt; show status like ‘innodb_log_waits’;Innodb_log_waits值不等于0的话，表明 innodb log buffer 因为空间不足而等待123456### Mysql查看死锁和解除锁所谓死锁&lt;DeadLock&gt;：是指两个或两个以上的进程在执行过程中,因争夺资源而造成的一种互相等待的现象,若无外力作用，它们都将无法推进下去.此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。表级锁不会产生死锁.所以解决死锁主要还是针对于最常用的InnoDB。解除正在死锁的状态有两种方法：* **第一种**1.查询是否锁表 mysql&gt; show OPEN TABLES where In_use &gt; 0;12.查询进程（如果您有SUPER权限，您可以看到所有线程。否则，您只能看到您自己的线程） mysql&gt; show processlist;13.杀死进程id（就是上面命令的id列） mysql&gt; kill id12* **第二种**1.查看下在锁的事务 mysql&gt; SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX;12.杀死进程id（就是上面命令的trx_mysql_thread_id列） mysql&gt; kill 线程ID1234567&gt;例子：查出死锁进程：mysql&gt; SHOW PROCESSLIST杀掉进程: mysql&gt; KILL 420821;其它关于查看死锁的命令： 1：查看当前的事务mysql&gt; SELECT FROM INFORMATION_SCHEMA.INNODB_TRX;2：查看当前锁定的事务mysql&gt; SELECT FROM INFORMATION_SCHEMA.INNODB_LOCKS;3：查看当前等锁的事务mysql&gt; SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;` 后记：文中提到一些数字都是参考值，了解基本原理就可以，除了MySQL提供的各种status值外，操作系统的一些性能指标也很重要，比如常用的top,iostat等，尤其是iostat，现在的系统瓶颈一般都在磁盘IO上，关于iostat的使用.在尝试学习新的语言之前先理解这门语言的设计原理能够让你在探索这门新语言时保持一个清醒而且开发的状态。]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix服务器监控之《配置Zabbix报警》（六）]]></title>
    <url>%2F2018%2F09%2F13%2Fzabbox-alert.html</url>
    <content type="text"><![CDATA[上一篇 我们已经配置过zabbix的触发器了，也知道当触发器阀值达到时，应该有一个动作，而这个动作可以是执行脚本，也可以是发邮件报警通知用户。那么本篇我们将再进行对zabbix的报警进行配置。 报警媒介类型当zabbix中的某些被监控指标出现异常时，zabbix会通过哪种方式通知运维人员呢？是通过邮件呢，还是通过短信呢，或者是通过其他方式呢？今天我们就来聊聊zabbix的报警方式，无论是通过邮件报警还是通过短信报警，无非都是通过某种”媒介”将报警信息传递给收信人，所以在zabbix中，报警方式被称为”报警媒介”，那么，zabbix都支持哪些报警媒介呢，我们一起来看看。zabbix支持的报警媒介如下： Email：邮件，这是最常用也是最传统的一种报警媒介，邮件报警，zabbix通过配置好的SMTP邮件服务器向用户发送对应的报警信息。 Script：脚本，当zabbix中的某些监控项出现异常时，也可以调用自定义的脚本进行报警，脚本的使用就比较灵活，具体怎样报警全看你的脚本怎么写。 SMS：短信，如果想要使用短信报警，则需要依赖短信网关（貌似需要北美的运行商）。 Jabber：即时通讯服务。 Ez Texting：商业的，收费的短信服务（北美运营商提供服务）。 第三方的onealert 定义报警媒介 下面我们通过配置邮件报警媒介来进行配置说明 点击管理-报警媒介类型-创建媒介类型，输入完信息后，点击添加之后，我们可以在报警媒介类型中看到已经添加的报警类型，点击右边的测试，可以测试当前邮件配置是否正常，如果配置正常你将收到测试的邮件。到此处，我们已经成功的定义了一个”报警媒介”，从此，我们可以通过这个媒介，向用户发送报警信息了。 配置用户接受报警通知媒介但是，如果想要某个zabbix用户能够接收到从”email报警媒介”发送过来的报警，还需要进一步配置，比如，当”Admin”用户想要通过”email”报警媒介接收警报时，则必须能够”适配”这种媒介，如果”Admin”用户没有使用”email媒介”的能力，那么”Admin”用户将无法接收到由”email媒介”发出的报警信息。我们应该怎样让用户能够对应的报警媒介呢，配置步骤如下。 点击管理-用户-Admin-报警媒介到此处，我们已经成功的定义了一个用户能接受对应”报警媒介”的邮件通知了。 配置告警动作 在zabbix中创建一个动作，前文中我们已经创建了用于监控磁盘根目录使用率的监控项,以及对应的触发器，现在，我们需要创建一个动作，与监控项和触发器结合起来一起使用。 打开zabbix控制台，点击配置-动作-事件源-触发器-创建动作点击操作点击恢复操作完成以上配置，点击添加即可添加一个对该触发器的动作。 上图报警的宏如下，更多的宏参考官方宏使用 1234567891011121314151617181920212223# 故障时默认标题：故障&#123;TRIGGER.STATUS&#125;,服务器:&#123;HOSTNAME&#125;发生: &#123;TRIGGER.NAME&#125;故障!消息内容：告警主机:&#123;HOSTNAME&#125;告警时间:&#123;EVENT.DATE&#125; &#123;EVENT.TIME&#125;告警等级:&#123;TRIGGER.SEVERITY&#125;告警信息: &#123;TRIGGER.NAME&#125;告警项目:&#123;TRIGGER.KEY&#125;问题详情:&#123;ITEM.NAME&#125;:&#123;ITEM.VALUE&#125;当前状态:&#123;TRIGGER.STATUS&#125;:&#123;ITEM.VALUE&#125;事件ID:&#123;EVENT.ID&#125;恢复时默认标题：恢复&#123;TRIGGER.STATUS&#125;, 服务器:&#123;HOSTNAME&#125;: &#123;TRIGGER.NAME&#125;已恢复!消息内容：告警主机:&#123;HOSTNAME&#125;告警时间:&#123;EVENT.DATE&#125; &#123;EVENT.TIME&#125;告警等级:&#123;TRIGGER.SEVERITY&#125;告警信息: &#123;TRIGGER.NAME&#125;告警项目:&#123;TRIGGER.KEY&#125;问题详情:&#123;ITEM.NAME&#125;:&#123;ITEM.VALUE&#125;当前状态:&#123;TRIGGER.STATUS&#125;:&#123;ITEM.VALUE&#125;事件ID:&#123;EVENT.ID&#125; 模拟告警在此之前我们已经总结了主机、监控项、触发器、事件、动作等相关知识点，但是到目前为止，还没有真正的收到过任何一个zabbix中的警告，那么这次，我们就在之前的基础上，刻意的让磁盘根目录使用率这个监控项达到指定的阈值，看看能否正常的收到报警信息。在模拟前，我们先看看之前磁盘根目录使用率是多少，使用率0.39% 阀值5%。好了，现在我们进入到被监控主机的根分区，在根分区中创建一个大文件，提高磁盘使用率。1234567891011121314[root@k8s nginx]# dd if=/dev/zero of=/testfile count=20 bs=1G记录了20+0 的读入记录了20+0 的写出21474836480字节(21 GB)已复制，44.8811 秒，478 MB/秒[root@k8s nginx]# df -h文件系统 容量 已用 可用 已用% 挂载点/dev/sda5 296G 22G 275G 8% /devtmpfs 3.9G 0 3.9G 0% /devtmpfs 3.9G 0 3.9G 0% /dev/shmtmpfs 3.9G 18M 3.9G 1% /runtmpfs 3.9G 0 3.9G 0% /sys/fs/cgroup/dev/sda2 200G 33M 200G 1% /home/dev/sda1 297M 107M 191M 36% /boottmpfs 797M 0 797M 0% /run/user/0 此时我们的根分区使用率已经达到了8%，超过了触发器设置的阀值5%，我们看看下图，（这里显示的是7.16%和df -h命令8%差一点点是由于linux只显示整数，小数点增1位）我们配置的是1分钟检测一次，因此我们能很快收到故障邮件通知报警。如下此时我们删掉dd命令生成的testfile文件进行恢复测试。1234567891011[root@k8s /]# rm -rf testfile [root@k8s /]# df -h文件系统 容量 已用 可用 已用% 挂载点/dev/sda5 296G 1.2G 295G 1% /devtmpfs 3.9G 0 3.9G 0% /devtmpfs 3.9G 0 3.9G 0% /dev/shmtmpfs 3.9G 18M 3.9G 1% /runtmpfs 3.9G 0 3.9G 0% /sys/fs/cgroup/dev/sda2 200G 33M 200G 1% /home/dev/sda1 297M 107M 191M 36% /boottmpfs 797M 0 797M 0% /run/user/0 那么很快我们将收到监控项恢复的邮件通知至此，我们已经完成了初步的zabbix使用了。也可以用户监控环境去监控服务了，当然监控项、触发器等还需要根据实际情况去配置。]]></content>
      <categories>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix服务器监控之《配置Zabbix触发器》（五）]]></title>
    <url>%2F2018%2F09%2F13%2Fzabbix-trigger.html</url>
    <content type="text"><![CDATA[上一篇 我们已经配置过zabbix的监控项了，本篇我们将再进行对监控项的触发器配置。而在配置zabbix触发器前，我们再来理解一下触发器，事件，动作。 触发器（Triggers）：我们可以把zabbix的触发器理解成一个条件表达式，我们往往通过触发器定义被监控项的阈值，当触发器对应的表达式被满足时，则代表被监控项达到了我们设定的阈值，也就意味着发生了我们不想要遇到的问题，换句话说，当监控项的值处于合理范围时，触发器不会被触发，当监控项的值超出合理范围（即达到阈值），触发器则会被触发，当触发器被触发时，往往代表着出现了问题，触发器未被触发时，其的状态为”OK”,当触发器被触发时，触发器的状态为”Problem”，当被监控项的值达到阈值时，触发器的状态从”OK”变为”Problem”,当监控项的值再次回归到合理范围时，触发器的状态会从”Problem”转换回”OK”。 事件（Events）：当触发器的状态发生改变时，则会产生对应的”事件”，当然，由触发器的状态改变而产生的事件被称为”触发器事件”，zabbix中，事件分为几种类型，除了”触发器事件”，还有一些别的事件，此处为了方便描述，暂且不提及他们，我们可以把”事件”大概理解成一个重要的事情。 动作（Actions）：当某个事件产生时，需要对应的处理措施，这种处理措施被称为动作。 配置触发器 我们还是以上节监控nginx1主机根目录的监控项为例进行创建触发器 点击配置-主机进入对应主机上的触发器后，点击右上角的创建触发器根据下图配置触发器信息，触发器也可以在模版的监控项中创建，也可以在主机中创建。点击添加后，我们可以在对应主机中查看根目录使用率的触发器最后，我们在监测-最新数据中过滤显示根目录使用率监控项，点击图形，可以看到该监控项已经有触发器了。至此，一个关于磁盘根目录使用率超过5%后的触发器就配置完成。然而当这个监控项的值达到我们指定的阈值5%时，就会产生某个”事件”，以便我们采取后续的措施，而这个后续操作可以是命令，也可以是报警通知。 触发器表达式说明如下图，触发器的表达式生成方式 其实，上面的5个部分我们可以通过如下语法表示，如下语法描述了一个触发器的条件表达式的基本结构，{&lt;server&gt;:&lt;key&gt;.&lt;function&gt;(&lt;parameter&gt;)}&lt;operator&gt;&lt;constant&gt; 下面我们对触发器的表达式语法进行说明，如：{web server1:vfs.fs.size[/,pused].last()}&gt;5，那么，我们把该表达式分解成5个部分，从而方便我们去理解。 web server1：表示主机名称。 vfs.fs.size[/,pused]：表示对应主机上某个监控项对应的key。 last()：对应上述语法中的()，last()被我们称之为函数。 \&gt;：对应了上述语法中的，其实就是常用的比较操作符或者运算操作符。 5：表示用于设定监控项对应的阈值。 function除了last()常用的有 avg、count、change、sum、max、min、date等，看这些函数的名字你也能猜出其大概的作用，无非就是获取监控项的值的最大值，最小值，值的总和，或者平均值等，如果你想要了解它们，可以登录zabbix的官网查看触发器表达式函数在线手册 而函数的参数格式变化则比较少，如果参数值前面带有”#”作为前缀,则表示次数，比如avg(#10),则表示最近10次监控项的值的平均值，如果参数值前面没有”#”作为前缀，则表示时间，比如sum(300),表示300秒内监控项的值的总和，max(#20)则表示最近20次监控项的值的最大值，min(600)则表示最近10分钟内监控项的值的最小值，但是需要注意，last(0)的含义与last(#1)的含义相同，都表示最近一次。有的函数还支持使用第二个参数，比如avg(1h,1d) ，表示一天前的一小时内的监控项的值的平均值，假设现在的时间是5点，avg(1h)可以理解为4点到5点之间的监控项的值的平均值，而avg(1h,1d) 中的1d表示时间偏移量，那么avg(1h,1d)可以理解为昨天4点到5点的监控项的值的平均值。 operator，其实就是常用的比较操作符或者运算操作符，由于zabbix版本的不同，操作符可能有所变化，zabbix4.0支持的操作符可以操作符参考在线手册。]]></content>
      <categories>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix服务器监控之《配置Zabbix监控项》（四）]]></title>
    <url>%2F2018%2F09%2F12%2Fzabbix-item.html</url>
    <content type="text"><![CDATA[通过上一篇 我们已经进行了对zabbix的agent端安装，以及通过手动、自动发现、自动注册的方式将agent端监控到server端，也知道应用集、监控项、触发器是什么概念。那么本篇我们将实际配置zabbix的监控项。 监控项说明在Zabbix中，我们要监控的某一个指标，被称为“监控项(item)”，比如监控磁盘的使用率，这就属于一个监控项，如果要获取到”监控项”的相关信息，我们则要执行一个命令，但是我们不能直接调用命令，而是通过一个”别名”去调用命令，这个”命令别名”在zabbix中被称为”键”(key)，所以，在zabbix中，如果我们想要获取到一个”监控项”的值，则需要有对应的”键”，通过”键”能够调用相应的命令，获取到对应的监控信息，而监控项的key、键值又可以为带参数和不带参数两种，下面我们将分别对其进行说明配置。 不参数键值监控项键值中只有键名的键称为不带参数的键值，如system.cpu.switches 带参数的键值监控项键值中有键名和参数的键值，如vfs.fs.size[fs,&lt;mode&gt;]，对于vfs.fs.size[fs,&lt;mode&gt;]这个键来说，vfs.fs.size就是键名，[fs,&lt;mode&gt;]就是这个键需要的参数。而[fs,&lt;mode&gt;]这两个参数中，fs是不可省参数，mode是可省参数。 配置监控项监控项可以单独配置在主机中，使该监控项专属于该主机。也可以配置在相应模版中，然后主机对该模版进行链接，从而使该主机也具有该模版的所有监控项。 在通常配置zabbix监控时，我们通常将监控项配置在模版中，这样方便调度和管理。(以下配置也采用监控项配置在模版里) 系统默认自带一些模版，这些模版有监控CPU的、内存的、http的等等，如果没有自己需要的也可以自定义模版，应用集、监控项、触发器等。 配置不带参数的监控项点击配置-模版-Template OS Linux 找到Template OS Linux模版 点击Template OS Linux模版中的监控项-创建监控项，完成下图设置后添加现在我们想要在Template OS Linux模版中创建CPU的上下文切换的监控项，那么我们可以在此界面进行如下配置。现在我们可以看到在Template OS Linux模版中已经有我们刚刚创建的名为Context switches per second监控项此时我们让主机和该模版关联，使主机能使用该模版的监控项， 点击配置-主机-模版，把Template OS Linux模版链接到主机中完成以上操作后，我们对主机进行cpu上下文监控也就配置完成，可以等待2分钟让zabbix进行数据采集后，在监测-最新数据通过过滤器过滤出CPU上下文切换的监控项最新数据也可以点击旁边的图形，查看图形信息 配置带参数的监控项点击Template OS Linux模版中的监控项-创建监控项，由于配置项已在上面说明，我们只阐述不同的地方由于Template OS Linux模版在上面已经加入到nginx1主机了，所以我们这里就不做主机和模版关联了最后等待几分钟在监测-最新数据通过过滤器过滤出磁盘使用率的监控项最新数据 关于这个键到底怎么使用呢，类似和fs和mode这两个参数分别代表了什么呢，我们可以通过官网帮助手册，查看这些”键”的含义与使用方法。]]></content>
      <categories>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix服务器监控之《安装Zabbix Agent》（三）]]></title>
    <url>%2F2018%2F09%2F11%2Fzabbix-agent.html</url>
    <content type="text"><![CDATA[上一篇 我们已经进行了对zabbix的server端安装，本篇我们将进行对Zabbix agent端安装配置！ 通过第一篇 我们已经知道server-agent 都是部署到被监控主机上，由agent采集数据，报告给zabbix-server端进行监控的。 安装Zabbix代理端 由于zabbix-server用的是4.2版，那么我们agent也用4.2版。 yum安装zabbix-agent123456#yum安装zabbix源$ rpm -Uvh https://repo.zabbix.com/zabbix/4.2/rhel/7/x86_64/zabbix-release-4.2-1.el7.noarch.rpm# 安装zabbix-agent代理端# zabbix_sender` 为测试是否能够向server端发送数据的工具$ yum install -y zabbix-agent zabbix-sender zabbix代理端配置123456789# 修改/etc/zabbix/zabbix_agentd.conf配置文件# 设置被动模式下zabbix-server的IP地址Server=192.168.20.210# 设置主动模式下zabbix-server的IP地址ServerActive=192.168.20.210# 设置本机zabbix-agent主机名称Hostname=web server1 启动zabbix代理端12345# 启动zabbix-agent$ systemctl start zabbix-agent# 开机自启动zabbix-agent`$ systemctl enable zabbix-agent 默认情况下，zabbix-agent不能使用root用户运行的，如果非要以root用户运行，可以在/etc/zabbix/zabbix_agentd.conf 配置文件中设置AllowRoot=1 此时查看zabbix-agent进程和端口是否正常：1234567891011121314# 查看端口是否正常$ netstat -ptlnProto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:10050 0.0.0.0:* LISTEN 11734/zabbix_agentd # 查看进程是否正常$ ps -ef | grep zabbix_agentzabbix 11734 1 0 4月13 ? 00:00:00 /usr/sbin/zabbix_agentd -c /etc/zabbix/zabbix_agentd.confzabbix 11735 11734 0 4月13 ? 00:00:00 /usr/sbin/zabbix_agentd: collector [idle 1 sec]zabbix 11736 11734 0 4月13 ? 00:00:00 /usr/sbin/zabbix_agentd: listener #1 [waiting for connection]zabbix 11737 11734 0 4月13 ? 00:00:00 /usr/sbin/zabbix_agentd: listener #2 [waiting for connection]zabbix 11738 11734 0 4月13 ? 00:00:00 /usr/sbin/zabbix_agentd: listener #3 [waiting for connection]zabbix 11739 11734 0 4月13 ? 00:00:00 /usr/sbin/zabbix_agentd: active checks #1 [idle 1 sec]root 12105 11549 0 00:23 pts/0 00:00:00 grep --color=auto zabbix_agent 至此zabbix-agent 代理端安装完毕。 监控zabbix-agent代理端zabbix-server监控zabbix-agent有两种方式： 手动添加对应的zabbix-agent客户端 自动发现和自动注册 手动添加zabbix-agent适用于少量的被监控主机，而自动发现主要是通过发现网络中的主机，并自动把主机添加到监控中，并关联特定的模板，实现自动监控，适合有大量被监控主机，减少频繁手动添加主机的麻烦操作。 手动添加zabbix-agent客户端浏览器输入http://192.168.20.210/zabbix ，访问zabbix服务，点击配置-主机-创建主机点击模版 ，选择主机属于哪个模版 （模版里面包含需要监控的条目）点击添加 应用集： 表示模版中监控业务的一类型。（如：CPU应用集属于Template OS Linx模版） 监控项： 表示某一应用集中监控的某一项。（如：CPU负载、CPU使用率都属于CPU应用集中的监控项） 触发器： 表示某一监控项达到某自定义的阀值时，该出现的状态。（如：当CPU使用率达到70%设置他的状态为警告，80%为严重，这就属于触发器） 图 形： 表示哪些监控项进行了图形显示。（如：将CPU使用率用图形显示一段时间里的曲线变化） 自动发现：表示哪些监控项是可以通过自动发现进行监控。（如：自动发现主机网络接口流量） web监测: 表示zabbix把web某页面也监控起来，第一时间得知web崩溃信息并做相应处理。（如：监控http某一页面，如果状态码不是200，通过触发器返回严重告警） 至此手动添加zabbix-agent客户端步骤完成，可以在监控-图形中查看对监控项设置了图形的状态了。 自动发现当监控主机不断增多，有的时候需要添加一批机器，特别是刚用zabbix的运维人员需要将公司的所有服务器添加到zabbix，如果使用传统办法去单个添加设备、分组、项目、图像…..结果可想而知。鉴于这个问题我们可以好好利用下Zabbix的一个发现(Discovery)模块，进而来实现自动刚发现主机、自动将主机添加到主机组、自动加载模板、自动创建项目（item）、自动创建图像，下面我们来看看这个模块如何使用。 自动发现由服务端主动发起，Zabbix Server开启发现进程，定时扫描局域网中IP服务器、设备。 自动发现过程需要分为两个步骤： 通过网络扫描制定的服务，如：Zabbix Agent是否可以访问system.uname指标 发现主机之后需要执行添加的动作，这个过程由动作（Action）完成 点击配置-自动发现-创建发现规则填入名称、需发现服务器、设备的IP范围、更新间隔、检查项（ssh和zabbix客户端）、设备唯一性准则，最后勾选已启用、点击添加。进行自动发现规则的创建 在点击配置-动作-事件源-自动发现-创建动作 进行主机自动加入主机组并关联模板点击操作 对该动作关联到模版的操作添加到主机：将发现到的主机添加到主机添加到主机群组：选择要添加到的主机组链接到模版：链接到模板、选择相应的模板 点击添加完成动作规则的创建，至此发现主机、添加主机并将主机添加到主机组、链接模板全部完毕。 此时可以在监测-自动发现中看到已经被自动发现规则监测到的内网服务器！也可以在配置-主机群组-Discovered hosts中看到已经被自动发现的主机。也可以在监测-图形中查看自动发现的主机监控项的图形。 自动注册当主机分布在不同的城市，比如不同的云环境中时，使用主动发现就不好处理了，使用自动注册的方式非常适合在云环境中的部署。 由客户端主动发起，客户端必须安装并启动Agentd，否则无法被自动注册添加至主机列表。 点击配置-动作-事件源-自动注册-创建动作 进行主机自动加入主机组并关联模板点击操作选择具体的操作类型：添加主机、添加到主机群组、与模板关联的操作，最后点击添加。 在配置-主机中查看注册的设备信息]]></content>
      <categories>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix服务器监控之《安装Zabbix Server》（二）]]></title>
    <url>%2F2018%2F09%2F11%2Fzabbix-server.html</url>
    <content type="text"><![CDATA[上一篇 我们已经讲了zabbix的常用组件和工作模式，本篇我们将进行对Zabbix Server端安装配置！ 搭建环境系统信息 系统 版本 IP 关系 centos 7.5 192.168.20.210 服务端 centos 7.5 192.168.20.211 代理端 环境配置 设置主机名，重启生效 12345# server端$ echo "zabbix-server" &gt; /etc/hostname # agent端$ echo "zabbix-agent" &gt; /etc/hostname 关闭SELinux和防火墙检查 123$ sed -i "s/SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config$ systemctl stop firewalld.service$ systemctl disable firewalld.service 安装Zabbix服务端 我们这里安装的zabbix版本为4.2版本 yum安装zabbix-server123456#yum安装zabbix源$ rpm -Uvh https://repo.zabbix.com/zabbix/4.2/rhel/7/x86_64/zabbix-release-4.2-1.el7.noarch.rpm#安装zabbix服务端#zabbix-get为测试是否能够从agent端拉取数据的工具$ yum -y install zabbix-server-mysql zabbix-web-mysql zabbix-agent zabbix-get 安装mysql数据库 如果有现有的数据库环境，请跳过安装数据库环节，直接从创建zabbix数据库 开始。 12345678910111213# 在线yum安装mysql5.7$ wget -c https://dev.mysql.com/get/mysql80-community-release-el7-1.noarch.rpm$ rpm -ivh mysql80-community-release-el7-1.noarch.rpm$ yum -y install yum-utils$ yum-config-manager --disable mysql80-community$ yum-config-manager --enable mysql57-community$ yum install mysql-community-server -y# 启动mysql$ systemctl start mysqld# 开机启动$ systemctl enable mysqld 修改root密码12345# 查看mysql临时密码$ grep 'temporary password' /var/log/mysqld.log# 使用mysql临时登录，修改root密码mysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED BY 'Ala@2018'; 创建zabbix数据库创建zabbix用户和库12mysql&gt; create database zabbix character set utf8 collate utf8_bin;mysql&gt; grant all privileges on zabbix.* to zabbix@localhost identified by "Ala@2018"; 导入zabbix数据库在shell命令行执行导入zabbix数据1$ zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p'Ala@2018' zabbix zabbix服务端配置123456789101112131415# 配置zabbix连接的数据库地址、数据库名以及数据库用户DBHost=localhostDBName=zabbixDBUser=zabbix# 修改`/etc/zabbix/zabbix_server.conf` 文件，修改mysql连接密码DBPassword=Ala@2018# 添加上海区$ sed -i.ori '19a php_value date.timezone Asia/Shanghai' /etc/httpd/conf.d/zabbix.conf# 解决图形列表下中文乱码$ yum -y install wqy-microhei-fonts$ mv /usr/share/fonts/dejavu/DejaVuSans.ttf /usr/share/fonts/dejavu/DejaVuSans.ttf.bak$ cp -f /usr/share/fonts/wqy-microhei/wqy-microhei.ttc /usr/share/fonts/dejavu/DejaVuSans.ttf 启动zabbix服务端并配置12345# 启动 zabbix-server和httpd服务$ systemctl start zabbix-server httpd# 开机启动$ systemctl enable zabbix-server httpd 浏览器输入http://192.168.20.210/zabbix ，访问zabbix，如下图接下来点击 Next setup从上图可以看到zabbix相关组件配置，继续点击 Next setup上图中配置好之后，继续点击 Next setup上图中，name尽量取有意义的名字，继续点击 Next setup到这一步可以看到全部配置，确认无误后点击 Next setup登录zabbix登录之后点击 管理-用户-点击Admin ，可以设置超级管理基本属性，例如语言和主题，点击配置-主机 ，可以看到如下图，接下来安装zabbix客户端 安装zabbix agent客户端 这里的客户端作用是监控服务端本机 配置客户端，配置文件/etc/zabbix/zabbix_agentd.conf12345678# 主要配置如下，默认即可Server=127.0.0.1ServerActive=127.0.0.1Hostname=Zabbix server# 启动zabbix客户端systemctl start zabbix-agent# 开机启动systemctl enable zabbix-agent 现在可以看到可用性ZBX 为绿色，表示的是zabbix-agent服务连接正常]]></content>
      <categories>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix服务器监控之《初识zabbix概念》（一）]]></title>
    <url>%2F2018%2F09%2F11%2Fzabbix-summarize.html</url>
    <content type="text"><![CDATA[为什么要用Zabbix对于运维人员来说，监控是非常重要的，因为如果想要保证线上业务整体能够稳定运行，那么我们则需要实时关注与其相关的各项指标是否正常，而一个业务系统的背后，往往存在着很多的服务器、网络设备等硬件资源，如果我们想要能够更加方便的、集中的监控他们，我们则需要依靠一些外部的工具，而zabbix就是一个被广泛使用的，可以实现集中监控管理的应用程序。 Zabbix支持那些通讯方式 agent ：通过专用的代理程序进行监控，与常见的master/agent模型类似,如果被监控对象支持对应的agent，推荐首选这种方式。 ssh/telnet ：通过远程控制协议进行通讯，比如ssh或者telnet。 SNMP ：通过SNMP协议与被监控对象进行通讯，SNMP协议的全称为Simple Network Management Protocol ,被译为 “简单网络管理协议”，通常来说，我们无法在路由器、交换机这种硬件上安装agent，但是这些硬件往往都支持SNMP协议，SNMP是一种比较久远的、通行的协议，大部分网络设备都支持这种协议，其实SNMP协议的工作方式也可以理解为master/agent的工作方式，只不过是在这些设备中内置了SNMP的agent而已，所以，大部分网络设备都支持这种协议。 IPMI ：通过IPMI接口进行监控，我们可以通过标准的IPMI硬件接口，监控被监控对象的物理特征，比如电压，温度，风扇状态，电源状态等。 JMX ：通过JMX进行监控，JMX（Java Management Extensions，即Java管理扩展），监控JVM虚拟机时，使用这种方法也是非常不错的选择。 Zabbix监控流程一般情况下，我们将zabbix agent部署到被监控主机上，由agent采集数据，报告给负责监控的中心主机，中心主机也就是master/agent模型中的master，负责监控的中心主机被称为zabbix server，zabbix server将从agent端接收到的信息存储于zabbix的数据库中，我们把zabbix的数据库端称为zabbix database， 如果管理员需要查看各种监控信息，则需要zabbix的GUI，zabbix的GUI是一种Web GUI，我们称之为zabbix web，zabbix web是使用php编写的，所以，如果想要使用zabbix web展示相关监控信息，需要依赖LAMP环境，不管是zabbix server ，或是zabbix web，他们都需要连接到zabbix database获取相关数据，这样说可能不容易理解，对比下图理解上述概念，就容易许多。 当监控规模变得庞大时，我们可能有成千上万台设备需要监控，这时我们是否需要部署多套zabbix系统进行监控呢？如果部署多套zabbix监控系统，那么监控压力将会被分摊，但是，这些监控的对象将会被尽量平均的分配到不同的监控系统中，这个时候，我们就无法通过统一的监控入口，去监控这些对象了，虽然分摊了监控压力，但是也增加了监控工作的复杂度，那么，我们到底该不该建立多套zabbix监控系统从而分摊巨大的监控压力呢？其实，zabbix天生就有处理这种问题的能力，因为zabbix支持分布式监控，我们可以把成千上万台的被监控对象分成不同的区域，每个区域中设置一台代理主机，区域内的每个被监控对象的信息被agent采集，提交给代理主机，在这个区域内，代理主机的作用就好比zabbix server，我们称这些代理主机为zabbix proxy，zabbix proxy再将收集到的信息统一提交给真正的zabbix server处理，这样，zabbix proxy分摊了zabbix server的压力，同时，我们还能够通过统一的监控入口，监控所有的对象，当监控规模庞大到需要使用zabbix proxy时，zabbix的架构如下图，我们可以对比下图，理解上述描述。 总结zabbix核心组件 zabbix agent ：部署在被监控主机上，负责被监控主机的数据，并将数据发送给zabbix server。 zabbix server ：负责接收agent发送的报告信息，并且负责组织配置信息、统计信息、操作数据等。 zabbix database ：用于存储所有zabbix的配置信息、监控数据的数据库。 zabbix proxy ：可选组件，用于分布式监控环境中，zabbix proxy代表server端，完成局部区域内的信息收集，最终统一发往server端。 zabbix工作模式我们知道，agent端会将采集完的数据主动发送给server端，这种模式我们称之为主动模式，即对于agent端来说是主动的。其实，agent端也可以不主动发送数据，而是等待server过来拉取数据，这种模式我们称之为被动模式。但是，不管是主动模式还是被动模式，都是对于agent端来说的，而且，主动模式与被动模式可以同时存在，并不冲突。管理员可以在agent端使用一个名为zabbix_sender 的工具，测试是否能够向server端发送数据。管理员也可以在server端使用一个名为zabbix_get 的工具，测试是否能够从agent端拉取数据。]]></content>
      <categories>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云ECS用465端口发邮件]]></title>
    <url>%2F2018%2F03%2F25%2Faliyun-ecs-mail.html</url>
    <content type="text"><![CDATA[原由大家可能都知道在阿里云购买的ECS云主机是不能直接通过25号端口发邮件的，因为阿里云底层对25号端口做了屏蔽。所以例如我们需要做监控、报告等邮件通知行为时，只能修改默认的25号端口。下面我们就开始如何用465端口来发送邮件。 请求数字证书 创建目录，用来存放证书 [root@PLAY ~]# mkdir -p /root/.certs/ [root@PLAY ~]# echo -n | openssl s_client -connect smtp.126.com:465 | sed -ne &apos;/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p&apos; &gt; ~/.certs/126.crt depth=2 C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert Global Root CA verify return:1 depth=1 C = US, O = DigiCert Inc, OU = www.digicert.com, CN = GeoTrust RSA CA 2018 verify return:1 depth=0 C = CN, L = Hangzhou, O = &quot;NetEase (Hangzhou) Network Co., Ltd&quot;, OU = Mail Dept., CN = *.126.com verify return:1 DONE smtp.126.com:465 为发件者的邮件服务器，我这用的是网易126.com 邮箱。生成126.crt 的证书。 添加一个证书到证书数据库中 [root@PLAY ~]# certutil -A -n &quot;GeoTrust SSL CA&quot; -t &quot;C,,&quot; -d ~/.certs -i ~/.certs/126.crt [root@PLAY ~]# certutil -A -n &quot;GeoTrust Global CA&quot; -t &quot;C,,&quot; -d ~/.certs -i ~/.certs/126.crt 列出目录下证书 [root@PLAY ~]# certutil -L -d /root/.certs Certificate Nickname Trust Attributes SSL,S/MIME,JAR/XPI GeoTrust SSL CA C,, 获取126邮箱的授权码前往邮箱的登陆网站登陆自己的邮箱，在邮箱设置里找到POP3/SMTP/IMAP 设置，并且完成客户端授权密码。如下图： 配置/etc/mail.rc文件在/etc/mail.rc文件末尾追加如下参数12345678set bsdcompatset from=test_wly@126.comset smtp="smtps://smtp.126.com:465"set smtp-auth-user=test_wly@126.comset smtp-auth-password=73jdi9dw7j3gc8gf1xvak01fssset smtp-auth=loginset ssl-verify=ignoreset nss-config-dir=/root/.certs 测试邮件发送是否正常1[root@PLAY ~]# echo "test mail" | mail -s "nagios report" test_wly@126.com 如果配置正确，此时test_wly@126.com就能收到刚刚发送的测试邮件了。 看起来已经成功了，但是发送完邮件还有报错：证书不被信任，且命令行就此卡住，需要按键才能出现命令提示符Error in certificate: Peer&#39;s certificate issuer is not recognized.可以按如下操作即可解决问题：123[root@PLAY ~]# cd /root/.certs/[root@PLAY .certs]# certutil -A -n "GeoTrust SSL CA - G3" -t "Pu,Pu,Pu" -d ./ -i 126.crt Notice: Trust flag u is set automatically if the private key is present.]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>aliyun</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible playbook详解]]></title>
    <url>%2F2018%2F03%2F23%2Fansible-playbook.html</url>
    <content type="text"><![CDATA[Playbook简介Playbooks与Ad-Hoc相比，是一种完全不同的运用Ansible的方式，而且是非常之强大的；也是系统ansible命令的集合，其利用yaml语法编写，运行过程，ansbile-playbook命令根据自上而下的顺序依次执行任务。playbook 由一个或多个 ‘plays’ 组成.它的内容是一个以 ‘plays’为元素的列表，在 play 之中,一组机器被映射为定义好的角色.在 ansible 中,play 的内容,被称为 tasks,即任务.在基本层次的应用中,一个任务是一个对 ansible模块的调用。当第一个任务依次在所有主机上执行完毕后，开始执行第二个任务。如果某个主机执行时发生错误，则所有操作将会回滚。 Playbook基础组件 hosts：运行执行任务（task）的目标主机 remote_user：在远程主机上执行任务的用户 tasks：任务列表 handlers：任务，与tasks不同的是只有在接受到通知时才会被触发 templates：使用模板语言的文本文件，使用jinja2语法。 variables：变量，变量替换 tag：标签，为某tasks指定标签，运行该标签可以即运行特定的tasks，定义为always的tag总会执行 when: 条件判断，当条件成立则执行tasks，不成立不执行表达式 判断表达式如：not or and != = with_items：循环迭代需要重复执行的任务列表，用{item}}引用列表值 例如一个简单的playbook文件：12345678910111213141516171819202122232425--- - hosts: test # 指定运行任务的主机组 remote_user: root # 指定远程执行任务的用户 vars: # 指定变量 - bsh: b.sh - httprpm: httpd task: # 任务的开始 - name: install httpd # 一个安装httpd的任务 yum: name=&#123;&#123; httprpm &#125;&#125; state=present # ansible的yum模块 tags: install_httpd # 为该任务打一个install_httpd的标签 - name: copy b.sh # 又一个复制b.sh脚本的任务 copy: src=/root/&#123;&#123; bsh &#125;&#125; dest=/root/ owner=ala group=ala mode=0644 notify: # 如果copy的文件内容发生改变就会触发 - reload httpd # 指定通知的哪个handlers when: ansible_distribution == "CentOS" # 通过变量判断系统为CentOS时才执行该copy任务 - name: copy b.sh copy: src=/root/&#123;&#123; bsh &#125;&#125; dest=/opt/ owner=ala group=ala mode=0644 notify: - reload httpd when: ansible_distribution == "Ubuntu" # 通过变量判断系统为Ubuntu时才执行该copy任务 - name: start httpd # 又一个启动httpd服务的任务 service: name=httpd state=started enabled=yes handlers: # 满足触发条件则执行的任务 - name: reload httpd # 满足触发条件的任务名 service: name=httpd state=reloaded # 该任务为重新加载一下httpd服务 其中的ansible_distribution是ansible收集的facts变量。 playbook定义变量 ansible 常见定义变量有以下 6 种 /etc/ansible/hosts文件主机中定义 /etc/ansible/hosts/文件主机组中定义 playbook的yaml文件中通过vars定义 获取系统变量，也称facts变量 分文件定义主机和主机组的变量 playbook 的role中定义 123456789101112131415161718192021222324252627282930313233343536373839# /etc/ansible/hosts文件主机中定义 主机变量192.168.200.136 http_port=808 maxRequestsPerChild=808192.168.200.137 http_port=8080 maxRequestsPerChild=909 # /etc/ansible/hosts文件主机中定义 主机组变量[websers]192.168.200.136192.168.200.137 [websers:vars] ntp_server=ntp.exampl.comproxy=proxy.exampl.com # ntp_server和proxy变量可为websers组中主机使用# playbook的yaml文件中通过vars定义 --- - hosts: test remote_user: root vars: # 定义bsh和httprpm的两个变量 - bsh: b.sh - httprpm: httpd# 获取系统facts变量ansible 192.168.200.136 -m setup # 可以获取主机所有的facts变量，通过&#123;&#123;variable_name&#125;&#125;引用# 分文件定义主机和主机组的变量/etc/ansible/group_vars/websers # 定义主机组名为websers的变量文件/etc/ansible/host_vars/hostpc # 定义主机名为hostpc的变量文件$ cat /etc/ansible/host_vars/hostpc # 变量文件内容格式如下---ntp_server: acme.example.orgdatabase_server: storage.example.org# role中定义 （目录结构下文讲述）$ cat /etc/ansible/roles/nginx/vars/main.yml---nginx_port: 80nginx_domain: www.abc.comnginx_user: nginx playbook role目录结构Roles简介Ansible为了层次化、结构化地组织Playbook，使用了角色（roles）。Roles能够根据层次型结构自动装载变量文件、task及handlers等。简单来讲，roles就是通过分别将变量、文件、任务、模块及处理器放置于单独的目录中，并可以便捷地include它们，roles一般用于基于主机构建服务的场景中，但也可以用于构建守护进程等场景中。 创建Roles创建roles时一般需要以下步骤：首先创建以roles命名的目录。然后在roles目标下分别创建以这个角色名称命令的目录，如websevers等，然后在每个角色命令的目录中分别创建files、handlers、tasks、templates、meta、defaults和vars目录，用不到的目录可以创建为空目录。最后在Playbook文件中调用各角色进行使用。 roles内各目录含义解释 files：用来存放由copy模块或script模块调用的文件。 templates：用来存放jinjia2模板，template模块会自动在此目录中寻找jinjia2模板文件。 tasks：此目录应当包含一个main.yml文件，用于定义此角色的任务列表，此文件可以使用include包含其它的位于此目录的task文件。 handlers：此目录应当包含一个main.yml文件，用于定义此角色中触发条件时执行的动作。 vars：此目录应当包含一个main.yml文件，用于定义此角色用到的变量。 defaults：此目录应当包含一个main.yml文件，用于为当前角色设定默认变量。 meta：此目录应当包含一个main.yml文件，用于定义此角色的特殊设定及其依赖关系。 如下定义了一个nginx服务的playbook目录结构树。1234567891011121314151617[root@k8s-master1 roles]# tree /etc/ansible/roles/nginx/etc/ansible/roles/nginx├── defaults│ └── main.yml├── files│ └── nginx.tar.gz├── handlers│ └── main.yml├── meta│ └── main.yml├── tasks│ └── main.yml├── templates│ └── nginx.conf.j2│ └── default.conf.j2└── vars └── main.yml 使用roles安装nginx案例实例环境 主机名 IP 系统 角色 ansible 192.168.20.210 centos7.5 ansible控制器 web-nginx 192.168.20.213 centos7.5 web服务器 hosts主机组清单123$ cat /etc/ansilbe/hosts # ansible hosts主机组配置 [web-node] 192.168.20.213 生成ssh密钥1234567891011121314151617181920212223242526272829# 在ansible控制机上生成ssh密钥对 $ ssh-keygen -t rsaGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:SHA256:m4+23Eh+dJ8r/9zSjpUbHJECh1iFQU8Z0QMlygrRm98 root@k8s-node1The key's randomart image is:+---[RSA 2048]----+| .. +==OB. || .o.o*..o.|| . oo o o.|| .o. . .|| S.. . . || o...E. o|| +. . . *.|| +.=. . ++=|| .*oo o+*=|+----[SHA256]-----+# 复制ansible控制机上的公钥到nginx web服务器$ ssh-copy-id -i ~/.ssh/id_rsa.pub 192.168.20.213这里是root用户验证，输入完root密码后，就可以在ansible主机上无密码ssh登陆nginx web服务器了。 创建nginx的roles结构目录1$ mkdir -pv /etc/ansible/roles/nginx/&#123;defaults,files,handlers,meta,tasks,templates,vars&#125; 准备安装包和依赖包12345cd /etc/ansible/roles/nginx/files$ wget http://nginx.org/download/nginx-1.16.0.tar.gz$ wget https://www.openssl.org/source/openssl-1.0.2r.tar.gz$ wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.42.tar.gz$ wget http://www.zlib.net/zlib-1.2.11.tar.gz 准备安装脚本 该脚本已在手动安装测试过，建议各位在通过ansible playbook安装服务器前，先手动安装一遍确保无误。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081$ cat /etc/ansible/roles/nginx/files/install_nginx.sh#!/bin/sh#info: source code install nginx 1.16.0#author: pyker &lt;pyker@qq.com&gt;export PATH=`echo $PATH`PWD="/opt"NGINX=nginx-1.16.0OPENSSL=openssl-1.0.2rPCRE=pcre-8.42ZLIB=zlib-1.2.11RUN_USER=nginxid -u $&#123;RUN_USER&#125; &gt;/dev/null 2&gt;&amp;1[ $? -ne 0 ] &amp;&amp; useradd -M -s /sbin/nologin $&#123;RUN_USER&#125;mkdir -p /var/log/nginxyum install -y epel-release yum install -y jemalloc jemalloc-develyum install -y gcc \ gcc-c++ \ gcc++ \ perl \ perl-devel \ perl-ExtUtils-Embed \ libxslt \ libxslt-devel \ libxml2 \ libxml2-devel \ gd \ gd-devel \ GeoIP \ GeoIP-develcd $PWDfor tar in `ls *.tar.gz`; do tar zxf $tardonecd $PWD/$NGINX &amp;&amp; ./configure --prefix=/usr/local/nginx \ --sbin-path=/usr/sbin/nginx \ --user=nginx \ --group=nginx \ --pid-path=/var/run/nginx.pid \ --lock-path=/var/run/nginx.lock \ --error-log-path=/var/log/nginx/error.log \ --http-log-path=/var/log/nginx/access.log \ --with-select_module \ --with-poll_module \ --with-threads \ --with-file-aio \ --with-http_ssl_module \ --with-http_v2_module \ --with-http_realip_module \ --with-http_addition_module \ --with-http_xslt_module=dynamic \ --with-http_image_filter_module=dynamic \ --with-http_geoip_module=dynamic \ --with-http_sub_module \ --with-http_dav_module \ --with-http_flv_module \ --with-http_mp4_module \ --with-http_gunzip_module \ --with-http_gzip_static_module \ --with-http_auth_request_module \ --with-http_random_index_module \ --with-http_secure_link_module \ --with-http_degradation_module \ --with-http_slice_module \ --with-http_stub_status_module \ --with-mail=dynamic \ --with-mail_ssl_module \ --with-stream \ --with-stream_ssl_module \ --with-stream_realip_module \ --with-stream_geoip_module=dynamic \ --with-stream_ssl_preread_module \ --with-compat \ --with-ld-opt="-ljemalloc" \ --with-pcre=../$&#123;PCRE&#125; \ --with-pcre-jit \ --with-zlib=../$&#123;ZLIB&#125; \ --with-openssl=../$&#123;OPENSSL&#125;\ --with-openssl-opt=no-nextprotoneg \ --with-debug &amp;&amp; make -j 4 &amp;&amp; make install 配置变量 在安装nginx的时候或者其他服务的时候常常用到变量，下面配置变量是通过roles方式配置。 12345$ cat /etc/ansible/roles/nginx/vas/main.ymlcat nginx/vars/main.yml nginx_user: nginxnginx_port: 80nginx_dir: /usr/local/nginx 准备nginx.conf模版 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859$ cat /etc/ansible/roles/nginx/templates/nginx.conf.j2user &#123;&#123; nginx_user &#125;&#125;;worker_processes &#123;&#123; ansible_processor_vcpus &#125;&#125;;error_log /var/log/nginx/error_nginx.log crit;pid /var/run/nginx.pid;worker_rlimit_nofile 51200;events &#123; use epoll; worker_connections 51200; multi_accept on;&#125;http &#123; map $http_upgrade $connection_upgrade &#123; default upgrade; '' close; &#125; include mime.types; default_type application/octet-stream; server_names_hash_bucket_size 128; client_header_buffer_size 32k; large_client_header_buffers 4 32k; client_max_body_size 1024m; client_body_buffer_size 10m; sendfile on; tcp_nopush on; keepalive_timeout 120; server_tokens off; tcp_nodelay on; #Gzip Compression gzip on; gzip_buffers 16 8k; gzip_comp_level 6; gzip_http_version 1.1; gzip_min_length 256; gzip_proxied any; gzip_vary on; gzip_types text/xml application/xml application/atom+xml application/rss+xml application/xhtml+xml image/svg+xml text/javascript application/javascript application/x-javascript text/x-json application/json application/x-web-app-manifest+json text/css text/plain text/x-component font/opentype application/x-font-ttf application/vnd.ms-fontobject image/x-icon; gzip_disable "MSIE [1-6]\.(?!.*SV1)"; #If you have a lot of static files to serve through Nginx then caching of the files' metadata (not the actual files' contents) can save some latency. open_file_cache max=1000 inactive=20s; open_file_cache_valid 30s; open_file_cache_min_uses 2; open_file_cache_errors on;########################## vhost ############################# include upstream/*.conf; include vhost/*.conf;&#125; nginx.conf.j2文件中nginx_user和ansible_processor_vcpus分别为用户自定义变量和-m setup获取的facts。 定义默认server模版 1234567891011121314151617 ```bash$ cat /etc/ansible/roles/nginx/templates/default.conf.j2server &#123; listen &#123;&#123; nginx_port &#125;&#125;; server_name &#123;&#123; ansible_all_ipv4_addresses &#125;&#125;; index index.html index.htm index.jsp index.do; access_log off; location / &#123; root /data/wwwroot; &#125; location /nginx_status &#123; stub_status on; access_log off; &#125;&#125; default.conf.j2文件中nginx_port和ansible_all_ipv4_addresses分别为用户自定义变量和-m setup获取的facts。 定义一个测试index.html文件12$ cat /etc/ansible/roles/nginx/templates/index.html this is test pages! 定义nginx启动脚本12345678910111213141516$ cat /etc/ansible/roles/nginx/files/nginx.service[Unit]Description=The NGINX HTTP and reverse proxy serverAfter=syslog.target network.target remote-fs.target nss-lookup.target[Service]Type=forkingPIDFile=/var/run/nginx.pidExecStartPre=/usr/sbin/nginx -tExecStart=/usr/sbin/nginxExecReload=/usr/sbin/nginx -s reloadExecStop=/usr/bin/kill -s QUIT $MAINPIDPrivateTmp=true[Install]WantedBy=multi-user.target 定义tasks任务1234567891011121314151617181920# 在tasks目录中定义了一个copy.yaml文件用户复制files目录下的文件到nginx服务器# 定义完成后，需要在tasks/main.yaml文件中用-include包含该copy.yaml$ cat /etc/ansible/roles/nginx/tasks/copy.yaml- name: copy nginx-1.16.0.tar.gz to client copy: src=/etc/ansible/roles/nginx/files/nginx-1.16.0.tar.gz dest=/opt/nginx-1.16.0.tar.gz- name: copy install_nginx.sh to client copy: src=/etc/ansible/roles/nginx/files/install_nginx.sh dest=/opt/install_nginx.sh- name: mkdir nginx data directory file: path=/data/wwwroot state=directory recurse=yes- name: copy index.html copy: src=/etc/ansible/roles/nginx/files/index.html dest=/data/wwwroot/index.html- name: copy nginx systemctl file copy: src=/etc/ansible/roles/nginx/files/nginx.service dest=/usr/lib/systemd/system/nginx.service- name: copy dependency package copy: src=/etc/ansible/roles/nginx/files/&#123;&#123; item &#125;&#125; dest=/opt/&#123;&#123; item &#125;&#125; with_items: - openssl-1.0.2r.tar.gz - pcre-8.42.tar.gz - zlib-1.2.11.tar.gz 123456789101112131415161718# 定义main.yaml文件$ cat /etc/ansible/roles/nginx/tasks/main.yml ---- include: copy.yml # 使用include将上面copy.yaml文件包含进来- name: install nginx shell: /usr/bin/sh /opt/install_nginx.sh- name: replace nginx.conf file template: src=/etc/ansible/roles/nginx/templates/nginx.conf.j2 dest=&#123;&#123; nginx_dir &#125;&#125;/conf/nginx.conf- name: mkdir nginx vhost directory file: path=&#123;&#123;nginx_dir&#125;&#125;/conf/vhost state=directory- name: relpace default.conf file template: src=/etc/ansible/roles/nginx/templates/default.conf.j2 dest=&#123;&#123;nginx_dir&#125;&#125;/conf/vhost/default.conf tags: ngxdef # 定义一个tag，当default.conf发生改变时可以指定运行该任务 notify: - reload nginx # 该名称需要和handler中定义的一样- name: start nginx command: /usr/sbin/nginx # 由于配置了nginx启动服务，也可以使用 shell: systemctl start nginx 定义触发通知handlers1234$ cat /etc/ansible/roles/nginx/handlers/main.yml ---- name: reload nginx shell: /usr/sbin/nginx -t; /usr/sbin/nginx -s reload # 也可以使用 shell: systemctl reload nginx 定义role入口文件123456$ cat /etc/ansible/roles/nginx.yml ---- hosts: web-node # 定义要执行该playbook的主机组 remote_user: root # 定义远程执行命令的用户 roles: # - nginx # 主机组中的主机使用哪个playbook剧本 查看当前nginx roles目录树结构123456789101112131415161718192021222324$ tree /etc/ansible/roles//etc/ansible/roles/├── nginx│ ├── defaults│ ├── files│ │ ├── index.html│ │ ├── nginx.service│ │ ├── install_nginx.sh│ │ ├── nginx-1.16.0.tar.gz│ │ ├── openssl-1.0.2r.tar.gz│ │ ├── pcre-8.42.tar.gz│ │ └── zlib-1.2.11.tar.gz│ ├── handlers│ │ └── main.yml│ ├── meta│ ├── tasks│ │ ├── copy.yml│ │ └── main.yml│ ├── templates│ │ ├── default.conf.j2│ │ └── nginx.conf.j2│ └── vars│ └── main.yml└── nginx.yml playbook语法检测通过上面的配置，我们已经完成了使用playbook方式安装nginx所需要的步骤，现在我们应该在执行该playbook前检查一下上述语法有没有错误。123$ ansible-playbook --syntax-check /etc/ansible/roles/nginx.yml playbook: /etc/ansible/roles/nginx.yml # 如果语法没问题，将直接显示文件名称，如果有错误将告知你那里错了 测试安装ansible-playbook -C 命令可以测试运行playbook剧本，而非真正在远端服务器上执行，这样可以方便查看playbook在执行过程中将会做哪些事情。1234567891011121314151617181920212223242526272829303132333435363738394041424344$ ansible-playbook -C nginx.yml PLAY [web-node] ************************************************************************************************************************************************TASK [nginx : copy nginx-1.16.0.tar.gz to client] **************************************************************************************************************changed: [192.168.20.213]TASK [nginx : copy install_nginx.sh to client] *****************************************************************************************************************changed: [192.168.20.213]TASK [nginx : mkdir nginx data directory] **********************************************************************************************************************changed: [192.168.20.213]TASK [nginx : copy index.html] *********************************************************************************************************************************changed: [192.168.20.213]TASK [nginx : copy nginx systemctl file] ***********************************************************************************************************************changed: [192.168.20.213]TASK [nginx : copy dependency package] *************************************************************************************************************************changed: [192.168.20.213] =&gt; (item=openssl-1.0.2r.tar.gz)changed: [192.168.20.213] =&gt; (item=pcre-8.42.tar.gz)changed: [192.168.20.213] =&gt; (item=zlib-1.2.11.tar.gz)TASK [nginx : install nginx] ***********************************************************************************************************************************skipping: [192.168.20.213]TASK [nginx : replace nginx.conf file] *************************************************************************************************************************changed: [192.168.20.213]TASK [nginx : mkdir nginx vhost directory] *********************************************************************************************************************changed: [192.168.20.213]TASK [nginx : relpace default.conf file] ***********************************************************************************************************************changed: [192.168.20.213]TASK [nginx : start nginx] *************************************************************************************************************************************skipping: [192.168.20.213]RUNNING HANDLER [nginx : reload nginx] *************************************************************************************************************************skipping: [192.168.20.213]PLAY RECAP *****************************************************************************************************************************************************192.168.20.213 : ok=8 changed=8 unreachable=0 failed=0 运行nginx playbook1$ ansible-playbook nginx.yml 执行ansible-playbook nginx.yml命令后，ansible将会按照刚刚测试安装的步骤在远端进行安装nginx服务并且启动。 验证安装结果等待一会nginx playbook将会在远端服务器上安装完毕，现在我们来验证一下结果：1234567891011121314151617181920212223# 在web服务器上查看nginx端口$ netstat -ptln | grep 80tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 14461/nginx: master# 查看nginx进程$ ps -ef | grep nginxroot 14461 1 0 00:39 ? 00:00:00 nginx: master process /usr/sbin/nginxnginx 14474 14461 0 00:39 ? 00:00:00 nginx: worker processnginx 14475 14461 0 00:39 ? 00:00:00 nginx: worker processnginx 14476 14461 0 00:39 ? 00:00:00 nginx: worker processnginx 14477 14461 0 00:39 ? 00:00:00 nginx: worker processroot 39501 1664 0 11:38 pts/0 00:00:00 grep --color=auto nginx# 让我们在内网任意一台电脑上来访问一下该nginx页面$ curl http://192.168.20.213this is a test pages! # 结果是我们前面定义的index.html内容# 访问一下nginx_status的uri$ curl http://192.168.20.213/nginx_status #前面default.conf.j2文件中定义的nginx locationActive connections: 1 server accepts handled requests 8 8 10 Reading: 0 Writing: 1 Waiting: 0 至此，一个使用ansible-playbook安装nginx服务已完成。]]></content>
      <categories>
        <category>CI/CD</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible 常用模块指令]]></title>
    <url>%2F2018%2F03%2F22%2Fansible-module.html</url>
    <content type="text"><![CDATA[本文主要讲解ansible的常用命令和简单安装步骤，具体配置文件详解以及playbook暂未涉及！后续更新。。。。 安装Ansible1$ yum install epel-release ansible -y 配置文件配置 常用ansible.cfg配置文件 123456789101112131415161718192021222324252627$ cat /etc/ansible/ansible.cfg [defaults] inventory = /etc/ansible/hosts #主机清单 library = /usr/share/my_modules/ # 使用的模块 forks = 5 #处理并发的进程数，建议设置控制机的数量 sudo_user = root #默认执行远程命令的用户 remote_port = 22 #SSH连接被控制机的端口 gathering = smart #'smart'收集facts的信息，如已收集，则采用缓存。可选参数'implicit'、'explicit'，分别表示每次都收集和默认不收集facts信息 fact_caching_timeout = 86400 #'gathering为smart'可用，设置收集超时时间 fact_caching = jsonfile #'gathering为smart'可用，设置以什么存储facts信息。还可在本地安装redis、memcache来作为facts的存储。 fact_caching_connection = /etc/ansible/ansible_facts_cache #'gathering为smart'可用，设置缓存路径。 roles_path = /etc/ansible/roles #设置ansible其他roles的路径 host_key_checking = false #忽略检查主机密钥 log_path = /var/log/ansible.log #ansible日志路径 module_name = command #ansible默认的模块 deprecation_warnings = False #禁用ansible“不建议使用”的警告 [ssh_connection] ssh_args = -C -o ControlMaster=auto -o ControlPersist=1d #开启ssh长连接，保存时间为1天 control_path_dir = /etc/ansible/ssh-socket #ssh长连接存放的路径 control_path = %(directory)s/%%h-%%p-%%r #ssh长连接的格式名称 pipelining = True #减少执行远程模块SSH操作次数，开启这个设置,将显著提高性能，但被控制机需要将/etc/sudoers下"Defaults requiretty"注释掉 [accelerate] accelerate_port = 5099 #使用python程序在被控制机上运行一个守护进程，ansible通过这个守护进程监听的端口进行通信。所有机器都要安装python-keyczar包 accelerate_timeout = 30 #设置用来控制从客户机获取数据的超时时间，如果在这段时间内没有数据传输,套接字连接会被关闭。 accelerate_connect_timeout = 5.0 #设置空着套接字调用的超时时间.这个应该设置相对比较短.这个和`accelerate_port`连接在回滚到ssh或者paramiko连接方式之前会尝试三次开始远程加速daemon守护进程.默认设置为1.0秒: hosts 文件（机器清单，进行分组管理） 123456[tomcat]192.168.16.192192.168.16.193[nginx]app1 ansible_ssh_host=192.168.16.190 ansible_ssh_pass="2039"app2 ansible_ssh_host=192.168.16.191 sudo_user=”ald” ansible_ssh_pass="2039" sudo_user和ansible_ssh_pass为帐号密码方式验证，建议用密钥。 Ansible指令参数 ansible 常用命令参数-m指定模块-a 指定模块的命令。默认是command模块，可以省略-B 指定ansible后台运行超时时间-C 测试运行效果，而不是正在运行-f 指定使用的并行进程的数量-i 指定inventory/hosts文件，默认/etc/ansiable/hosts文件–limit=xxx.xxx.xxx.xxx 限制对某个ip或者网段或者组执行–list-hosts 显示将要执行命令的主机 ansible-doc 常用命令参数-M –module-path=/xxx/xxx 查询模块 默认是/usr/share/ansible/-l –list 显示已存在的所有模块-s command 显示playbook制定模块的用法，类似 man 命令 ansible-galaxy 下载第三方模块指令，类似yum、pip、easy_install这样的命令 ansible-galaxy install &lt;module_name&gt; ansible-playbook 常用命令参数–syntax-check [yaml文件] 语法检测-t TAGS 只允许指定的tags标签任务，多个以 , 分开–skip-tags=SKIP_TAGS 跳过指定的标签–start-at-task=START_AT 从哪个任务后执行 常用指令模块1、 copy——拷贝模块 (用于将本地或远程机器上的文件拷贝到远程主机上)12$ ansible all –m copy -a “src=/xxx/xxx dest=/yyy/yyy owner=root group=root mode=644 force=yes/no backup=yes/no”解释：将src 文件/目录复制到远程dest上，所有者/组为root 权限为644，force为是否强制替换，backup为替换前是否需要备份远程远文件 2、 raw——命令模块 （和command、shell类似）12$ ansible all –m raw -a "ifconfig"解释：在所有主机上执行ifocnfig命令。 3、 yum——安装模块 （安装程序）12$ ansible all –m yum –a “name=httpd state=present”解释：安装httpd程序，state可以是present、latest、installed表示安装程序，absent、removed表示卸载程序 4、 file——文件模块 （文件属性修改）123456789$ ansible all –m file –a “src=/xxx/xxx/1 dest=/yyy/1 state=link owner=alad group=alad mode=777”$ ansible develop -m file -a "path=/xxx/dir recurse=yes owner=root group=alad mode=644"解释：1、将src的文件软连接到dest目录下，并修改所有者/组和权限 2、将path路径的目录递归形式设置所有者和权限*、state还可以是directory：如果目录不存在，创建目录 file：即使文件不存在，也不会被创建 hard：创建硬链接 touch：如果文件不存在，则会创建一个新的文件，如果文件或目录已存在，则更新其最后修改时间 absent：删除目录、文件或者取消链接文件 5、 cron——计划任务模块 （计划任务crontab）1234$ ansible develop -m cron -a "name='show time' minute=*/1 hour=* day=* month=* weekday=* job='/bin/date'"$ ansible develop -m cron -a "name='show time' state=absent"解释：1、创建一个每分钟显示时间的计划任务 2、删除名为show time这个计划任务 6、 group——组模块（用户组）12$ ansible all-m group -a "name=develop"解释：在所有主机上创建一个develop的组 ，state=absent表示删除该组 7、 user——用户模块（用户）12345$ ansible develop -m user -a "name=harlan groups=root password=-1vFO89dP6qyK"$ ansible develop -m user -a "name=harlan state=absent remove=yes"解释：1、在所有主机上创建harlan用户，并将其添加到root组，密码是经过hash加密后的，明文密码会被哈希，所以先填入hash后的密码即可可用此命令hash密码 openssl passwd -salt -1 "123456" 2、删除harlan用户。Remove表示是否删除用户的同时删除家目录 8、 service——服务模块（服务状态）1234$ ansible develop -m service -a "name=nginx state=running"$ ansible develop -m service -a "name=nginx state=restarted enabled=yes"解释：1、无论服务处在什么状态，最后都是将服务状态设置为启动，当服务正在运行的时候，显示为changed为false，state显示为状态，表示为正在运行；当服务停止的时候，显示为changed为true，表示这个时候将服务进行了启动，状态为启动 2、表示重启nginx并且将nginx设置为开机自启动，state还有staeted、reloaded、stoped值 9、 script——脚本模块（运行脚本）12$ ansible develop -m script -a "/root/a.sh"解释：在develop主机上运行当前服务器上的a.sh脚本 10、get_url——下载url上指定文件（类似wget）12$ ansible develop -m get_url -a "url=http://file.alavening.com/alading_file/head_img/1526900421976.jpg dest=/home/ owner=alad group=alad mode=644"解释：将url上的图片下载到dest目的目录上,并且设置相应的所有者/组和权限。 11、synchronize——同步目录（默认推送，mode=pull为拉取）1234$ ansible develop -m synchronize -a "src=/home/test/ dest=/home/test compress=yes delete=yes"$ ansible develop -m synchronize -a "src=/home/test/ dest=/home/test compress=yes mode=pull"解释：1、将src下的文件同步到dest上，delete=yes表示以src 目录为准镜像同步。 2、拉取远程src上的目录文件到本地dest上 12、template——文档内变量的替换的模块12$ ansible develop –m template –a ‘src=/mytemplates/foo.j2 dest=/etc/file.conf mode="u=rw,g=r,o=r"’解释：将src上foo.j2的变量模版复制到dest上。Template适合用playbook编写 ，通过变量然后拷贝到远程主机。 可以参考：https://www.cnblogs.com/jsonhc/p/7895399.html 13、fetch——从远程主机下载文件（不能拉取目录）12$ ansible develop -m fetch -a "src=/home/test/xxx dest=/home/ flat=yes"解释：将远程xxx文件拉取到本地home目录下，目录结构会是dest路径+远程主机名+src，假如远程主机名为develop，拉取的xxx文件在本地的/home/develop/home/test目录。如果需要指定拉取到某目录下 加个flat=yes的参数即可。 14、unarchive——解压文件1234$ ansible develop -m unarchive -a "src=/root/apache-tomcat-7.0.85.tar.gz dest=/home/test owner=alad group=alad mode=755"$ ansible develop -m unarchive -a "src=/home/alad/ansible/elk/logstash-6.2.4.tar.gz dest=/home/test remote_src=yes"$ ansible develop -m unarchive -a "src=http://mirrors.linuxeye.com/oneinstack-full.tar.gz dest=/home/test remote_src=yes"解释：将本地的tomcat压缩包解压到远程主机dest目录下，并修改其权限和所有者/组，remote_src=yes 表示解压远程主机已有的压缩包，src为url表示下载此包到远程主机dest目录进行解压缩后，并删除压缩包源文件 15、command和shell——linux命令模块12shell和command的区别：shell模块可以特殊字符，而command是不支持简单说：command运行的命令中无法使用变量，管道。如果需要使用管道、变量，请使用raw模块,或者shell模块。 16、setup——获取主机信息1234$ ansible develop -m setup$ ansible develop -m setup -a 'filter=ansible_*_mb'解释：1、显示系统所有信息 2、通常配合filter进行过滤来获取主机信息，（例子是显示内存信息） 17、assemble——配置文件组装发送到远程主机12$ ansible test -m assemble -a "src=/root/test dest=/root/ansible/fileone mode=777 remote_src=False delimiter='========'"解释：将src test目录下所有文件（不含test子目录内容）的内容发送到dest fileone文件中，remote_src默认为Ture表示src为远程主机上的路径，False为ansible控制端的路径，delimiter为文件之间内容分隔符。 Playbook语法和结构Playbook需要7个文件夹，如ansible安装nginx，则需要在/etc/ansible/roles目录下建立以下文件夹。mkdir -pv nginx/{default,tasks,vars,meta,handlers,templates,files}对于Ansible，几乎每个YAML文件都以一个列表开始。列表中的每个项目都是键/值对列表，通常称为“散列”或“字典”。所以，我们需要知道如何在YAML中编写列表和字典。YAML还有一个小小的怪癖。所有YAML文件（无论它们是否与Ansible相关联）都可以选择开始—和结束—.。这是YAML格式的一部分，并指示文档的开始和结束。列表中的所有成员都是以相同的缩进级别开头的行（短划线和空格）：”- “ 例如：12345678910111213141516171819---- hosts: test remote_user: root vars: - bsh: b.sh - httprpm: httpd task: - name: install httpd yum: name=&#123;&#123; httprpm &#125;&#125; state=present” tags: install_httpd - name: copy b.sh copy: src=/root/&#123;&#123; bsh &#125;&#125; dest=/root/ owner=ala group=ala mode=0644 notify: - reload httpd - name: start httpd service: name=httpd state=started enabled=yes handlers: - name: reload httpd service: name=httpd state=reloaded 第一次的话都会运行，后边如果copy的文件内容发生改变就会触发 notify ，然后会直接执行 handlers 的内容（ 这里notify后边的事件就都不会执行了 ）。 template模块jinja2语法 template:使用了Jinjia2格式作为文件模版，进行文档内变量的替换的模块。相当于copy，将jinja2的文件模板理解并执行，转化为各个主机间的对应值。如：template: src=httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf http.conf.j2必须是完整的文件内容，因为这是覆盖操作，而非只选择性远程主机替换变量，dest要指定文件名，如果是目录就相当于copy了http.conf.j2到远程目录下，不是我们要的结果。 when语句：在tasks中使用，Jinja2的语法格式 123- name: start nginx service shell: systemctl start nginx.service when: ansible_distribution == "CentOS" and ansible_distribution_major_version == "7" 当系统为 centos 7的时候执行sysctemctl命令，否则不执行 循环：迭代，需要重复执行的任务 变量名为item，而with_item为要迭代的元素。如果某个任务出错，后面不执行 12345- name: install packages yum: name=&#123;&#123; item &#125;&#125; state=latest with_items: - httpd - php 这是基于字符串列表给出元素示例 12345- name: create users user: name=&#123;&#123; item.name &#125;&#125; group=&#123;&#123; item.group &#125;&#125; state=present with_items: - &#123;name: 'userx1', group: 'groupx1'&#125; - &#123;name: 'userx2', group: 'groupx2'&#125; 这是基于字典列表给元素示例：item.name . 后边的表示键。]]></content>
      <categories>
        <category>CI/CD</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx内置变量]]></title>
    <url>%2F2018%2F01%2F23%2Fnginx-variable.html</url>
    <content type="text"><![CDATA[Nginx 内置变量解释为了方便配置和使用nginx，nginx核心模块ngx_http_core_module自带有许多内置的人性化变量，这极大的方便了系统管理员对nginx维护和管理。下面我们详解注解内置变量的含义（当然，如果你懂点HTTP知识的话，就更好理解了）：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263$args #请求中的参数值$query_string #同 $args$arg_NAME #GET请求中NAME的值$is_args #如果请求中有参数，值为"?"，否则为空字符串$uri #请求中的当前URI(不带请求参数，参数位于$args)，可以不同于浏览器传递的$request_uri的值，它可以通过内部重定向，或者使用index指令进行修改，$uri不包含主机名，如"/foo/bar.html"。$document_uri #同 $uri$document_root #当前请求的文档根目录或别名$host #优先级：HTTP请求行的主机名&gt;"HOST"请求头字段&gt;符合请求的服务器名$hostname #主机名$https #如果开启了SSL安全模式，值为"on"，否则为空字符串。$binary_remote_addr #客户端地址的二进制形式，固定长度为4个字节$body_bytes_sent #传输给客户端的字节数，响应头不计算在内；这个变量和Apache的mod_log_config模块中的"%B"参数保持兼容$bytes_sent #传输给客户端的字节数$connection #TCP连接的序列号$connection_requests #TCP连接当前的请求数量$content_length #"Content-Length" 请求头字段$content_type #"Content-Type" 请求头字段$cookie_name #cookie名称$limit_rate #用于设置响应的速度限制$msec #当前的Unix时间戳$nginx_version #nginx版本$pid #工作进程的PID$pipe #如果请求来自管道通信，值为"p"，否则为"."$proxy_protocol_addr #获取代理访问服务器的客户端地址，如果是直接访问，该值为空字符串$realpath_root #当前请求的文档根目录或别名的真实路径，会将所有符号连接转换为真实路径$remote_addr #客户端地址$remote_port #客户端端口$remote_user #用于HTTP基础认证服务的用户名$request #代表客户端的请求地址$request_body #客户端的请求主体：此变量可在location中使用，将请求主体通过proxy_pass，fastcgi_pass，uwsgi_pass和scgi_pass传递给下一级的代理服务器$request_body_file #将客户端请求主体保存在临时文件中。文件处理结束后，此文件需删除。如果需要之一开启此功能，需要设置client_body_in_file_only。如果将次文件传递给后端的代理服务器，需要禁用request body，即设置proxy_pass_request_body off，fastcgi_pass_request_body off，uwsgi_pass_request_body off，or scgi_pass_request_body off$request_completion #如果请求成功，值为"OK"，如果请求未完成或者请求不是一个范围请求的最后一部分，则为空$request_filename #当前连接请求的文件路径，由root或alias指令与URI请求生成$request_length #请求的长度 (包括请求的地址，http请求头和请求主体)$request_method #HTTP请求方法，通常为"GET"或"POST"$request_time #处理客户端请求使用的时间; 从读取客户端的第一个字节开始计时$request_uri #这个变量等于包含一些客户端请求参数的原始URI，它无法修改，请查看$uri更改或重写URI，不包含主机名，例如："/cnphp/test.php?arg=freemouse"$scheme #请求使用的Web协议，"http" 或 "https"$server_addr #服务器端地址，需要注意的是：为了避免访问linux系统内核，应将ip地址提前设置在配置文件中$server_name #服务器名$server_port #服务器端口$server_protocol #服务器的HTTP版本，通常为 "HTTP/1.0" 或 "HTTP/1.1"$status #HTTP响应代码$time_iso8601 #服务器时间的ISO 8610格式$time_local #服务器时间（LOG Format 格式）$cookie_NAME #客户端请求Header头中的cookie变量，前缀"$cookie_"加上cookie名称的变量，该变量的值即为cookie名称的值$http_NAME #匹配任意请求头字段；变量名中的后半部分NAME可以替换成任意请求头字段，如在配置文件中需要获取http请求头："Accept-Language"，$http_accept_language即可$http_cookie$http_post$http_referer #url跳转来源 （https://www.baidu.com/）$http_user_agent #用户终端浏览器等信息 （"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; SV1; GTB7.0; .NET4.0C;）$http_x_forwarded_for #获取到最原始用户IP，或者代理IP地址。$sent_http_NAME #可以设置任意http响应头字段；变量名中的后半部分NAME可以替换成任意响应头字段，如需要设置响应头Content-length，$sent_http_content_length即可$upstream_response_time #请求过程中，upstream响应时间（0.002）$upstream_addr #后台upstream的地址，即真正提供服务的主机地址 （10.10.10.100:80）$upstream_status #upstream状态 （200）$sent_http_cache_control$sent_http_connection$sent_http_content_type$sent_http_keep_alive$sent_http_last_modified$sent_http_location$sent_http_transfer_encoding 这些变量可以在配置文件中使用，方便你做各种nginx页面代理，转换，重写，重定向等操作；而且还可以对nginx日志做自定义的日志配置，方便你对nginx日志的收集和分析。如常用的nginx日志格式：123log_format main '$remote_addr $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '$http_user_agent $http_x_forwarded_for $request_time $upstream_response_time $upstream_addr $upstream_status'; 日志截取如下（可以从日志中看到代理到后端哪台机器上的哪个端口上，负载访问的状态值等都能看到）：123456[root@nginx1 logs]# tail -f /data/wwwlogs/access.log...110.156.114.121 - [11/Aug/2017:09:57:19 +0800] "GET /rest/mywork/latest/status/notification/count?_=1502416641768 HTTP/1.1" 200 67 "http://wiki.wang-inc.com/pages/viewpage.action?pageId=11174759" Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.78 Safari/537.36 - 0.006 0.006 12.129.120.121:8090 200]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详解nginx之location误区]]></title>
    <url>%2F2018%2F01%2F23%2FNginx-location.html</url>
    <content type="text"><![CDATA[location 的匹配顺序是“先匹配正则，再匹配普通”。矫正： location 的匹配顺序其实是“先匹配普通，再匹配正则”。我这么说，大家一定会反驳我，因为按“先匹配普通，再匹配正则”解释不了大家平时习惯的按“先匹配正则，再匹配普通”的实践经验。这里我只能暂时解释下，造成这种误解的原因是：正则匹配会覆盖普通匹配（实际的规则，比这复杂，后面会详细解释）。 location 的执行逻辑跟 location 的编辑顺序无关。矫正：这句话不全对，“普通 location ”的匹配规则是“最大前缀”，因此“普通 location ”的确与 location 编辑顺序无关；但是“正则 location ”的匹配规则是“顺序匹配，且只要匹配到第一个就停止后面的匹配”；“普通location ”与“正则 location ”之间的匹配顺序是？先匹配普通 location ，再“考虑”匹配正则 location 。注意这里的“考虑”是“可能”的意思，也就是说匹配完“普通 location ”后，有的时候需要继续匹配“正则 location ”，有的时候则不需要继续匹配“正则 location ”。两种情况下，不需要继续匹配正则 location ：（ 1 ）当普通 location 前面指定了“ ^~ ”，特别告诉 Nginx 本条普通 location 一旦匹配上，则不需要继续正则匹配；（ 2 ）当普通location 恰好严格匹配上，不是最大前缀匹配，则不再继续匹配正则。 总结一句话： “正则 location 匹配让步普通 location 的严格精确匹配结果；但覆盖普通 location 的最大前缀匹配结果” 匹配优先级为： (location =) &gt; (location 完整路径) &gt; (location ^~ 路径) &gt; (location ~,~* 正则顺序) &gt; (location 部分起始路径) &gt; (/) 官方文档解释：http://wiki.nginx.org/NginxHttpCoreModule#location1234locationsyntax: `location [=|~|~*|^~|@] /uri/ &#123; … &#125;`default: nocontext: server This directive allows different configurations depending on the URI. （译者注：1 、different configurations depending on the URI 说的就是语法格式：location [=|~|~*|^~|@] /uri/ { … } ，依据不同的前缀“= ”，“^~ ”，“~ ”，“~* ”和不带任何前缀的（因为[A] 表示可选，可以不要的），表达不同的含义, 简单的说尽管location 的/uri/ 配置一样，但前缀不一样，表达的是不同的指令含义。2 、查询字符串不在URI范围内。例如：/films.htm?fid=123 的URI 是/films.htm 。）It can be configured using both literal strings and regular expressions. To use regular expressions, you must use a prefix:“~”for case sensitive matching“~*”for case insensitive matching译文：上文讲到location /uri/ 可通过使用不同的前缀，表达不同的含义。对这些不同前缀，分下类，就2 大类：正则location ，英文说法是location using regular expressions 和普通location ，英文说法是location using literal strings 。那么其中“~ ”和“~ ”前缀表示正则location ，“~ ”区分大小写，“~ ”不区分大小写；其他前缀（包括：“=”，“^~ ”和“@ ”）和无任何前缀的都属于普通location 。 To determine which location directive matches a particular query, the literal strings are checked first. 译文：对于一个特定的 HTTP 请求（ a particular query ）， nginx 应该匹配哪个 location 块的指令呢（注意：我们在 nginx.conf 配置文件里面一般会定义多个 location 的）？匹配 规则是：先匹配普通location （再匹配正则表达式）。注意：官方文档这句话就明确说了，先普通location ，而不是有些同学的误区“先匹配正则location ”。 Literal strings match the beginning portion of the query – the most specific match will be used. 前面说了“普通location ”与“正则location ”之间的匹配规则是：先匹配普通location ，再匹配正则location 。那么，“普通location ”内部（普通location 与普通location ）是如何匹配的呢？简单的说：最大前缀匹配。原文：1、match the beginning portion of the query （说的是匹配URI 的前缀部分beginning portion ）； 2 、the most specific match will be used （因为location 不是“严格匹配”，而是“前缀匹配”，就会产生一个HTTP 请求，可以“前缀匹配”到多个普通location ，例如：location /prefix/mid/ {} 和location /prefix/ {} ，对于HTTP 请求/prefix/mid/t.html ，前缀匹配的话两个location 都满足，选哪个？原则是：the most specific match ，于是选的是location /prefix/mid/ {} ）。 Afterwards, regular expressions are checked in the order defined in the configuration file. The first regular expression to match the query will stop the search. 这段话说了两层意思，第一层是：“Afterwards, regular expressions are checked ”, 意思是普通location 先匹配，而且选择了最大前缀匹配后，就不能停止后面的匹配，最大前缀匹配只是一个临时的结果，nginx 还需要继续检查正则location （但至于最终是和普通location 的最大前缀匹配，还是正则location 的匹配，截止当前的内容还没讲，但后面会讲）。第二层是“regular expressions are checked in the order defined in the configuration file. The first regular expression to match the query will stop the search. ”，意思是说“正则location ”与“正则location”内部的匹配规则是：按照正则location 在配置文件中的物理顺序（编辑顺序）匹配的（这句话就说明location 并不是一定跟顺序无关，只是普通location 与顺序无关，正则location 还是与顺序有关的），并且只要匹配到一条正则location ，就不再考虑后面的（这与“普通location ”与“正则location ”之间的规则不一样，“普通location ”与“正则location ”之间的规则是：选择出“普通location ”的最大前缀匹配结果后，还需要继续搜索正则location ）。 If no regular expression matches are found, the result from the literal string search is used. 这句话回答了“普通location ”的最大前缀匹配结果与继续搜索的“正则location ”匹配结果的决策关系。如果继续搜索的“正则location ”也有匹配上的，那么“正则location ”覆盖 “普通location ”的最大前缀匹配（因为有这个覆盖关系，所以造成有些同学以为正则location 先于普通location 执行的错误理解）；但是如果“正则location ”没有能匹配上，那么就用“普通location ”的最大前缀匹配结果。For case insensitive operating systems, like Mac OS X or Windows with Cygwin, literal string matching is done in a case insensitive way (0.7.7). However, comparison is limited to single-byte locale’s only.Regular expression may contain captures (0.7.40), which can then be used in other directives. It is possible to disable regular expression checks after literal string matching by using “^~” prefix.If the most specific match literal location has this prefix: regular expressions aren’t checked. 通常的规则是，匹配完了“普通location ”指令，还需要继续匹配“正则location ”，但是你也可以告诉Nginx ：匹配到了“普通location ”后，不再需要继续匹配“正则location ”了，要做到这一点只要在“普通location ”前面加上“^~ ”符号（^ 表示“非”，~ 表示“正则”，字符意思是：不要继续匹配正则）。 By using the “=” prefix we define the exact match between request URI and location. When matched search stops immediately. E.g., if the request “/” occurs frequently, using “location = /” will speed up processing of this request a bit as search will stop after first comparison. 除了上文的“^~ ”可以阻止继续搜索正则location 外，你还可以加“= ”。那么如果“^~ ”和“= ”都能阻止继续搜索正则location 的话，那它们之间有什么区别呢？区别很简单，共同点是它们都能阻止继续搜索正则location ，不同点是“^~ ”依然遵守“最大前缀”匹配规则，然而“= ”不是“最大前缀”，而是必须是严格匹配（exact match ）。这里顺便讲下“location / {} ”和“location = / {} ”的区别，“location / {} ”遵守普通location 的最大前缀匹配，由于任何URI 都必然以“/ ”根开头，所以对于一个URI ，如果有更specific 的匹配，那自然是选这个更specific 的，如果没有，“/ ”一定能为这个URI 垫背（至少能匹配到“/ ”），也就是说“location / {} ”有点默认配置的味道，其他更specific的配置能覆盖overwrite 这个默认配置（这也是为什么我们总能看到location / {} 这个配置的一个很重要的原因）。而“location = / {} ”遵守的是“严格精确匹配exact match ”，也就是只能匹配 http://host:port/ 请求，同时会禁止继续搜索正则location 。因此如果我们只想对“GET / ”请求配置作用指令，那么我们可以选“location = / {} ”这样能减少正则location 的搜索，因此效率比“location / {}” 高（注：前提是我们的目的仅仅只想对“GET / ”起作用）。 On exact match with literal location without “=” or “^~” prefixes search is also immediately terminated. 前面我们说了，普通location 匹配完后，还会继续匹配正则location ；但是nginx 允许你阻止这种行为，方法很简单，只需要在普通location 前加“^~ ”或“= ”。但其实还有一种“隐含”的方式来阻止正则location 的搜索，这种隐含的方式就是：当“最大前缀”匹配恰好就是一个“严格精确（exact match ）”匹配，照样会停止后面的搜索。原文字面意思是：只要遇到“精确匹配exact match ”，即使普通location 没有带“= ”或“^~ ”前缀，也一样会终止后面的匹配。 先举例解释下，后面例题会用实践告诉大家。假设当前配置是：location /exact/match/test.html { 配置指令块1}，location /prefix/ { 配置指令块2} 和 location ~ .html$ { 配置指令块3} ，如果我们请求 GET /prefix/index.html ，则会被匹配到指令块3 ，因为普通location /prefix/ 依据最大匹配原则能匹配当前请求，但是会被后面的正则location 覆盖；当请求GET /exact/match/test.html ，会匹配到指令块1 ，因为这个是普通location 的exact match ，会禁止继续搜索正则location 。 To summarize, the order in which directives are checked is as follows: Directives with the “=” prefix that match the query exactly. If found, searching stops. All remaining directives with conventional strings. If this match used the “^~” prefix, searching stops. Regular expressions, in the order they are defined in the configuration file. If #3 yielded a match, that result is used. Otherwise, the match from #2 is used. 这个顺序没必要再过多解释了。但我想用自己的话概括下上面的意思“正则 location 匹配让步普通location 的严格精确匹配结果；但覆盖普通 location 的最大前缀匹配结果”。 It is important to know that nginx does the comparison against decoded URIs. For example, if you wish to match “/images/ /test”, then you must use “/images/ /test” to determine the location. 在浏览器上显示的URL 一般都会进行URLEncode ，例如“空格”会被编码为 ，但是Nginx 的URL 的匹配都是针对URLDecode 之后的。也就是说，如果你要匹配“/images/ /test ”，你写location 的时候匹配目标应该是：“/images/ /test ”。 Example:123456789101112131415161718192021222324location = / &#123; # matches the query / only. [ configuration A ]&#125;location / &#123; # matches any query, since all queries begin with /, but regular # expressions and any longer conventional blocks will be # matched first. [ configuration B ]&#125;location ^~ /images/ &#123; # matches any query beginning with /images/ and halts searching, # so regular expressions will not be checked. [ configuration C ]&#125;location ~* \.(gif|jpg|jpeg)$ &#123; # matches any request ending in gif, jpg, or jpeg. However, all # requests to the /images/ directory will be handled by # Configuration C. [ configuration D ]&#125; 上述这4 个location 的配置，没什么好解释的，唯一需要说明的是location / {[configuration B]} ，原文的注释严格来说是错误的，但我相信原文作者是了解规则的，只是文字描述上简化了下，但这个简化容易给读者造成“误解：先检查正则location ，再检查普通location ”。原文：“matches any query, since all queries begin with /, butregular expressions and any longer conventional blocks will be matched first. ”大意是说：“location / {} 能够匹配所有HTTP 请求，因为任何HTTP 请求都必然是以‘/ ’开始的（这半句没有错误）。但是，正则location 和其他任何比‘/ ’更长的普通location （location / {} 是普通location 里面最短的，因此其他任何普通location 都会比它更长，当然location = / {} 和 location ^~ / {} 是一样长的）会优先匹配（matched first ）。” 原文作者说“ but regular expressions will be matched first. ”应该只是想说正则 location 会覆盖这里的 location / {} ，但依然是普通location / {} 先于正则 location 匹配，接着再正则 location 匹配；但其他更长的普通 location （ any longer conventional blocks ）的确会先于 location / {} 匹配。 Example requests: / -&gt; configuration A /documents/document.html -&gt; configuration B /images/1.gif -&gt; configuration C /documents/1.jpg -&gt; configuration D Note that you could define these 4 configurations in any order and the results would remain the same. 需要提醒下：这里说“in any order ”和“… remain the same ”是因为上面只有一个正则location 。文章前面已经说了正则location 的匹配是跟编辑顺序有关系的。 While nested locations are allowed by the configuration file parser, their use is discouraged and may produce unexpected results. 实际上 nginx 的配置文件解析程序是允许 location 嵌套定义的（ location / { location /uri/ {} } ）。但是我们平时却很少看见这样的配置，那是因为 nginx 官方并不建议大家这么做，因为这样会导致很多意想不到的后果。 The prefix “@” specifies a named location. Such locations are not used during normal processing of requests, they are intended only to process internally redirected requests (see error_page ,try_files ). 文章开始说了location 的语法中，可以有“= ”，“^~ ”，“~ ”和“~* ”前缀，或者干脆没有任何前缀，还有“@ ”前缀，但是后面的分析我们始终没有谈到“@ ”前缀。文章最后点内容，介绍了“＠”的用途：“@ ”是用来定义“Named Location ”的（你可以理解为独立于“普通location （location using literal strings ）”和“正则location （location using regular expressions ）”之外的第三种类型），这种“Named Location ”不是用来处理普通的HTTP 请求的，它是专门用来处理“内部重定向（internally redirected ）”请求的。注意：这里说的“内部重定向（internally redirected ）”或许说成“forward ”会好点，以为内internally redirected 是不需要跟浏览器交互的，纯粹是服务端的一个转发行为。 location 实例练习Nginx 的语法形式是：location [=|~|~*|^~|@] /uri/ { … }，意思是可以以“ = ”或“ ~* ”或“ ~ ”或“ ^~ ”或“ @ ”符号为前缀，当然也可以没有前缀（因为 [A] 是表示可选的 A ； A|B 表示 A 和 B 选一个），紧接着是 /uri/ ，再接着是{…} 指令块，整个意思是对于满足这样条件的 /uri/ 适用指令块 {…} 的指令。 上述各种 location 可分两大类，分别是：“普通 location ”，官方英文说法是 location using literal strings 和“正则 location ”，英文说法是 location using regular expressions 。其中“普通 location ”是以“ = ”或“ ^~ ”为前缀或者没有任何前缀的 /uri/ ；“正则 location ”是以“ ~ ”或“ ~* ”为前缀的 /uri/ 。那么，当我们在一个 server 上下文编写了多个 location 的时候， Nginx 对于一个 HTTP 请求，是如何匹配到一个 location 做处理呢？用一句话简单概括 Nginx 的 location 匹配规则是：“正则 location ”让步 “普通 location”的严格精确匹配结果；但覆盖 “普通 location ”的最大前缀匹配结果。理解这句话，我想通过下面的实例来说明。 先普通 location ，再正则 location周边不少童鞋告诉我， nginx 是“先匹配正则 location 再匹配普通 location ”，其实这是一个误区， nginx 其实是“先匹配普通 location ，再匹配正则 location ”，但是普通 location 的匹配结果又分两种：一种是“严格精确匹配”，官方英文说法是“ exact match ”；另一种是“最大前缀匹配”，官方英文说法是“ Literal strings match the beginning portion of the query – the most specific match will be used. ”。我们做个实验： 例题 1 ：假设 nginx 的配置如下123456789101112server &#123; listen 9090; server_name localhost; location / &#123; root html; index index.html index.htm; deny all; &#125; location ~ \.html$ &#123; allow all; &#125;&#125; 附录 nginx 的目录结构是： nginx-&gt;html-&gt;index.html上述配置的意思是： location / {… deny all;} 普通 location 以“ / ”开始的 URI 请求（注意任何 HTTP 请求都必然以“/ ”开始，所以“ / ”的意思是所有的请求都能被匹配上），都拒绝访问； location ~.html$ {allow all;} 正则 location以 .html 结尾的 URI 请求，都允许访问。 测试结果：123456789101112131415161718192021222324252627[root@web108 ~]# curl http://localhost:9090/&lt;html&gt;&lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=”white”&gt;&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx/1.1.0&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;[root@web108 ~]# curl http://localhost:9090/index.html&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=”white” text=”black”&gt;&lt;center&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;[root@web108 ~]# curl http://localhost:9090/index_notfound.html&lt;html&gt;&lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=”white”&gt;&lt;center&gt;&lt;h1&gt;404 Not Found&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx/1.1.0&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 测试结果如下： URI请求 HTTP响应 curl http://localhost:9090/ 403 Forbidden curl http://localhost:9090/index.html Welcome to nginx! curl http://localhost:9090/index_notfound.html 404 Not Found curl http://localhost:9090/ 的结果是“ 403 Forbidden ”，说明被匹配到“ location / {..deny all;} ”了，原因很简单HTTP 请求 GET / 被“严格精确”匹配到了普通 location / {} ，则会停止搜索正则 location ； curl http://localhost:9090/index.html 结果是“ Welcome to nginx! ”，说明没有被“ location / {…deny all;} ”匹配，否则会 403 Forbidden ，但 /index.html 的确也是以“ / ”开头的，只不过此时的普通 location / 的匹配结果是“最大前缀”匹配，所以 Nginx 会继续搜索正则 location ， location ~ .html$ 表达了以 .html 结尾的都 allow all; 于是接着就访问到了实际存在的 index.html 页面。 curl http://localhost:9090/index_notfound.html 同样的道理先匹配 location / {} ，但属于“普通 location 的最大前缀匹配”，于是后面被“正则 location ” location ~ .html$ {} 覆盖了，最终 allow all ； 但的确目录下不存在index_notfound.html 页面，于是 404 Not Found 。 如果此时我们访问 http://localhost:9090/index.txt 会是什么结果呢？显然是 deny all ；因为先匹配上了 location / {..deny all;} 尽管属于“普通 location ”的最大前缀匹配结果，继续搜索正则 location ，但是 /index.txt 不是以 .html结尾的，正则 location 失败，最终采纳普通 location 的最大前缀匹配结果，于是 deny all 了。12345678[root@web108 ~]# curl http://localhost:9090/index.txt&lt;html&gt;&lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=”white”&gt;&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx/1.1.0&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 普通 location 的“隐式”严格匹配 例题 2 ：我们在例题 1 的基础上增加精确配置 123456789101112131415server &#123; listen 9090; server_name localhost; location /exact/match.html &#123; allow all; &#125; location / &#123; root html; index index.html index.htm; deny all; &#125; location ~ \.html$ &#123; allow all; &#125;&#125; 测试请求：12345678[root@web108 ~]# curl http://localhost:9090/exact/match.html&lt;html&gt;&lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=”white”&gt;&lt;center&gt;&lt;h1&gt;404 Not Found&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx/1.1.0&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 结果进一步验证了“普通 location ”的“严格精确”匹配会终止对正则 location 的搜索。这里我们小结下“普通 location”与“正则 location ”的匹配规则：先匹配普通 location ，再匹配正则 location ，但是如果普通 location 的匹配结果恰好是“严格精确（ exact match ）”的，则 nginx 不再尝试后面的正则 location ；如果普通 location 的匹配结果是“最大前缀”，则正则 location 的匹配覆盖普通 location 的匹配。也就是前面说的“正则 location 让步普通location 的严格精确匹配结果，但覆盖普通 location 的最大前缀匹配结果”。 普通 location 的“显式”严格匹配和“ ^~ ” 前缀 上面我们演示的普通 location 都是不加任何前缀的，其实普通 location 也可以加前缀：“ ^~ ”和“ = ”。其中“ ^~”的意思是“非正则，不需要继续正则匹配”，也就是通常我们的普通 location ，还会继续搜索正则 location （恰好严格精确匹配除外），但是 nginx 很人性化允许配置人员告诉 nginx 某条普通 location ，无论最大前缀匹配，还是严格精确匹配都终止继续搜索正则 location ；而“ = ”则表达的是普通 location 不允许“最大前缀”匹配结果，必须严格等于，严格精确匹配。 例题 3 ：“ ^~ ”前缀的使用123456789101112131415server &#123; listen 9090; server_name localhost; location /exact/match.html &#123; allow all; &#125; location ^~ / &#123; root html; index index.html index.htm; deny all; &#125; location ~ \.html$ &#123; allow all; &#125;&#125; 把例题 2 中的 location / {} 修改成 location ^~ / {} ，再看看测试结果： URL请求 修改前 修改后 curl http://localhost:9090/ 403 Forbidden 403 Forbidden curl http://localhost:9090/index.html Welcome to nginx! 403 Forbidden curl http://localhost:9090/index_notfound.html 404 Not Found 403 Forbidden curl http://localhost:9090/exact/match.html 404 Not Found 404 Not Found 除了 GET /exact/match.html 是 404 Not Found ，其余都是 403 Forbidden ，原因很简单所有请求都是以“ / ”开头，所以所有请求都能匹配上“ / ”普通 location ，但普通 location 的匹配原则是“最大前缀”，所以只有/exact/match.html 匹配到 location /exact/match.html {allow all;} ，其余都 location ^~ / {deny all;} 并终止正则搜索。 例题 4 ：“ = ”前缀的使用123456789101112131415server &#123; listen 9090; server_name localhost; location /exact/match.html &#123; allow all; &#125; location = / &#123; root html; index index.html index.htm; deny all; &#125; location ~ \.html$ &#123; allow all; &#125;&#125; 例题 4 相对例题 2 把 location / {} 修改成了 location = / {} ，再次测试结果： URL请求 修改前 修改后 curl http://localhost:9090/ 403 Forbidden 403 Forbidden curl http://localhost:9090/index.html Welcome to nginx! Welcome to nginx! curl http://localhost:9090/index_notfound.html 404 Not Found 404 Not Found curl http://localhost:9090/exact/match.html 404 Not Found 404 Not Found curl http://localhost:9090/test.jsp 403 Forbidden 404 Not Found 最能说明问题的测试是 GET /test.jsp ，实际上 /test.jsp 没有匹配正则 location （ location ~.html$ ），也没有匹配 location = / {} ，如果按照 location / {} 的话，会“最大前缀”匹配到普通 location / {} ，结果是 deny all 。 正则 location 与编辑顺序location 的指令与编辑顺序无关，这句话不全对。对于普通 location 指令，匹配规则是：最大前缀匹配（与顺序无关），如果恰好是严格精确匹配结果或者加有前缀“ ^~ ”或“ = ”（符号“ = ”只能严格匹配，不能前缀匹配），则停止搜索正则 location ；但对于正则 location 的匹配规则是：按编辑顺序逐个匹配（与顺序有关），只要匹配上，就立即停止后面的搜索。 123456789101112131415161718192021222324配置 3.1server &#123; listen 9090; server_name localhost; location ~ \.html$ &#123; allow all; &#125; location ~ ^/prefix/.*\.html$ &#123; deny all; &#125; &#125;配置 3.2server &#123; listen 9090; server_name localhost; location ~ ^/prefix/.*\.html$ &#123; deny all; &#125; location ~ \.html$ &#123; allow all; &#125; &#125; 测试结果： URL请求 配置3.1 配置3.2 curl http://localhost:9090/regextest.html 404 Not Found 404 Not Found curl http://localhost:9090/prefix/regextest.html 404 Not Found 403 Forbidden 解释：Location ~ ^/prefix/.*\.html$ {deny all;} 表示正则 location 对于以 /prefix/ 开头， .html 结尾的所有 URI 请求，都拒绝访问； location ~\.html${allow all;} 表示正则 location 对于以 .html 结尾的 URI 请求，都允许访问。 实际上，prefix 的是 ~.html$ 的子集。 在“配置 3.1 ”下，两个请求都匹配上 location ~\.html$ {allow all;} ，并且停止后面的搜索，于是都允许访问， 404 Not Found ；在“配置 3.2 ”下， /regextest.html 无法匹配 prefix ，于是继续搜索 ~.html$ ，允许访问，于是 404 Not Found ；然而 /prefix/regextest.html 匹配到 prefix ，于是 deny all ， 403 Forbidden 。123456789101112131415161718192021222324配置 3.3server &#123; listen 9090; server_name localhost; location /prefix/ &#123; deny all; &#125; location /prefix/mid/ &#123; allow all; &#125; &#125;配置 3.4server &#123; listen 9090; server_name localhost; location /prefix/mid/ &#123; allow all; &#125; location /prefix/ &#123; deny all; &#125; &#125; 测试结果： URL请求 配置3.3 配置3.4 curl http://localhost:9090/prefix/t.html 403 Forbidden 403 Forbidden curl http://localhost:9090/prefix/mid/t.html 404 Not Found 404 Not Found 测试结果表明：普通 location 的匹配规则是“最大前缀”匹配，而且与编辑顺序无关。 “@” 前缀 Named Location 使用REFER: http://wiki.nginx.org/HttpCoreModule#error_page假设配置如下：123456789101112131415server &#123; listen 9090; server_name localhost; location / &#123; root html; index index.html index.htm; allow all; &#125; #error_page 404 http://www.baidu.com # 直接这样是不允许的 error_page 404 = @fallback; location @fallback &#123; proxy_pass http://www.baidu.com; &#125;&#125; 上述配置文件的意思是：如果请求的 URI 存在，则本 nginx 返回对应的页面；如果不存在，则把请求代理到baidu.com 上去做个弥补（注： nginx 当发现 URI 对应的页面不存在， HTTP_StatusCode 会是 404 ，此时error_page 404 指令能捕获它）。 测试一： 123456789101112131415161718[root@web108 ~]# curl http://localhost:9090/nofound.html -iHTTP/1.1 302 FoundServer: nginx/1.1.0Date: Sat, 06 Aug 2011 08:17:21 GMTContent-Type: text/html; charset=iso-8859-1Location: http://localhost:9090/search/error.htmlConnection: keep-aliveCache-Control: max-age=86400Expires: Sun, 07 Aug 2011 08:17:21 GMTContent-Length: 222&lt;!DOCTYPE HTML PUBLIC “-//IETF//DTD HTML 2.0//EN”&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;302 Found&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Found&lt;/h1&gt;&lt;p&gt;The document has moved &lt;a href=”http://www.baidu.com/search/error.html”&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 当我们 GET /nofound.html 发送给本 nginx ， nginx 找不到对应的页面，于是 error_page 404 = @fallback ，请求被代理到 http://www.baidu.com ，于是 nginx 给 http://www.baidu.com 发送了 GET /nofound.html ，但/nofound.html 页面在百度也不存在，百度 302 跳转到错误页。直接访问 http://www.baidu.com/nofound.html 结果： 123456789101112131415161718[root@web108 ~]# curl http://www.baidu.com/nofound.html -iHTTP/1.1 302 FoundDate: Sat, 06 Aug 2011 08:20:05 GMTServer: ApacheLocation: http://www.baidu.com/search/error.htmlCache-Control: max-age=86400Expires: Sun, 07 Aug 2011 08:20:05 GMTContent-Length: 222Connection: Keep-AliveContent-Type: text/html; charset=iso-8859-1 &lt;!DOCTYPE HTML PUBLIC “-//IETF//DTD HTML 2.0//EN”&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;302 Found&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Found&lt;/h1&gt;&lt;p&gt;The document has moved &lt;a href=”http://www.baidu.com/search/error.html”&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 测试二：访问一个 nginx 不存在，但 baidu 存在的页面1234567891011121314151617181920212223[root@web108 ~]# curl http://www.baidu.com/duty/ -iHTTP/1.1 200 OKDate: Sat, 06 Aug 2011 08:21:56 GMTServer: ApacheP3P: CP=” OTI DSP COR IVA OUR IND COM ”P3P: CP=” OTI DSP COR IVA OUR IND COM ”Set-Cookie: BAIDUID=5C5D2B2FD083737A0C88CA7075A6601A:FG=1; expires=Sun, 05-Aug-12 08:21:56 GMT; max-age=31536000; path=/; domain=.baidu.com; version=1Set-Cookie: BAIDUID=5C5D2B2FD083737A2337F78F909CCB90:FG=1; expires=Sun, 05-Aug-12 08:21:56 GMT; max-age=31536000; path=/; domain=.baidu.com; version=1Last-Modified: Wed, 05 Jan 2011 06:44:53 GMTETag: “d66-49913b8efe340″Accept-Ranges: bytesContent-Length: 3430Cache-Control: max-age=86400Expires: Sun, 07 Aug 2011 08:21:56 GMTVary: Accept-Encoding,User-AgentConnection: Keep-AliveContent-Type: text/html&lt;!DOCTYPE HTML PUBLIC “-//W3C//DTD HTML 4.01 Transitional//EN”“http://www.w3.org/TR/html4/loose.dtd”&gt;。。。。&lt;/body&gt;&lt;/html&gt; 显示，的确百度这个页面是存在的。 123456789101112131415161718192021222324[root@web108 ~]# curl http://localhost:9090/duty/ -iHTTP/1.1 200 OKServer: nginx/1.1.0Date: Sat, 06 Aug 2011 08:23:23 GMTContent-Type: text/htmlConnection: keep-aliveP3P: CP=” OTI DSP COR IVA OUR IND COM ”P3P: CP=” OTI DSP COR IVA OUR IND COM ”Set-Cookie: BAIDUID=8FEF0A3A2C31D277DCB4CC5F80B7F457:FG=1; expires=Sun, 05-Aug-12 08:23:23 GMT; max-age=31536000; path=/; domain=.baidu.com; version=1Set-Cookie: BAIDUID=8FEF0A3A2C31D277B1F87691AFFD7440:FG=1; expires=Sun, 05-Aug-12 08:23:23 GMT; max-age=31536000; path=/; domain=.baidu.com; version=1Last-Modified: Wed, 05 Jan 2011 06:44:53 GMTETag: “d66-49913b8efe340″Accept-Ranges: bytesContent-Length: 3430Cache-Control: max-age=86400Expires: Sun, 07 Aug 2011 08:23:23 GMTVary: Accept-Encoding,User-Agent&lt;!DOCTYPE HTML PUBLIC “-//W3C//DTD HTML 4.01 Transitional//EN”“http://www.w3.org/TR/html4/loose.dtd”&gt;&lt;html&gt;。。。&lt;/body&gt;&lt;/html&gt; 当 curl http://localhost:9090/duty/ -i 时， nginx 没找到对应的页面，于是 error_page = @fallback ，把请求代理到 baidu.com 。注意这里的 error_page = @fallback 不是靠重定向实现的，而是所说的“ internally redirected （forward ）”。 proxy_pass URL 末尾加与不加/（斜线）的区别 Proxy_pass末尾带”/”和不带是有区别的：不带斜杠转发的是除hostname以外的部分，包括目录。可以使用正则表达式匹配location，且任意正则匹配成功后，转发的都是完整目录路径。带斜杠转发的是除hostname及目录外的所有部分。不能使用正则表达式匹配location块，只能使用完整路径名准确匹配。 1234配置1location /tobaidu &#123; proxy_pass http://127.0.0.1:8087;&#125; 测试结果： 请求URL 请求结果 curl http://127.0.0.1/tobaidu http://127.0.0.1:8087/tobaidu curl http://127.0.0.1/tobaidu/ http://127.0.0.1:8087/tobaidu/ curl http://127.0.0.1/tobaidu/xxxx http://127.0.0.1:8087/tobaidu/xxxx 1234配置2location /tobaidu &#123; proxy_pass http://127.0.0.1:8087/define;&#125; 测试结果： 请求URL 请求结果 curl http://127.0.0.1/tobaidu http://127.0.0.1:8087/define curl http://127.0.0.1/tobaidu/ http://127.0.0.1:8087/define/ curl http://127.0.0.1/tobaidu/xxxx http://127.0.0.1:8087/define/xxxx 1234配置3location /tobaidu/ &#123; proxy_pass http://127.0.0.1:8087;&#125; 测试结果： 请求URL 请求结果 curl http://127.0.0.1/tobaidu 重定向到http://127.0.0.1/tobaidu/ curl http://127.0.0.1/tobaidu/ http://127.0.0.1:8087/tobaidu/ curl http://127.0.0.1/tobaidu/xxxx http://127.0.0.1:8087/tobaidu/xxxx 1234配置4location /tobaidu/ &#123; proxy_pass http://127.0.0.1:8087/define;&#125; 测试结果： 请求URL 请求结果 curl http://127.0.0.1/tobaidu 重定向到http://127.0.0.1/tobaidu/ curl http://127.0.0.1/tobaidu/ http://127.0.0.1:8087/define curl http://127.0.0.1/tobaidu/xxxx http://127.0.0.1:8087/define/xxxx 1234配置5location /tobaidu &#123; proxy_pass http://127.0.0.1:8087/;&#125; 测试结果： 请求URL 请求结果 curl http://127.0.0.1/tobaidu http://127.0.0.1:8087/ curl http://127.0.0.1/tobaidu/ http://127.0.0.1:8087// curl http://127.0.0.1/tobaidu/xxxx http://127.0.0.1:8087//xxxx 1234配置6location /tobaidu &#123; proxy_pass http://127.0.0.1:8087/define/;&#125; 测试结果： 请求URL 请求结果 curl http://127.0.0.1/tobaidu http://127.0.0.1:8087/define/ curl http://127.0.0.1/tobaidu/ http://127.0.0.1:8087/define// curl http://127.0.0.1/tobaidu/xxxx http://127.0.0.1:8087/define//xxxx 1234配置7location /tobaidu/ &#123; proxy_pass http://127.0.0.1:8087/;&#125; 测试结果： 请求URL 请求结果 curl http://127.0.0.1/tobaidu 重定向到http://127.0.0.1/tobaidu/ curl http://127.0.0.1/tobaidu/ http://127.0.0.1:8087/ curl http://127.0.0.1/tobaidu/xxxx http://127.0.0.1:8087/xxxx 1234配置8location /tobaidu/ &#123; proxy_pass http://127.0.0.1:8087/define/;&#125; 测试结果： 请求URL 请求结果 curl http://127.0.0.1/tobaidu 重定向到http://127.0.0.1/tobaidu/ curl http://127.0.0.1/tobaidu/ http://127.0.0.1:8087/define/ curl http://127.0.0.1/tobaidu/xxxx http://127.0.0.1:8087/define/xxxx 结论URL符合 protocol://ip:port 同时结尾不加/,则nginx会代理匹配路径部分,否则不代理匹配路径,同时自动添加不匹配路径”部分”,比如/tobaidu/xxxx的/xxxx部分]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP请求头响应头字段详解]]></title>
    <url>%2F2017%2F12%2F26%2Fhttp-header.html</url>
    <content type="text"><![CDATA[HTTP消息头是指，在超文本传输协议（ Hypertext Transfer Protocol ，HTTP）的请求和响应消息中，协议头部分的那些组件。HTTP消息头用来准确描述正在获取的资源、服务器或者客户端的行为，定义了HTTP事务中的具体操作参数。 关于HTTP消息头HTTP消息头是在客户端请求（Request） 或服务器响应（Response） 时传递的，为请求或响应的第一行，HTTP消息体（请求或响应的内容）是其后传输。HTTP消息头，以明文的字符串格式传送，是以冒号分隔的键/值对，如：Accept-Charset: utf-8，每一个消息头最后以回车符(CR)和换行符(LF)结尾。HTTP消息头结束后，会用一个空白的字段来标识，这样就会出现两个连续的CR-LF。HTTP消息头支持自定义， 自定义的专用消息头一般会添加’X-‘前缀。 常用标准请求头字段Accept 设置接受的内容类型 Accept: text/plain Accept-Charset 设置接受的字符编码 Accept-Charset: utf-8 Accept-Encoding 设置接受的编码格式 Accept-Encoding: gzip, deflate Accept-Datetime 设置接受的版本时间 Accept-Datetime: Thu, 31 May 2007 20:35:00 GMT Accept-Language 设置接受的语言 Accept-Language: en-US Authorization 设置HTTP身份验证的凭证 Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Cache-Control 设置请求响应链上所有的缓存机制必须遵守的指令 Cache-Control: no-cache Connection 设置当前连接和hop-by-hop协议请求字段列表的控制选项 Connection: keep-alive Connection: Upgrade Content-Length 设置请求体的字节长度 Content-Length: 348 Content-MD5 设置基于MD5算法对请求体内容进行Base64二进制编码 Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ== Content-Type 设置请求体的MIME类型（适用POST和PUT请求） Content-Type: application/x-www-form-urlencoded Cookie 设置服务器使用Set-Cookie发送的http cookie Cookie: $Version=1; Skin=new; Date 设置消息发送的日期和时间 Date: Tue, 15 Nov 1994 08:12:31 GMT Expect 标识客户端需要的特殊浏览器行为 Expect: 100-continue Forwarded 披露客户端通过http代理连接web服务的源信息 Forwarded: for=192.0.2.60;proto=http;by=203.0.113.43 Forwarded: for=192.0.2.43, for=198.51.100.17 From 设置发送请求的用户的email地址 From: user@example.com Host 设置服务器域名和TCP端口号，如果使用的是服务请求标准端口号，端口号可以省略 Host: en.wikipedia.org:8080 Host: en.wikipedia.org If-Match 设置客户端的ETag,当时客户端ETag和服务器生成的ETag一致才执行，适用于更新自从上次更新之后没有改变的资源 If-Match: &quot;737060cd8c284d8af7ad3082f209582d If-Modified-Since 设置更新时间，从更新时间到服务端接受请求这段时间内如果资源没有改变，允许服务端返回304 Not Modified If-Modified-Since: Sat, 29 Oct 1994 19:43:31 GMT If-None-Match 设置客户端ETag，如果和服务端接受请求生成的ETage相同，允许服务端返回304 Not Modified If-None-Match: &quot;737060cd8c284d8af7ad3082f209582d&quot; If-Range 设置客户端ETag，如果和服务端接受请求生成的ETage相同，返回缺失的实体部分；否则返回整个新的实体 If-Range: &quot;737060cd8c284d8af7ad3082f209582d&quot; If-Unmodified-Since 设置更新时间，只有从更新时间到服务端接受请求这段时间内实体没有改变，服务端才会发送响应 If-Unmodified-Since: Sat, 29 Oct 1994 19:43:31 GMT Max-Forwards 限制代理或网关转发消息的次数 Max-Forwards: 10 Origin 标识跨域资源请求（请求服务端设置Access-Control-Allow-Origin响应字段） Origin: http://www.example-social-network.com Pragma 设置特殊实现字段，可能会对请求响应链有多种影响 Pragma: no-cache Proxy-Authorization 为连接代理授权认证信息 Proxy-Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Range 请求部分实体，设置请求实体的字节数范围，具体可以参见HTTP/1.1中的Byte serving Range: bytes=500-999 Referer 设置前一个页面的地址，并且前一个页面中的连接指向当前请求，意思就是如果当前请求是在A页面中发送的，那么referer就是A页面的url地址（轶 事：这个单词正确的拼法应该是”referrer”,但是在很多规范中都拼成了”referer”，所以这个单词也就成为标准用法） Referer: http://en.wikipedia.org/wiki/Main_Page TE 设置用户代理期望接受的传输编码格式，和响应头中的Transfer-Encoding字段一样 TE: trailers, deflate Upgrade 请求服务端升级协议 Upgrade: HTTP/2.0, HTTPS/1.3, IRC/6.9, RTA/x11, websocket User-Agent 用户代理的字符串值 User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:12.0) Gecko/20100101 Firefox/21.0 Via 通知服务器代理请求 Via: 1.0 fred, 1.1 example.com (Apache/1.1) Warning 实体可能会发生的问题的通用警告 Warning: 199 Miscellaneous warning 常用非标准请求头字段X-Requested-With 标识Ajax请求，大部分js框架发送请求时都会设置它为XMLHttpRequest X-Requested-With: XMLHttpRequest DNT 请求web应用禁用用户追踪 DNT: 1 (Do Not Track Enabled) DNT: 0 (Do Not Track Disabled) X-Forwarded-For 一个事实标准，用来标识客户端通过HTTP代理或者负载均衡器连接的web服务器的原始IP地址 X-Forwarded-For: client1, proxy1, proxy2 X-Forwarded-For: 129.78.138.66, 129.78.64.103 X-Forwarded-Host 一个事实标准，用来标识客户端在HTTP请求头中请求的原始host,因为主机名或者反向代理的端口可能与处理请求的原始服务器不同 X-Forwarded-Host: en.wikipedia.org:8080 X-Forwarded-Host: en.wikipedia.org X-Forwarded-Proto 一个事实标准，用来标识HTTP原始协议，因为反向代理或者负载均衡器和web服务器可能使用http,但是请求到反向代理使用的是https X-Forwarded-Proto: https Front-End-Https 微软应用程序和负载均衡器使用的非标准header字段 Front-End-Https: on X-Http-Method-Override 请求web应用时，使用header字段中给定的方法（通常是put或者delete）覆盖请求中指定的方法（通常是post）,如果用户代理或者防火墙不支持直接使用put或者delete方法发送请求时，可以使用这个字段 X-HTTP-Method-Override: DELETE X-ATT-DeviceId 允许更简单的解析用户代理在AT&amp;T设备上的MakeModel/Firmware X-Att-Deviceid: GT-P7320/P7320XXLPG X-Wap-Profile 设置描述当前连接设备的详细信息的xml文件在网络中的位置 x-wap-profile: http://wap.samsungmobile.com/uaprof/SGH-I777.xml Proxy-Connection 早起HTTP版本中的一个误称，现在使用标准的connection字段 Proxy-Connection: keep-alive X-UIDH 服务端深度包检测插入的一个唯一ID标识Verizon Wireless的客户 X-UIDH: ... X-Csrf-Token,X-CSRFToken,X-XSRF-TOKEN 防止跨站请求伪造 X-Csrf-Token: i8XNjC4b8KVok4uw5RftR38Wgp2BFwql X-Request-ID,X-Correlation-ID 标识客户端和服务端的HTTP请求 X-Request-ID: f058ebd6-02f7-4d3f-942e-904344e8cde5 常用标准响应头字段Access-Control-Allow-Origin 指定哪些站点可以参与跨站资源共享 Access-Control-Allow-Origin: * Accept-Patch 指定服务器支持的补丁文档格式，适用于http的patch方法 Accept-Patch: text/example;charset=utf-8 Accept-Ranges 服务器通过byte serving支持的部分内容范围类型 Accept-Ranges: bytes Age 对象在代理缓存中暂存的秒数 Age: 12 Allow 设置特定资源的有效行为，适用方法不被允许的http 405错误 Allow: GET, HEAD Alt-Svc 服务器使用”Alt-Svc”（Alternative Servicesde的缩写）头标识资源可以通过不同的网络位置或者不同的网络协议获取 Alt-Svc: h2=&quot;http2.example.com:443&quot;; ma=7200 Cache-Control 告诉服务端到客户端所有的缓存机制是否可以缓存这个对象，单位是秒 Cache-Control: max-age=3600 Connection 设置当前连接和hop-by-hop协议请求字段列表的控制选项 Connection: close Content-Disposition 告诉客户端弹出一个文件下载框，并且可以指定下载文件名 Content-Disposition: attachment; filename=&quot;fname.ext&quot; Content-Encoding 设置数据使用的编码类型 Content-Encoding: gzip Content-Language 为封闭内容设置自然语言或者目标用户语言 Content-Language: en Content-Length 响应体的字节长度 Content-Length: 348 Content-Location 设置返回数据的另一个位置 Content-Location: /index.htm Content-MD5 设置基于MD5算法对响应体内容进行Base64二进制编码 Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ== Content-Range 标识响应体内容属于完整消息体中的那一部分 Content-Range: bytes 21010-47021/47022 Content-Type 设置响应体的MIME类型 Content-Type: text/html; charset=utf-8 Date 设置消息发送的日期和时间 Date: Tue, 15 Nov 1994 08:12:31 GMT ETag 特定版本资源的标识符，通常是消息摘要 ETag: &quot;737060cd8c284d8af7ad3082f209582d&quot; Expires 设置响应体的过期时间 Expires: Thu, 01 Dec 1994 16:00:00 GMT Last-Modified 设置请求对象最后一次的修改日期 Last-Modified: Tue, 15 Nov 1994 12:45:26 GMT Link 设置与其他资源的类型关系 Link: &lt;/feed&gt;; rel=&quot;alternate&quot; Location 在重定向中或者创建新资源时使用 Location: http://www.w3.org/pub/WWW/People.html P3P 以P3P:CP=”your_compact_policy”的格式设置支持P3P(Platform for Privacy Preferences Project)策略，大部分浏览器没有完全支持P3P策略，许多站点设置假的策略内容欺骗支持P3P策略的浏览器以获取第三方cookie的授权 P3P: CP=&quot;This is not a P3P policy! See http://www.google.com/support/accounts/bin/answer.py?hl=en&amp;answer=151657 for more info.&quot; Pragma 设置特殊实现字段，可能会对请求响应链有多种影响 Pragma: no-cache Proxy-Authenticate 设置访问代理的请求权限 Proxy-Authenticate: Basic Public-Key-Pins 设置站点的授权TLS证书 Public-Key-Pins: max-age=2592000; pin-sha256=&quot;E9CZ9INDbd+2eRQozYqqbQ2yXLVKB9+xcprMF+44U1g=&quot;; Refresh “重定向或者新资源创建时使用，在页面的头部有个扩展可以实现相似的功能，并且大部分浏览器都支持meta http-equiv=&quot;refresh&quot; content=&quot;5; url=http://example.com/ Refresh: 5; url=http://www.w3.org/pub/WWW/People.html Retry-After 如果实体暂时不可用，可以设置这个值让客户端重试，可以使用时间段（单位是秒）或者HTTP时间 Example 1: Retry-After: 120 Example 2: Retry-After: Fri, 07 Nov 2014 23:59:59 GMT Server 服务器WEB名称 Server: Apache/2.4.1 (Unix) Set-Cookie 设置HTTP Cookie Set-Cookie: UserID=JohnDoe; Max-Age=3600; Version=1 Status 设置HTTP响应状态 Status: 200 OK Strict-Transport-Security 一种HSTS策略通知HTTP客户端缓存HTTPS策略多长时间以及是否应用到子域 Strict-Transport-Security: max-age=16070400; includeSubDomains Trailer 标识给定的header字段将展示在后续的chunked编码的消息中 Trailer: Max-Forwards Transfer-Encoding 设置传输实体的编码格式，目前支持的格式： chunked, compress, deflate, gzip, identity Transfer-Encoding: chunked TSV Tracking Status Value，在响应中设置给DNT(do-not-track),可能的取值 &quot;!&quot; — under construction &quot;?&quot; — dynamic &quot;G&quot; — gateway to multiple parties &quot;N&quot; — not tracking &quot;T&quot; — tracking &quot;C&quot; — tracking with consent &quot;P&quot; — tracking only if consented &quot;D&quot; — disregarding DNT &quot;U&quot; — updated TSV: ? Upgrade 请求客户端升级协议 Upgrade: HTTP/2.0, HTTPS/1.3, IRC/6.9, RTA/x11, websocket Vary 通知下级代理如何匹配未来的请求头已让其决定缓存的响应是否可用而不是重新从源主机请求新的 Example 1: Vary: * Example 2: Vary: Accept-Language Via 通知客户端代理，通过其要发送什么响应 Via: cache46.l2cn1341[84,206-0,H], cache38.l2c0c801[91,0], kunlun6.cn536[172,304-0,H], kunlun7.cn196[174,0] x-cache 是否命中缓存，HIT和MISS x-cache: HIT TCP_IMS_HIT dirn:-2:-2 Warning 实体可能会发生的问题的通用警告 Warning: 199 Miscellaneous warning WWW-Authenticate 标识访问请求实体的身份验证方案 WWW-Authenticate: Basic X-Frame-Options 点击劫持保护： deny frame中不渲染 sameorigin 如果源不匹配不渲染 allow-from 允许指定位置访问 allowall 不标准，允许任意位置访问 X-Frame-Options: deny 常用非标准响应头字段X-XSS-Protection 过滤跨站脚本 X-XSS-Protection: 1; mode=block Content-Security-Policy, X-Content-Security-Policy,X-WebKit-CSP 定义内容安全策略 X-WebKit-CSP: default-src &apos;self&apos; X-Content-Type-Options 唯一的取值是””,阻止IE在响应中嗅探定义的内容格式以外的其他MIME格式 X-Content-Type-Options: nosniff X-Powered-By 指定支持web应用的技术 X-Powered-By: PHP/5.4.0 X-UA-Compatible 推荐首选的渲染引擎来展示内容，通常向后兼容，也用于激活IE中内嵌chrome框架插件&lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;chrome=1&quot; /&gt; X-UA-Compatible: IE=EmulateIE7 X-UA-Compatible: IE=edge X-UA-Compatible: Chrome=1 X-Content-Duration 提供音视频的持续时间，单位是秒，只有Gecko内核浏览器支持 X-Content-Duration: 42.666 Upgrade-Insecure-Requests 标识服务器是否可以处理HTTPS协议 Upgrade-Insecure-Requests: 1 X-Request-ID,X-Correlation-ID 标识一个客户端和服务端的请求 X-Request-ID: f058ebd6-02f7-4d3f-942e-904344e8cde5 以下是一次客户端请求某网页的过程 如图通过二次请求对网页状态说明 客户端通过浏览器打开某网页，判断本地缓存是否过期。 没过期直接从缓存读取并且返回结果。 如果过期，服务器算出一个哈希值并通过 ETag 返回给浏览器，浏览器把哈希值和页面同时缓存在本地，当下次再次向服务器请求时，会通过类似 If-None-Match: “etag值” 的请求头把ETag发送给服务器，服务器再次计算页面的哈希值并和浏览器返回的值做比较，如果发现发生了变化就把页面返回给浏览器(200)，如果发现没有变化就给浏览器返回一个304未修改。这样通过控制浏览器端的缓存，可以节省服务器的带宽，因为服务器不需要每次都把全量数据返回给客户端。当未携带Etag时，客户端访问页面，服务器会将页面最后修改时间通过 Last-Modified 标识由服务器发往客户端，客户端记录修改时间，再次请求本地存在的cache页面时，客户端会通过 If-Modified-Since 头将先前服务器端发过来的Last-Modified时间戳发送回去，服务器端通过这个时间戳判断客户端的页面是否是最新的，如果不是最新的，则返回新的内容，如果是最新的，则 返回 304 告诉客户端其本地 cache 的页面是最新的。]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7 内核参数详解]]></title>
    <url>%2F2017%2F11%2F21%2Fcentos-kernel-analysis.html</url>
    <content type="text"><![CDATA[sysctl.conf 配置参数详解所谓Linux服务器内核参数优化，主要是指在Linux系统中针对业务服务应用而进行的系统内核参数调整，优化并无一定的标准。下面以生产环境下Linux常见的内核优化为例进行讲解，仅供参考。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495$ cat /etc/sysctl.conf#打开的文件句柄的数量fs.file-max = 265535#关闭ipv6net.ipv6.conf.all.disable_ipv6 = 1net.ipv6.conf.default.disable_ipv6 = 1# 避免放大攻击net.ipv4.icmp_echo_ignore_broadcasts = 1# 开启恶意icmp错误消息保护net.ipv4.icmp_ignore_bogus_error_responses = 1#关闭路由转发net.ipv4.ip_forward = 0net.ipv4.conf.all.send_redirects = 0net.ipv4.conf.default.send_redirects = 0#开启反向路径过滤net.ipv4.conf.all.rp_filter = 1net.ipv4.conf.default.rp_filter = 1#处理无源路由的包net.ipv4.conf.all.accept_source_route = 0net.ipv4.conf.default.accept_source_route = 0#关闭sysrq功能kernel.sysrq = 0#core文件名中添加pid作为扩展名kernel.core_uses_pid = 1# 开启SYN洪水攻击保护net.ipv4.tcp_syncookies = 1#修改消息队列长度kernel.msgmnb = 65536kernel.msgmax = 65536#设置最大内存共享段大小byteskernel.shmmax = 68719476736kernel.shmall = 4294967296#timewait的数量，默认180000net.ipv4.tcp_max_tw_buckets = 6000net.ipv4.tcp_sack = 1net.ipv4.tcp_window_scaling = 1net.ipv4.tcp_rmem = 4096 87380 4194304net.ipv4.tcp_wmem = 4096 16384 4194304net.core.wmem_default = 8388608net.core.rmem_default = 8388608net.core.rmem_max = 16777216net.core.wmem_max = 16777216#每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目net.core.netdev_max_backlog = 262144#限制仅仅是为了防止简单的DoS 攻击net.ipv4.tcp_max_orphans = 3276800#未收到客户端确认信息的连接请求的最大值net.ipv4.tcp_max_syn_backlog = 262144net.ipv4.tcp_timestamps = 0#内核放弃建立连接之前发送SYNACK 包的数量net.ipv4.tcp_synack_retries = 1#内核放弃建立连接之前发送SYN 包的数量net.ipv4.tcp_syn_retries = 1#启用timewait 快速回收net.ipv4.tcp_tw_recycle = 1#开启重用。允许将TIME-WAIT sockets 重新用于新的TCP 连接net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_mem = 94500000 915000000 927000000net.ipv4.tcp_fin_timeout = 1#当keepalive 起用的时候，TCP 发送keepalive 消息的频度。缺省是2 小时net.ipv4.tcp_keepalive_time = 30#允许系统打开的端口范围net.ipv4.ip_local_port_range = 1024 65000#修改防火墙表大小，默认65536net.netfilter.nf_conntrack_max=655350net.netfilter.nf_conntrack_tcp_timeout_established=1200# 确保无人能修改路由表net.ipv4.conf.all.accept_redirects = 0net.ipv4.conf.default.accept_redirects = 0net.ipv4.conf.all.secure_redirects = 0net.ipv4.conf.default.secure_redirects = 0 net.ipv4.tcp_tw_recycle = 1 启用TIME-WAIT状态sockets的快速回收，这个选项不推荐启用。在NAT(Network Address Translation)网络下，会导致大量的TCP连接建立错误。 我们在一些高并发的 WebServer上，为了端口能够快速回收，常常会打开了 tcp_tw_reccycle 。在关闭 tcp_tw_reccycle 的时候，kernel 是不会检查对端机器的包的时间戳的；而打开了 tcp_tw_reccycle 了，就会检查时间戳，很不幸网络发来的包的时间戳是乱跳的，所以我方的就把带了“倒退”的时间戳的包当作是“recycle的tw连接的重传数据，不是新的请求”，于是丢掉不回包，造成大量丢包。 当运行sysctl -p命令时报error: ‘net.ipv4.ip_conntrack_max’ is an unknown key 错时,通过以下命令修正：$ modprobe ip_conntrack$ echo “modprobe ip_conntrack” &gt;&gt; /etc/rc.local 一套生产环境使用过的内核参数 sysctl.conf文件 1234567891011121314151617181920212223242526272829303132333435363738394041fs.file-max=65535net.ipv4.ip_forward = 0net.ipv4.conf.default.rp_filter = 1net.ipv4.conf.default.accept_source_route = 0net.ipv4.tcp_max_tw_buckets = 6000net.ipv4.ip_local_port_range = 1024 65000net.ipv4.tcp_timestamps = 1net.ipv4.tcp_tw_recycle = 0net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_syncookies = 1kernel.msgmnb = 65536kernel.msgmax = 65536kernel.shmmax = 68719476736kernel.shmall = 4294967296net.ipv4.tcp_max_syn_backlog = 262144net.core.netdev_max_backlog = 262144net.core.somaxconn = 262144net.ipv4.tcp_max_orphans = 262144net.ipv4.tcp_synack_retries = 1net.ipv4.tcp_syn_retries = 1net.ipv4.tcp_fin_timeout = 1net.ipv4.tcp_keepalive_time = 30net.ipv4.tcp_sack = 1net.ipv4.tcp_window_scaling = 1net.ipv4.tcp_rmem = 4096 87380 4194304net.ipv4.tcp_wmem = 4096 16384 4194304net.core.wmem_default = 8388608net.core.rmem_default = 8388608net.core.rmem_max = 16777216net.core.wmem_max = 16777216net.ipv4.tcp_mem = 94500000 915000000 927000000net.nf_conntrack_max = 6553500#redisvm.dirty_ratio=10vm.dirty_background_ratio=5 禁用SELINUX 12$ vi /etc/sysconfig/selinux 设置为disabled 同步时间 12$ crontal -l*/20 * * * * /usr/sbin/ntpdate pool.ntp.org &gt; /dev/null 2&gt;&amp;1 文件描述符数量修改/etc/security/limits.conf文件，在文件末尾添加 1234root soft nofile 65535root hard nofile 65535* soft nofile 65535* hard nofile 65535 还需要修改/etc/security/limits.d下面的conf文件(会覆盖前面的配置信息)，我的是20-nproc.conf12* soft nproc 65535* hard nproc 65535 禁用自带的Firewalld防火墙 12systemctl stop firewalld.service 停止firewallsystemctl display firewalld.service 禁止firewall开机自启动]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[systemctl unit服务格式]]></title>
    <url>%2F2017%2F11%2F16%2Fsystemctl-unit.html</url>
    <content type="text"><![CDATA[systemctl是RHEL 7 的服务管理工具中主要的工具，它融合之前service和chkconfig的功能于一体。可以使用它永久性或只在当前会话中启用/禁用服务。 服务权限systemd有系统和用户区分；系统/user/lib/systemd/system/, 用户/etc/lib/systemd/user/一般系统管理员手工创建的单元文件建议存放在/etc/systemd/system/目录下面。或者/usr/lib/systemd/system/下面 ，然后可以通过systemctl enable xxx.service方式将该服务添加到/etc/systemd/system/multi-user.target.wants/目录下面设置为开机自启动。 格式介绍systemctl的服务文件主要包含[Unit]、[Service]、[Install]三类。下面我们对这三类进行说明。 [Unit]该部分主要对服务进行说明。 Description : 服务的简单描述。 Documentation ： 服务文档地址说明。 Before=xxx.service：代表本服务在xxx.service启动之前启动。 After=xxx.service：代表本服务在xxx.service启动之后启动。 Requires： 本服务启动后，它需要的服务也会启动；而本服务需要的服务被停止了，本服务也停止了。 Wants： 推荐使用。本服务启动了，它需要的服务也会被启动；而本服务需要的服务被停止了，对本单元没有影响。 [Service]该部分的配置服务的启动、重启、停止命令全部要求使用绝对路径，使用相对路径则会报错。 WorkingDirectory：指定服务运行的工作目录。 EnvironmentFile：指定服务需要的配置文件，下文可以用${}方式引用文件中的值。 Type=simple（默认值）：systemd认为该服务将立即启动。服务进程不会fork。如果该服务要启动其他服务，不要使用此类型启动，除非该服务是socket激活型。 Type=forking：systemd认为当该服务进程fork，且父进程退出后服务启动成功。对于常规的守护进程（daemon），除非你确定此启动方式无法满足需求，使用此类型启动即可。使用此启动类型应同时指定 PIDFile=，以便systemd能够跟踪服务的主进程。 Type=oneshot：这一选项适用于只执行一项任务、随后立即退出的服务。可能需要同时设置 RemainAfterExit=yes 使得 systemd 在服务进程退出之后仍然认为服务处于激活状态。 Type=notify：与 Type=simple 相同，但约定服务会在就绪后向 systemd 发送一个信号。这一通知的实现由 libsystemd-daemon.so 提供。 Type=dbus：若以此方式启动，当指定的 BusName 出现在DBus系统总线上时，systemd认为服务就绪。 Type=idle: systemd会等待所有任务(Jobs)处理完成后，才开始执行idle类型的单元。除此之外，其他行为和Type=simple 类似。 PIDFile：指定pid文件路径 ExecStart：指定启动单元的命令或者脚本 ExecStartPre和ExecStartPost：指定在执行ExecStart之前或者之后执行用户自定义的脚本，Type=oneshot允许用户执行多个按顺序定义的脚本。 ExecReload：指定单元重载时执行的命令或者脚本。 ExecStop：指定单元停止时执行的命令或者脚本。 PrivateTmp：True表示给服务分配独立的临时空间 LimitNOFILE：设置文件描述符相关参数个数，或者设置为无穷 infinity LimitNPROC：设置文件描述符相关参数个数，或者设置为无穷 infinity LimitCORE：设置文件描述符相关参数个数，或者设置为无穷 infinity Restart：这个选项如果被允许，服务重启的时候进程会退出，会通过systemctl命令执行清除并重启的操作。通常设置为on-failure。 RemainAfterExit：如果设置这个选择为真，服务会被认为是在激活状态，即使所以的进程已经退出，默认的值为假，这个选项只有在Type=oneshot时需要被配置。 [Install]定义如何安装这个配置文件，即怎样做到开机启动。 Alias：为单元提供一个空间分离的附加名字。 RequiredBy：单元被允许运行需要的一系列依赖单元，RequiredBy列表从Require获得依赖信息。 WantBy：单元被允许运行需要的弱依赖性单元，Wantby从Want列表获得依赖信息。 Also：指出和单元一起安装或者被协助的单元。 DefaultInstance：实例单元的限制，这个选项指定如果单元被允许运行默认的实例。 mysql.service样例123456789101112131415161718192021222324[Unit]Description=MySQL ServerDocumentation=man:mysqld(8)Documentation=http://dev.mysql.com/doc/refman/en/using-systemd.htmlAfter=network.targetAfter=syslog.target[Service]User=mysqlGroup=mysqlType=forkingPIDFile=/var/run/mysqld/mysqld.pidTimeoutSec=0PermissionsStartOnly=trueExecStartPre=/usr/bin/mysqld_pre_systemdExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid $MYSQLD_OPTSEnvironmentFile=-/etc/sysconfig/mysqlLimitNOFILE = 5000Restart=on-failureRestartPreventExitStatus=1PrivateTmp=false[Install]WantedBy=multi-user.target etcd.service样例12345678910111213141516[Unit]Description=Etcd ServerAfter=network.targetAfter=network-online.targetWants=network-online.target[Service]Type=notifyWorkingDirectory=/var/lib/etcd/EnvironmentFile=-/etc/etcd/etcd.conf #etcd配置文件路径ExecStart=/bin/bash -c "GOMAXPROCS=$(nproc) /usr/bin/etcd --name=\"$&#123;ETCD_NAME&#125;\" --data-dir=\"$&#123;ETCD_DATA_DIR&#125;\" --listen-client-urls=\"$&#123;ETCD_LISTEN_CLIENT_URLS&#125;\""Restart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.target # 说明：其中WorkingDirectory为etcd数据库目录，需要在etcd**安装前创建**]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[https证书加密解密原理解析]]></title>
    <url>%2F2017%2F10%2F26%2Fhttps-tls.html</url>
    <content type="text"><![CDATA[我们都知道HTTPS能够加密信息，以免敏感信息被第三方获取。所以很多银行网站或电子邮箱等等安全级别较高的服务都会采用HTTPS协议。而HTTPS可以看作是安全的HTTP，你可能听说过关于HTTPS的一些问题，比如什么握手，什么证书，加密之类的等等。HTTPS为何能保障web的安全，其运行原理是怎样的，当我们深入了解下去，其设计的思路对我们其他安全方面的设计也有一定的启发作用。 与http的区别HTTPS其实是有两部分组成：HTTP + SSL / TLS ，也就是在HTTP上又加了一层处理加密信息的模块。服务端和客户端的信息传输都会通过TLS进行加密，所以传输的数据都是加密后的数据。如下图。1234567891011HTTP HTTPS |-------| |-------| | HTTP | | HTTPS | |-------| |-------| | TCP | |ssl TLS| |-------| |-------| | IP | | TCP | |-------| |-------| | IP | |-------| HTTPS加密解密证书流程图HTTPS流程包含握手和后续的数据传输，握手的目的是为了客户端与服务端协商加密算法等参数。SSL/TLS基本过程是这样的： 客户端向服务器端所要并验证证书 双方协定加密算法以及“对话密钥” 双方采用协商后的“对话密钥”进行加密通信 整个流程步骤如下： 客户端发起HTTPS请求 这个没什么好说的，就是用户在浏览器里输入一个https网址，然后连接到server的443端口。 服务端的配置 采用HTTPS协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请。区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面(startssl就是个不错的选择，有1年的免费服务)。这套证书其实就是一对公钥和私钥。如果对公钥和私钥不太理解，可以想象成一把钥匙和一个锁头，只是全世界只有你一个人有这把钥匙，你可以把锁头给别人，别人可以用这个锁把重要的东西锁起来，然后发给你，因为只有你一个人有这把钥匙，所以只有你才能看到被这把锁锁起来的东西。 传送证书 这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间等等。 客户端解析证书 这部分工作是有客户端的TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个随即值。然后用证书对该随机值进行加密。就好像上面说的，把随机值用锁头锁起来，这样除非有钥匙，不然看不到被锁住的内容。 传送加密信息 这部分传送的是用证书加密后的随机值，目的就是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了。 服务段解密信息 服务端用私钥解密后，得到了客户端传过来的随机值(私钥)，然后把内容通过该值进行对称加密。所谓对称加密就是，将信息和私钥通过某种算法混合在一起，这样除非知道私钥，不然无法获取内容，而正好客户端和服务端都知道这个私钥，所以只要加密算法够彪悍，私钥够复杂，数据就够安全。 传输加密后的信息 这部分信息是服务段用私钥加密后的信息，可以在客户端被还原 客户端解密信息 客户端用之前生成的私钥解密服务段传过来的信息，于是获取了解密后的内容。整个过程第三方即使监听到了数据，也束手无策。 HTTPS加密解密证书流程图解释HTTPS在传输数据之前需要客户端（浏览器）与服务端（网站）之间进行一次握手，在握手过程中将确立双方加密传输数据的密码信息。TLS/SSL协议不仅仅是一套加密传输的协议，更是一件经过艺术家精心设计的艺术品，TLS/SSL中使用了非对称加密，对称加密以及HASH算法。握手过程的具体描述如下：11.浏览器将自己支持的一套加密规则发送给网站。 12.网站从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息。 12343.浏览器获得网站证书之后浏览器要做以下工作： a) 验证证书的合法性（颁发证书的机构是否合法，证书中包含的网站地址是否与正在访问的地址一致等），如果证书受信任，则浏览器栏里面会显示一个小锁头，否则会给出证书不受信的提示。 b) 如果证书受信任，或者是用户接受了不受信的证书，浏览器会生成一串随机数的密码，并用证书中提供的公钥加密。 c) 使用约定好的HASH算法计算握手消息，并使用生成的随机数对消息进行加密，最后将之前生成的所有信息发送给网站。 1234.网站接收浏览器发来的数据之后要做以下的操作： a) 使用自己的私钥将信息解密取出密码，使用密码解密浏览器发来的握手消息，并验证HASH是否与浏览器发来的一致。 b) 使用密码加密一段握手消息，发送给浏览器。 15.浏览器解密并计算握手消息的HASH，如果与服务端发来的HASH一致，此时握手过程结束，之后所有的通信数据将由之前浏览器生成的随机密码并利用对称加密算法进行加密。 这里浏览器与网站互相发送加密的握手消息并验证，目的是为了保证双方都获得了一致的密码，并且可以正常的加密解密数据，为后续真正数据的传输做一次测试。另外，HTTPS一般使用的加密与HASH算法如下：123非对称加密算法：RSA，DSA/DSS 对称加密算法：AES，RC4，3DES HASH算法：MD5，SHA1，SHA256]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown格式书写]]></title>
    <url>%2F2017%2F07%2F23%2Fmarkdown-format.html</url>
    <content type="text"><![CDATA[区块元素标题Markdown 支持两种标题的语法，类似 Setext 和类 atx 形式。类 Setext 形式是用底线的形式，利用 = （最高阶标题）和 - （第二阶标题），例如：1234This is an H1=============This is an H2------------- 也可以是类 Atx 形式则是在行首插入 1 到 6 个 # ，对应到标题 1 到 6 阶，例如：123# 这是 H1## 这是 H2###### 这是 H6 区块引用 Blockquotes区块引用是使用类似 email 中用 &gt; 的引用方式。例如:12345&gt; This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet,&gt; consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus.&gt; Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus.&gt;&gt; Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse 区块引用可以嵌套（例如：引用内的引用），只要根据层次加上不同数量的 &gt; ：12345&gt; This is the first level of quoting.&gt;&gt; &gt; This is nested blockquote.&gt;&gt; Back to the first level. 引用的区块内也可以使用其他的 Markdown 语法，包括标题、列表、代码区块等：12345678&gt; ### 这是一个标题。&gt; &gt; 1. 这是第一行列表项。&gt; 2. 这是第二行列表项。&gt; &gt; 给出一些例子代码：&gt; &gt; return shell_exec("echo $input | $markdown_script"); 列表Markdown 支持有序列表和无序列表。 无序列表使用星号、加号或是减号作为列表标记： 12345678910111213* Red* Green* Blue等同于：+ Red+ Green+ Blue也等同于：- Red- Green- Blue 有序列表则使用数字接着一个英文句点： 1231. Bird2. McHale3. Parish 要让列表看起来更漂亮，你可以把内容用固定的缩进整理好： * Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. * Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse id sem consectetuer libero luctus adipiscing. 列表项目可以包含多个段落， 每个项目下的段落都必须缩进 4 个空格或是 1 个制表符： 1. This is a list item with two paragraphs. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. Donec sit amet nisl. Aliquam semper ipsum sit amet velit. 2. Suspendisse id sem consectetuer libero luctus adipiscing. 如果要在列表项目内放进引用，那 &gt; 就需要缩进： * A list item with a blockquote: &gt; This is a blockquote &gt; inside a list item. 如果要放代码区块的话，该区块就需要缩进两次，也就是 8 个空格或是 2 个制表符： * 一列表项包含一个列表区块： &lt;代码写在这&gt; 代码区块和程序相关的写作或是标签语言原始码通常会有已经排版好的代码区块，通常这些区块我们并不希望它以一般段落文件的方式去排版，而是照原来的样子显示，要在 Markdown 中建立代码区块很简单，只要代码块每行简单地缩进 4 个空格或是 1 个制表符就可以，例如，下面的输入：123这是一个普通段落： 这是一个代码区块。 markdown也支持html的源码格式，只需要复制贴上，再加上缩进就可以了，剩下的 Markdown 都会帮你处理，例如： &lt;div class=&quot;footer&quot;&gt; &amp;copy; 2004 Foo Corporation &lt;/div&gt; 代码区块中，一般的 Markdown 语法不会被转换，像是星号便只是星号，这表示你可以很容易地以 Markdown 语法撰写 Markdown 语法相关的文件。 分割线你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线：1234567* * *********- - - 表格在markdown中也支持表格格式，格式如下：12345菜单1 | 菜单2 | 菜单3 | 菜单n----: | :---：| :---- | :----内容1 | 内容1 | 内容1 | 内容1内容2 | 内容2 | 内容2 | 内容2内容3 | 内容3 | 内容3 | 内容3 Markdown 插入的表格，单元格中默认左对齐；表头单元格中的内容会一直居中对齐，可以使用：来设置对齐方式，:---: 居中对齐，---: 右对齐， :--- 左对齐，- 的个数不限制。 区段元素链接Markdown 支持两种形式的链接语法： 行内式 和参考式 两种形式。不管是哪一种，链接文字都是用 [方括号] 来标记。要建立一个行内式 的链接，只要在方块括号后面紧接着圆括号并插入网址链接即可，如果你还想要加上链接的 title 文字，只要在网址后面，用双引号把 title 文字包起来即可，例如：12This is [an example](http://example.com/ "Title") inline link.[This link](http://example.net/) has no title attribute. 如果你是要链接到同样主机的资源，你可以使用相对路径： See my [About](/about/) page for details. 参考式 的链接是在链接文字的括号后面再接上另一个方括号，而在第二个方括号里面要填入用以辨识链接的标记,接着，在文件的任意处，你可以把这个标记的链接内容定义出来：：12This is [an example][id] reference-style link.[id]: http://example.com/ "Optional Title Here" 链接内容定义的形式为： 方括号（前面可以选择性地加上至多三个空格来缩进），里面输入链接文字 接着一个冒号 接着一个以上的空格或制表符 接着链接的网址 选择性地接着 title 内容，可以用单引号、双引号或是括弧包着 下面这三种链接的定义都是相同：123[foo]: http://example.com/ "Optional Title Here"[foo]: http://example.com/ 'Optional Title Here'[foo]: http://example.com/ (Optional Title Here) 请注意： 有一个已知的问题是 Markdown.pl 1.0.1 会忽略单引号包起来的链接 title。 强调Markdown 使用星号（*）和底线（_）作为标记强调字词 的符号，被 或 _ 包围的字词会被转成用 标签包围，用`两个 或 _ 包起来的话，则会被转成 &lt;strong&gt;，被三个星号（*）包起来则为倾斜和加粗文字，被两个波浪线（~~）` 包为起来是要在文字上加删除线。例如：1234567891011*single asterisks*_single underscores_**double asterisks**__double underscores__***double underscores***~~double underscores~~ 你可以随便用你喜欢的样式，唯一的限制是，你用什么符号开启标签，就要用什么符号结束。 但是如果你的 * 和 _ 两边都有空白的话，它们就只会被当成普通的符号。 如果要在文字前后直接插入普通的星号或底线，你可以用反斜线： \*this text is surrounded by literal asterisks\* 代码 单行短句 如果要标记一小段行内代码，你可以用反引号把它包起来` `，例如：1Use the `printf()` function. 如果要在代码区段内插入反引号，你可以用多个反引号来开启和结束代码区段： ``There is a literal backtick (`) here.`` 多行代码块 123代码块1代码块2代码块3 其中```也可以用~~~代替，且```后也支持语言关键字书写，使代码块格式化。例如```bash``` 语言对应关键字请参照本文最末尾。 图片很明显地，要在纯文字应用中设计一个「自然」的语法来插入图片是有一定难度的。Markdown 使用一种和链接很相似的语法来标记图片，同样也允许两种样式： 行内式 和参考式 。行内式的图片语法看起来像是：12![Alt text](/path/to/img.jpg)![Alt text](/path/to/img.jpg "Optional title") 详细叙述如下： 一个惊叹号 ! 接着一个方括号，里面放上图片下面的说明文字，相当于对图片内容的解释。 接着一个普通括号，里面放上图片的网址，最后还可以用引号包住并加上 选择性的 ‘title’ 文字。 参考式 的图片语法则长得像这样：12![Alt text][id][id]: url/to/image "Optional title attribute" 「id」是图片参考的名称，图片参考的定义方式则和连结参考一样： 字体和颜色Markdown是一种可以使用普通文本编辑器编写的标记语言，通过类似HTML的标记语法，它可以使普通文本内容具有一定的格式。但是它本身是不支持修改字体、字号与颜色 等功能的！为了使其修改字体和颜色，我们可以用html语法代替，如：123456&lt;font face="黑体"&gt;我是黑体字&lt;/font&gt;&lt;font face="微软雅黑"&gt;我是微软雅黑&lt;/font&gt;&lt;font face="STCAIYUN"&gt;我是华文彩云&lt;/font&gt;&lt;font color=#FF0000 size=3 face="黑体"&gt;这是一行红色3号大小的黑体文本&lt;/font&gt;&lt;font color=#00ffff size=72&gt;这是16位颜色值表示&lt;/font&gt;&lt;font color=gray size=72&gt;也可以用颜色的英文单词表示&lt;/font&gt; Size：规定文本的尺寸大小。可能的值：从 1 到 7 的数字。浏览器默认值是 3。颜色16进制值可以参考：https://www.114la.com/other/rgb.htm note和label颜色下面是note显示的颜色： default primary success info warning danger danger no-icon1234567&lt;div class="note default"&gt;&lt;p&gt;default&lt;/p&gt;&lt;/div&gt;&lt;div class="note primary"&gt;&lt;p&gt;primary&lt;/p&gt;&lt;/div&gt;&lt;div class="note success"&gt;&lt;p&gt;success&lt;/p&gt;&lt;/div&gt;&lt;div class="note info"&gt;&lt;p&gt;info&lt;/p&gt;&lt;/div&gt;&lt;div class="note warning"&gt;&lt;p&gt;warning&lt;/p&gt;&lt;/div&gt;&lt;div class="note danger"&gt;&lt;p&gt;danger&lt;/p&gt;&lt;/div&gt;&lt;div class="note danger no-icon"&gt;&lt;p&gt;danger no-icon&lt;/p&gt;&lt;/div&gt; 下面是label显示的颜色primarydefaultsuccessinfowarningdanger123456&#123;% label primary@primary %&#125;&#123;% label default@default %&#125;&#123;% label success@success %&#125;&#123;% label info@info %&#125;&#123;% label warning@warning %&#125;&#123;% label danger@danger %&#125; 其他自动链接Markdown 支持以比较简短的自动链接形式来处理网址和电子邮件信箱，只要是用方括号包起来， Markdown 就会自动把它转成链接。一般网址的链接文字就和链接地址一样，例如：1&lt;http://example.com/&gt; Markdown 会转为： &lt;a href=&quot;http://example.com/&quot;&gt;http://example.com/&lt;/a&gt; 反斜杠Markdown 可以利用反斜杠来插入一些在语法中有其它意义的符号，例如：如果你想要用星号加在文字旁边的方式来做出强调效果（但不用 标签），你可以在星号的前面加上反斜杠：1\*literal asterisks\* Markdown 支持以下这些符号前面加上反斜杠来帮助插入普通的符号：123456789101112\ 反斜线` 反引号* 星号_ 底线&#123;&#125; 花括号[] 方括号() 括弧# 井字号+ 加号- 减号. 英文句点! 惊叹号 语言关键字 语言名 关键字 Bash bash CoffeeScript coffeescript C++ cpp C# cs CSS css Diff diff HTTP http Ini ini Java java JavaScript javascript JSON json XML xml Makefile makefile Markdown markdown Objective-C objectivec Perl perl Python python Ruby ruby SQL sql]]></content>
      <categories>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
</search>
